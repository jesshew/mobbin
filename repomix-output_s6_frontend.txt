This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-04-24T13:24:25.061Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
/
  Users/
    jess/
      Desktop/
        personal git/
          mobbin/
            formobbin/
              app/
                globals.css
                layout.tsx
                page.tsx
              components/
                annotation/
                  annotation-canvas.tsx
                  annotation-header.tsx
                  box-handles.tsx
                  label-editor.tsx
                control-panel/
                  control-panel-header.tsx
                  element-editor.tsx
                  element-list.tsx
                  panel-footer-actions.tsx
                  summary-panel.tsx
                ui/
                  badge.tsx
                  button.tsx
                  card.tsx
                  input.tsx
                  label.tsx
                  reveal-on-hover.tsx
                  scroll-area.tsx
                  select.tsx
                  separator.tsx
                  tabs.tsx
                  toast.tsx
                  tooltip.tsx
                upload/
                  batch-card/
                    batch-header.tsx
                    constants.ts
                    image-grid.tsx
                    index.tsx
                    performance-stats.tsx
                    performance-tooltip.tsx
                    status-badge.tsx
                    utils.ts
                  batch-display.tsx
                  batch-list.tsx
                  dropzone-area.tsx
                  image-card.tsx
                  selected-images-panel.tsx
                annotation-editor.tsx
                control-panel.tsx
                element-list-item.tsx
                upload-interface.tsx
              hooks/
                use-annotation-state.tsx
                use-batch-management.ts
                use-box-interaction.tsx
                use-image-scale.tsx
                use-mobile.tsx
              lib/
                services/
                  ai/
                    ClaudeAIService.ts
                    MoondreamAIService.ts
                    MoondreamDetectionService.js
                    MoondreamVLService.js
                    OpenAIService.js
                  imageServices/
                    BoundingBoxService.js
                    imageFetchingService.ts
                    ImageProcessor.ts
                    screenshotProcessor.ts
                  AccuracyValidationService.ts
                  batchProcessingService.ts
                  DatabaseService.ts
                  ParallelAnnotationService.ts
                  ParallelExtractionService.ts
                  sample_vision_api_call.txt
              types/
                BatchProcessingScreenshot.ts
                DetectionResult.ts

================================================================
Repository Files
================================================================

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/app/globals.css
================
@import "tailwindcss";
@import "tw-animate-css";

@custom-variant dark (&:is(.dark *));

@theme inline {
  --color-background: var(--background);
  --color-foreground: var(--foreground);
  --font-sans: var(--font-geist-sans);
  --font-mono: var(--font-geist-mono);
  --color-sidebar-ring: var(--sidebar-ring);
  --color-sidebar-border: var(--sidebar-border);
  --color-sidebar-accent-foreground: var(--sidebar-accent-foreground);
  --color-sidebar-accent: var(--sidebar-accent);
  --color-sidebar-primary-foreground: var(--sidebar-primary-foreground);
  --color-sidebar-primary: var(--sidebar-primary);
  --color-sidebar-foreground: var(--sidebar-foreground);
  --color-sidebar: var(--sidebar);
  --color-chart-5: var(--chart-5);
  --color-chart-4: var(--chart-4);
  --color-chart-3: var(--chart-3);
  --color-chart-2: var(--chart-2);
  --color-chart-1: var(--chart-1);
  --color-ring: var(--ring);
  --color-input: var(--input);
  --color-border: var(--border);
  --color-destructive: var(--destructive);
  --color-accent-foreground: var(--accent-foreground);
  --color-accent: var(--accent);
  --color-muted-foreground: var(--muted-foreground);
  --color-muted: var(--muted);
  --color-secondary-foreground: var(--secondary-foreground);
  --color-secondary: var(--secondary);
  --color-primary-foreground: var(--primary-foreground);
  --color-primary: var(--primary);
  --color-popover-foreground: var(--popover-foreground);
  --color-popover: var(--popover);
  --color-card-foreground: var(--card-foreground);
  --color-card: var(--card);
  --radius-sm: calc(var(--radius) - 4px);
  --radius-md: calc(var(--radius) - 2px);
  --radius-lg: var(--radius);
  --radius-xl: calc(var(--radius) + 4px);
}

:root {
  --radius: 0.625rem;
  --background: oklch(1 0 0);
  --foreground: oklch(0.145 0 0);
  --card: oklch(1 0 0);
  --card-foreground: oklch(0.145 0 0);
  --popover: oklch(1 0 0);
  --popover-foreground: oklch(0.145 0 0);
  --primary: oklch(0.205 0 0);
  --primary-foreground: oklch(0.985 0 0);
  --secondary: oklch(0.97 0 0);
  --secondary-foreground: oklch(0.205 0 0);
  --muted: oklch(0.97 0 0);
  --muted-foreground: oklch(0.556 0 0);
  --accent: oklch(0.97 0 0);
  --accent-foreground: oklch(0.205 0 0);
  --destructive: oklch(0.577 0.245 27.325);
  --border: oklch(0.922 0 0);
  --input: oklch(0.922 0 0);
  --ring: oklch(0.708 0 0);
  --chart-1: oklch(0.646 0.222 41.116);
  --chart-2: oklch(0.6 0.118 184.704);
  --chart-3: oklch(0.398 0.07 227.392);
  --chart-4: oklch(0.828 0.189 84.429);
  --chart-5: oklch(0.769 0.188 70.08);
  --sidebar: oklch(0.985 0 0);
  --sidebar-foreground: oklch(0.145 0 0);
  --sidebar-primary: oklch(0.205 0 0);
  --sidebar-primary-foreground: oklch(0.985 0 0);
  --sidebar-accent: oklch(0.97 0 0);
  --sidebar-accent-foreground: oklch(0.205 0 0);
  --sidebar-border: oklch(0.922 0 0);
  --sidebar-ring: oklch(0.708 0 0);
}

.dark {
  --background: oklch(0.145 0 0);
  --foreground: oklch(0.985 0 0);
  --card: oklch(0.205 0 0);
  --card-foreground: oklch(0.985 0 0);
  --popover: oklch(0.205 0 0);
  --popover-foreground: oklch(0.985 0 0);
  --primary: oklch(0.922 0 0);
  --primary-foreground: oklch(0.205 0 0);
  --secondary: oklch(0.269 0 0);
  --secondary-foreground: oklch(0.985 0 0);
  --muted: oklch(0.269 0 0);
  --muted-foreground: oklch(0.708 0 0);
  --accent: oklch(0.269 0 0);
  --accent-foreground: oklch(0.985 0 0);
  --destructive: oklch(0.704 0.191 22.216);
  --border: oklch(1 0 0 / 10%);
  --input: oklch(1 0 0 / 15%);
  --ring: oklch(0.556 0 0);
  --chart-1: oklch(0.488 0.243 264.376);
  --chart-2: oklch(0.696 0.17 162.48);
  --chart-3: oklch(0.769 0.188 70.08);
  --chart-4: oklch(0.627 0.265 303.9);
  --chart-5: oklch(0.645 0.246 16.439);
  --sidebar: oklch(0.205 0 0);
  --sidebar-foreground: oklch(0.985 0 0);
  --sidebar-primary: oklch(0.488 0.243 264.376);
  --sidebar-primary-foreground: oklch(0.985 0 0);
  --sidebar-accent: oklch(0.269 0 0);
  --sidebar-accent-foreground: oklch(0.985 0 0);
  --sidebar-border: oklch(1 0 0 / 10%);
  --sidebar-ring: oklch(0.556 0 0);
}

@layer base {
  * {
    @apply border-border outline-ring/50;
  }
  body {
    @apply bg-background text-foreground;
  }
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/app/layout.tsx
================
import type { Metadata } from "next";
import { Geist, Geist_Mono } from "next/font/google";
import "./globals.css";

const geistSans = Geist({
  variable: "--font-geist-sans",
  subsets: ["latin"],
});

const geistMono = Geist_Mono({
  variable: "--font-geist-mono",
  subsets: ["latin"],
});

export const metadata: Metadata = {
  title: "For Mobbin By Jess Hew",
  description: "LLM-VLM-powered UI Labelling and Analysis",
};

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en">
      <body
        className={`${geistSans.variable} ${geistMono.variable} antialiased`}
      >
        {children}
      </body>
    </html>
  );
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/app/page.tsx
================
"use client"

import { useState, useEffect } from "react"
import { UploadInterface } from "@/components/upload-interface"
import { AnnotationEditor } from "@/components/annotation-editor"
import type { Batch } from "@/types/batch_v1"
import { useBatchManagement } from "@/hooks/use-batch-management"
import { BatchProcessingService } from "@/lib/services/batchProcessingService"

export default function Home() {
  const [selectedFiles, setSelectedFiles] = useState<File[]>([])
  const [selectedBatchId, setSelectedBatchId] = useState<string | null>(null)
  const [selectedImageIndex, setSelectedImageIndex] = useState<number | null>(null)
  const [currentView, setCurrentView] = useState<"upload" | "annotation">("upload")
  const [processingBatchId, setProcessingBatchId] = useState<string>("")
  const [processingStatus, setProcessingStatus] = useState<string>("")
  
  const {
    batches,
    mutate: refetchBatches,
    expandedBatchId,
    toggleBatch,
    showToast,
    setShowToast,
    generateDefaultBatchName,
  } = useBatchManagement()

  // Handle file selection (not uploading yet)
  const handleFilesSelected = (files: File[]) => {
    setSelectedFiles(files)
  }

  // Handle batch upload
  const handleUploadBatch = (batchName: string, analysisType: string, uploadedFiles: File[]) => {
    const newBatchId = Date.now().toString()

    const newBatch: Batch = {
      id: newBatchId,
      name: batchName || generateDefaultBatchName(),
      timestamp: new Date(),
      images: uploadedFiles.map(file => ({
        id: Date.now().toString() + Math.random().toString(36).substr(2, 9),
        name: file.name,
        url: URL.createObjectURL(file)
      })),
      status: "uploading",
      analysisType: analysisType
    }

    // Update local state and trigger refetch
    refetchBatches()
    setSelectedFiles([]) // Clear selected files after upload

    // simulateBatchProcessing(newBatchId)
  }

  // Simulate batch processing with status changes
  const simulateBatchProcessing = (batchId: string) => {
    // Simulate upload completion after 2 seconds
    setTimeout(() => {
      refetchBatches()
      // Simulate extraction completion after 3 more seconds
      setTimeout(() => {
        refetchBatches()
      }, 3000)
    }, 2000)
  }

  // Handle batch processing for temporary debugging
  const handleProcessBatch = async () => {
    if (!processingBatchId) {
      setProcessingStatus("Please enter a batch ID")
      console.log(`[DEBUG] Batch ID is empty. Please enter a valid batch ID.`) // Added debug printing statement for visibility
      return
    }

    try {
      setProcessingStatus("Processing batch...")
      console.log(`[DEBUG] Processing batch ID: ${processingBatchId}`) // Added debug printing statement for visibility
      
      // Use server action to process batch instead of direct client-side processing
      const response = await fetch('/api/process-batch', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ batchId: parseInt(processingBatchId) }),
      });
      
      console.log(`[DEBUG] Received response from /api/process-batch: ${response.status} ${response.statusText}`) // Added debug printing statement for visibility
      
      if (!response.ok) {
        const errorData = await response.json();
        console.log(`[DEBUG] Error response from /api/process-batch: ${errorData.message}`) // Added debug printing statement for visibility
        throw new Error(errorData.message || 'Failed to process batch');
      }
      
      setProcessingStatus("Processing request sent successfully")
      console.log(`[DEBUG] Processing request sent successfully. Refetching batches...`) // Added debug printing statement for visibility
      refetchBatches()
    } catch (error) {
      console.error("Error processing batch:", error)
      console.log(`[DEBUG] Error processing batch: ${error instanceof Error ? error.message : "Unknown error"}`) // Added debug printing statement for visibility
      setProcessingStatus(`Processing failed: ${error instanceof Error ? error.message : "Unknown error"}`)
    }
  }

  // Handle image selection from a batch
  const handleImageSelect = (batchId: string, imageIndex: number) => {
    setSelectedBatchId(batchId)
    setSelectedImageIndex(imageIndex)
    setCurrentView("annotation")
  }

  // Handle navigation back to upload interface
  const handleBackToUpload = () => {
    setSelectedBatchId(null)
    setSelectedImageIndex(null)
    setCurrentView("upload")
  }

  // Handle navigation between images in annotation view
  const handleNextImage = () => {
    const currentBatch = batches?.find((batch) => batch.id === selectedBatchId)
    if (selectedImageIndex !== null && currentBatch && selectedImageIndex < currentBatch.images.length - 1) {
      setSelectedImageIndex(selectedImageIndex + 1)
    }
  }

  const handlePreviousImage = () => {
    if (selectedImageIndex !== null && selectedImageIndex > 0) {
      setSelectedImageIndex(selectedImageIndex - 1)
    }
  }

  // Handle viewing results from a batch
  const handleViewResults = (batchId: string) => {
    const batch = batches?.find(b => b.id === batchId)
    if (batch && batch.images && batch.images.length > 0) {
      setSelectedBatchId(batchId)
      setSelectedImageIndex(0) // Start with the first image
      setCurrentView("annotation")
    }
  }

  return (
    <main className="min-h-screen bg-background">
          {/* Temporary Batch Processing Section */}
          <div className="max-w-screen-lg mx-auto p-4 mt-8 bg-card rounded-lg border border-border">
            <h2 className="text-xl font-bold mb-4">Temporary Batch Processing</h2>
            <div className="flex items-center gap-4 mb-2">
              <input
                type="text"
                value={processingBatchId}
                onChange={(e) => setProcessingBatchId(e.target.value)}
                placeholder="Enter batch ID"
                className="flex h-10 w-full rounded-md border border-input bg-background px-3 py-2 text-sm"
              />
              <button 
                onClick={handleProcessBatch}
                className="bg-primary text-primary-foreground hover:bg-primary/90 h-10 px-4 py-2 rounded-md"
              >
                Process Batch
              </button>
            </div>
            {processingStatus && (
              <div className="mt-2 text-sm">
                <p>{processingStatus}</p>
              </div>
            )}
          </div>

          
      {currentView === "upload" && (
        <>
          <UploadInterface
            selectedFiles={selectedFiles}
            onFilesSelected={handleFilesSelected}
            onUploadBatch={handleUploadBatch}
            onImageSelect={handleImageSelect}
            onViewResults={handleViewResults}
            onRefetchBatches={refetchBatches}
          />
          
        </>
      )}

      {currentView === "annotation" && selectedBatchId && selectedImageIndex !== null && (
        <AnnotationEditor
          image={batches?.find((batch) => batch.id === selectedBatchId)?.images[selectedImageIndex] ?? {
            id: "",
            name: "",
            url: ""
          }}
          onBack={handleBackToUpload}
          onNextImage={
            selectedImageIndex < (batches?.find((batch) => batch.id === selectedBatchId)?.images.length ?? 0) - 1
              ? handleNextImage
              : undefined
          }
          onPreviousImage={selectedImageIndex > 0 ? handlePreviousImage : undefined}
        />
      )}
    </main>
  )
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/annotation/annotation-canvas.tsx
================
import { useRef, useEffect, memo } from "react"
import React from "react"
import { LabelEditor } from "./label-editor"
import { BoxHandles } from "./box-handles"
import { BoundingBox } from "@/types/annotation"

interface ImageState {
  imageUrl: string
  scale: number
  imageRef: React.RefObject<HTMLImageElement>
  containerRef: React.RefObject<HTMLDivElement>
}

interface BoxControls {
  boundingBoxes: BoundingBox[]
  selectedBox: BoundingBox | null
  onSelect: (box: BoundingBox) => void
  onUpdate: (box: BoundingBox) => void
  onDelete: (id: number) => void
  onDeselect: () => void
}

interface LabelEditing {
    editingLabelId: number | null
    editingLabelText: string
    setEditingLabelId: (id: number | null) => void
    setEditingLabelText: (text: string) => void
    updateLabelAndFinishEditing: () => void
  }

interface InteractionHandlers {
  startDragging: (e: React.MouseEvent | React.TouchEvent, box: BoundingBox) => void
  startResizing: (e: React.MouseEvent | React.TouchEvent, box: BoundingBox, handle: string) => void
  dragState: {
    isDragging: boolean
    startX: number
    startY: number
    originalBox: BoundingBox | null
  }
  resizeState: {
    isResizing: boolean
    handle: string | null
    startX: number
    startY: number
    originalBox: BoundingBox | null
  }
}

// Memoized box component to prevent unnecessary re-renders
const Box = memo(({ 
  box, 
  isSelected, 
  onSelect, 
  startDragging, 
  startResizing,
  labelEditing
}: { 
  box: BoundingBox
  isSelected: boolean
  onSelect: (box: BoundingBox) => void
  startDragging: (e: React.MouseEvent | React.TouchEvent, box: BoundingBox) => void
  startResizing: (e: React.MouseEvent | React.TouchEvent, box: BoundingBox, handle: string) => void
  labelEditing: {
    editingLabelId: number | null
    editingLabelText: string
    setEditingLabelId: (id: number | null) => void
    setEditingLabelText: (text: string) => void
    updateLabelAndFinishEditing: () => void
  }
}) => {
  return (
    <div
      key={box.id}
      className={`absolute border-2 ${isSelected ? 'border-slate-700' : 'border-muted-foreground/50'} cursor-move border-dotted`}
      style={{
        left: `${box.x}px`,
        top: `${box.y}px`,
        width: `${box.width}px`,
        height: `${box.height}px`,
      }}
      onClick={(e) => {
        e.stopPropagation()
        onSelect(box)
      }}
      onMouseDown={(e) => startDragging(e, box)}
      onTouchStart={(e) => startDragging(e, box)}
    >
      <BoxHandles 
        box={box} 
        isSelected={isSelected} 
        startResizing={startResizing} 
      />
      <LabelEditor 
        box={box} 
        isSelected={isSelected}
        {...labelEditing}
      />
    </div>
  )
})

Box.displayName = 'Box'

interface AnnotationCanvasProps {
  imageState: ImageState
  boxControls: BoxControls
  labelEditing: LabelEditing
  interactionHandlers: InteractionHandlers
  isMobile: boolean
}

export function AnnotationCanvas({
  imageState,
  boxControls,
  labelEditing,
  interactionHandlers,
  isMobile
}: AnnotationCanvasProps) {
  const { imageUrl, scale, imageRef, containerRef } = imageState
  const { boundingBoxes, selectedBox, onSelect, onDeselect } = boxControls
  const { startDragging, startResizing } = interactionHandlers

  return (
    <div
      ref={containerRef}
      className="relative"
      style={{ transform: `scale(${scale})`, transformOrigin: 'top left' }}
    >
      <img
        ref={imageRef}
        src={imageUrl}
        alt="Annotation target"
        className="max-w-full h-auto"
        draggable={false}
      />
      {boundingBoxes.map((box) => (
        <Box
          key={box.id}
          box={box}
          isSelected={selectedBox?.id === box.id}
          onSelect={onSelect}
          startDragging={startDragging}
          startResizing={startResizing}
          labelEditing={labelEditing}
        />
      ))}
    </div>
  )
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/annotation/annotation-header.tsx
================
import { ArrowLeft, Save } from "lucide-react"
import { Button } from "@/components/ui/button"

interface AnnotationHeaderProps {
  imageName: string
  onBack: () => void
  onSave: () => void
}

export function AnnotationHeader({ imageName, onBack, onSave }: AnnotationHeaderProps) {
  return (
    <div className="bg-background p-4 border-b flex items-center justify-between">
      <Button variant="ghost" onClick={onBack}>
        <ArrowLeft className="mr-2 h-4 w-4" />
        <span className="hidden sm:inline">Back to Upload</span>
        <span className="sm:hidden">Back</span>
      </Button>
      <h2 className="text-xl font-medium truncate max-w-[150px] sm:max-w-none">{imageName}</h2>
      <Button onClick={onSave} className="hidden md:flex">
        <Save className="mr-2 h-4 w-4" />
        Save
      </Button>
    </div>
  )
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/annotation/box-handles.tsx
================
import React from "react"
import { BoundingBox } from "@/types/annotation"

interface BoxHandlesProps {
  box: BoundingBox
  isSelected: boolean
  startResizing: (e: React.MouseEvent | React.TouchEvent, box: BoundingBox, handle: string) => void
}

export function BoxHandles({ box, isSelected, startResizing }: BoxHandlesProps) {
  if (!isSelected) return null

  const handleSize = 8
  const handleStyle = {
    width: handleSize,
    height: handleSize,
    backgroundColor: "white",
    border: "2px solid #3b82f6",
    position: "absolute" as const,
    borderRadius: "50%",
    cursor: "pointer",
  }

  const handles = [
    { position: "top-left", x: -handleSize / 2, y: -handleSize / 2, cursor: "nw-resize" },
    { position: "top-right", x: box.width - handleSize / 2, y: -handleSize / 2, cursor: "ne-resize" },
    { position: "bottom-left", x: -handleSize / 2, y: box.height - handleSize / 2, cursor: "sw-resize" },
    { position: "bottom-right", x: box.width - handleSize / 2, y: box.height - handleSize / 2, cursor: "se-resize" },
    { position: "top", x: box.width / 2 - handleSize / 2, y: -handleSize / 2, cursor: "n-resize" },
    { position: "right", x: box.width - handleSize / 2, y: box.height / 2 - handleSize / 2, cursor: "e-resize" },
    { position: "bottom", x: box.width / 2 - handleSize / 2, y: box.height - handleSize / 2, cursor: "s-resize" },
    { position: "left", x: -handleSize / 2, y: box.height / 2 - handleSize / 2, cursor: "w-resize" },
  ]

  return (
    <>
      {handles.map(({ position, x, y, cursor }) => (
        <div
          key={position}
          style={{
            ...handleStyle,
            left: x,
            top: y,
            cursor,
          }}
          onMouseDown={(e) => startResizing(e, box, position)}
          onTouchStart={(e) => startResizing(e, box, position)}
        />
      ))}
    </>
  )
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/annotation/label-editor.tsx
================
import { useState, useEffect, useRef } from "react"
import { BoundingBox } from "@/types/annotation"

interface LabelEditorProps {
  box: BoundingBox
  isSelected: boolean
  editingLabelId: number | null
  editingLabelText: string
  setEditingLabelId: (id: number | null) => void
  setEditingLabelText: (text: string) => void
  updateLabelAndFinishEditing: () => void
}

export function LabelEditor({
  box,
  isSelected,
  editingLabelId,
  editingLabelText,
  setEditingLabelId,
  setEditingLabelText,
  updateLabelAndFinishEditing
}: LabelEditorProps) {
  const [isHovered, setIsHovered] = useState(false)
  const inputRef = useRef<HTMLInputElement>(null)
  const isEditing = editingLabelId === box.id

  // Focus input when editing starts
  useEffect(() => {
    if (isEditing && inputRef.current) {
      inputRef.current.focus()
    }
  }, [isEditing])

  const handleLabelClick = (e: React.MouseEvent) => {
    e.stopPropagation()
    if (!isEditing) {
      setEditingLabelId(box.id)
      setEditingLabelText(box.textLabel)
    }
  }

  const handleKeyDown = (e: React.KeyboardEvent) => {
    if (e.key === "Enter") {
      updateLabelAndFinishEditing()
    } else if (e.key === "Escape") {
      setEditingLabelId(null)
    }
  }

  const labelStyles = "bg-black text-white text-xs px-1 py-0.5 rounded"

  return (
    <div
      className="absolute -top-6 left-0 min-w-[60px] max-w-full"
      onMouseEnter={() => setIsHovered(true)}
      onMouseLeave={() => setIsHovered(false)}
      onClick={handleLabelClick}
    >
      {isEditing ? (
        <input
          ref={inputRef}
          type="text"
          value={editingLabelText}
          onChange={(e) => setEditingLabelText(e.target.value)}
          onKeyDown={handleKeyDown}
          onBlur={updateLabelAndFinishEditing}
          className={`${labelStyles} w-full outline-none border border-white`}
          placeholder="Enter label..."
        />
      ) : (
        <span className={`${labelStyles} pointer-events-auto cursor-text inline-block max-w-[200px] overflow-hidden text-ellipsis whitespace-nowrap`}>
          {box.textLabel}
        </span>
      )}
    </div>
  )
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/control-panel/control-panel-header.tsx
================
import { Clock } from "lucide-react"

interface ControlPanelHeaderProps {
  title: string
  masterPromptRuntime: number
  totalInferenceTime: number
}

export function ControlPanelHeader({ 
  title, 
  masterPromptRuntime, 
  totalInferenceTime 
}: ControlPanelHeaderProps) {
  return (
    <div className="p-4 border-b">
      <h3 className="text-lg font-medium">{title}</h3>
      <div className="mt-2 space-y-2">
        <div className="flex items-center justify-between">
          <div className="flex items-center text-sm">
            <Clock className="h-4 w-4 mr-1.5 text-muted-foreground" />
            <span>Master Prompt Runtime:</span>
          </div>
          <span className="font-medium">{masterPromptRuntime.toFixed(1)}s</span>
        </div>
        <div className="flex items-center justify-between">
          <div className="flex items-center text-sm">
            <Clock className="h-4 w-4 mr-1.5 text-muted-foreground" />
            <span>Total Inference Time:</span>
          </div>
          <span className="font-medium">{totalInferenceTime.toFixed(1)}s</span>
        </div>
      </div>
    </div>
  )
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/control-panel/element-editor.tsx
================
import { ArrowLeft, List, WandSparkles, Trash2 } from "lucide-react"
import { Button } from "@/components/ui/button"
import { Input } from "@/components/ui/input"
import { Label } from "@/components/ui/label"
import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from "@/components/ui/select"
import { ScrollArea } from "@/components/ui/scroll-area"
import { BoundingBox } from "@/types/annotation"

interface ElementEditorProps {
  selectedBox: BoundingBox
  onBoxUpdate: (box: BoundingBox) => void
  onBoxDelete: (id: number) => void
  onBackToList: () => void
  editingLabelState: {
    editingLabelId: number | null
    editingLabelText: string
    setEditingLabelText: (text: string) => void
    updateLabelAndFinishEditing: () => void
  }
}

export function ElementEditor({
  selectedBox,
  onBoxUpdate,
  onBoxDelete,
  onBackToList,
  editingLabelState
}: ElementEditorProps) {
  const handleLabelChange = (value: string) => {
    onBoxUpdate({ ...selectedBox, label: value })
  }

  const handleDescriptionChange = (value: string) => {
    onBoxUpdate({ ...selectedBox, description: value })
  }

  const handleCoordinateChange = (field: keyof BoundingBox, value: string) => {
    const numValue = Number.parseInt(value, 10)
    if (!isNaN(numValue)) {
      onBoxUpdate({ ...selectedBox, [field]: numValue })
    }
  }

  return (
    <>
      <div className="p-4 border-b">
        <div className="flex items-center justify-between mb-2">
          <h3 className="text-lg font-medium">Edit Element</h3>
          <Button variant="ghost" size="sm" onClick={onBackToList}>
            <ArrowLeft className="h-4 w-4 mr-1" />
            {/* <List className="h-4 w-4 mr-1" /> */}
            Back to Element List
          </Button>
        </div>
        <p className="text-sm text-muted-foreground">
          {`Editing "${selectedBox.textLabel}" (${selectedBox.label})`}
        </p>
      </div>

      <ScrollArea className={"flex-1"}>
        <div className="p-4 space-y-4">
          <div className="space-y-2">
            <Label htmlFor="element-type">Element Type</Label>
            <Select value={selectedBox.label} onValueChange={handleLabelChange}>
              <SelectTrigger id="element-type">
                <SelectValue placeholder="Select element type" />
              </SelectTrigger>
              <SelectContent>
                <SelectItem value="Button">Button</SelectItem>
                <SelectItem value="Tab Bar">Tab Bar</SelectItem>
                <SelectItem value="Text Field">Text Field</SelectItem>
                <SelectItem value="Checkbox">Checkbox</SelectItem>
                <SelectItem value="Dropdown">Dropdown</SelectItem>
                <SelectItem value="Image">Image</SelectItem>
                <SelectItem value="Icon">Icon</SelectItem>
                <SelectItem value="Label">Label</SelectItem>
              </SelectContent>
            </Select>
          </div>

          <div className="space-y-2">
            <Label htmlFor="text-label">Text Label</Label>
            {/* <Input
              id="text-label"
              value={editingLabelState.editingLabelText}
              onChange={(e) => editingLabelState.setEditingLabelText(e.target.value)}
              onBlur={editingLabelState.updateLabelAndFinishEditing}
              placeholder="Enter display text"
            /> */}
            <Input
              id="text-label"
              value={selectedBox.textLabel}
              readOnly
              disabled
              placeholder="Enter display text"
            />
          </div>

          <div className="space-y-2">
            <Label htmlFor="description">Description</Label>
            <Input
              id="description"
              value={selectedBox.description}
              onChange={(e) => handleDescriptionChange(e.target.value)}
              placeholder="Enter description"
            />
          </div>

          <div className="space-y-2">
            <Label htmlFor="inference-time">Inference Time</Label>
            <Input
              id="inference-time"
              value={`${selectedBox.inferenceTime.toFixed(2)}s`}
              readOnly
              disabled
              className="bg-muted"
            />
          </div>

          <div className="grid grid-cols-2 gap-2">
            <div className="space-y-2">
              <Label htmlFor="x-coord">X Position</Label>
              <Input
                id="x-coord"
                type="number"
                value={selectedBox.x}
                onChange={(e) => handleCoordinateChange("x", e.target.value)}
              />
            </div>
            <div className="space-y-2">
              <Label htmlFor="y-coord">Y Position</Label>
              <Input
                id="y-coord"
                type="number"
                value={selectedBox.y}
                onChange={(e) => handleCoordinateChange("y", e.target.value)}
              />
            </div>
            <div className="space-y-2">
              <Label htmlFor="width">Width</Label>
              <Input
                id="width"
                type="number"
                value={selectedBox.width}
                onChange={(e) => handleCoordinateChange("width", e.target.value)}
              />
            </div>
            <div className="space-y-2">
              <Label htmlFor="height">Height</Label>
              <Input
                id="height"
                type="number"
                value={selectedBox.height}
                onChange={(e) => handleCoordinateChange("height", e.target.value)}
              />
            </div>
          </div>
        </div>
      </ScrollArea>

      <div className="border-t p-4">
        {/* <Button className="w-full mb-3" variant="outline" onClick={() => onBoxDelete(selectedBox.id)}>
          <Trash2 className="mr-2 h-4 w-4" />
          Delete Element
        </Button> */}
        <Button className="w-full mb-3" variant="outline">
          <WandSparkles className="mr-2 h-4 w-4" />
          Regenerate Description and Label
        </Button>
        <Button className="w-full" onClick={onBackToList}>
          <ArrowLeft className="mr-2 h-4 w-4" />
          Back to Element List
        </Button>
      </div>
    </>
  )
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/control-panel/element-list.tsx
================
import { Trash2, Eye, Clock } from "lucide-react"
import { Button } from "@/components/ui/button"
import { ScrollArea } from "@/components/ui/scroll-area"
import { BoundingBox } from "@/types/annotation"
import { RevealOnHover } from "@/components/ui/reveal-on-hover"

interface ElementListProps {
  boundingBoxes: BoundingBox[]
  selectedBox: BoundingBox | null
  hoveredBoxId: number | null
  setHoveredBoxId: (id: number | null) => void
  onBoxSelect: (box: BoundingBox) => void
  onBoxDelete: (id: number) => void
  // isMobile: boolean
  // setActiveTab?: (tab: string) => void
}

export function ElementList({
  boundingBoxes,
  selectedBox,
  hoveredBoxId,
  setHoveredBoxId,
  onBoxSelect,
  onBoxDelete,
  // isMobile,
  // setActiveTab
}: ElementListProps) {
  const handleElementSelect = (box: BoundingBox) => {
    onBoxSelect(box)
    // if (isMobile && setActiveTab) {
    //   setActiveTab("editor")
    // }
  }

  const getBorderClass = (box: BoundingBox) => {
    // if (isMobile) {
    //   return selectedBox?.id === box.id ? "border-primary" : "border-border"
    // }
    return hoveredBoxId === box.id ? "border-primary/50" : "border-border"
  }

  const renderBoxDetails = (box: BoundingBox) => (
    <RevealOnHover isVisible={hoveredBoxId === box.id}>
      <div className="text-xs text-muted-foreground">{box.label}</div>
      <div className="text-xs text-muted-foreground mt-1">
        x: {box.x}, y: {box.y}, w: {box.width}, h: {box.height}
      </div>
      <div className="text-xs flex items-center mt-1 text-muted-foreground">
        <Clock className="h-3 w-3 mr-1" />
        Inference Time: {box.inferenceTime.toFixed(2)}s
      </div>
    </RevealOnHover>
  )

  const renderActionButtons = (box: BoundingBox) => (
    <div className="flex gap-1 ml-2">
      <Button
        variant="ghost"
        size="icon"
        className="h-7 w-7"
        onClick={(e) => {
          e.stopPropagation()
          handleElementSelect(box)
        }}
      >
        <Eye className="h-4 w-4" />
      </Button>
      <Button
        variant="ghost"
        size="icon"
        className="h-7 w-7 text-destructive"
        onClick={(e) => {
          e.stopPropagation()
          onBoxDelete(box.id)
        }}
      >
        <Trash2 className="h-4 w-4" />
      </Button>
    </div>
  )

  return (
    <ScrollArea className="flex-1">
      <div className="p-4 space-y-2">
        {boundingBoxes.map((box) => (
          <div
            key={box.id}
            className={`rounded-md border transition-all duration-200 overflow-hidden ${getBorderClass(box)}`}
            onMouseEnter={() => setHoveredBoxId(box.id)}
            onMouseLeave={() => setHoveredBoxId(null)}
            onClick={() => handleElementSelect(box)}
          >
            <div className="p-3">
              <div className="flex items-center justify-between">
                <div className="font-medium truncate">{box.textLabel}</div>
                {hoveredBoxId === box.id && renderActionButtons(box)}
              </div>

              {renderBoxDetails(box)}
            </div>
          </div>
        ))}
      </div>
    </ScrollArea>
  )
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/control-panel/panel-footer-actions.tsx
================
import { ArrowLeft, ArrowRight, Save, Download } from "lucide-react"
import { Button } from "@/components/ui/button"

interface PanelFooterActionsProps {
  onSave: () => void
  onExport: () => void
  onPreviousImage?: () => void
  onNextImage?: () => void
}

export function PanelFooterActions({
  onSave,
  onExport,
  onPreviousImage,
  onNextImage
}: PanelFooterActionsProps) {
  return (
    <div className="border-t p-4">
      <div className="grid grid-cols-2 gap-2 mb-3">
        <Button variant="outline" className="w-full" onClick={onPreviousImage} disabled={!onPreviousImage}>
          <ArrowLeft className="mr-2 h-4 w-4" />
          {onPreviousImage ? "Previous" : "Prev Image"}
        </Button>
        <Button variant="outline" className="w-full" onClick={onNextImage} disabled={!onNextImage}>
          {onNextImage ? "Next" : "Next Image"}
          <ArrowRight className="ml-2 h-4 w-4" />
        </Button>
      </div>
      <Button className="w-full mb-2" onClick={onSave}>
        <Save className="mr-2 h-4 w-4" />
        Save Changes
      </Button>
      <Button className="w-full" variant="secondary" onClick={onExport}>
        <Download className="mr-2 h-4 w-4" />
        Export Annotations
      </Button>
    </div>
  )
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/control-panel/summary-panel.tsx
================
import { Clock } from "lucide-react"
import { ScrollArea } from "@/components/ui/scroll-area"
import { Separator } from "@/components/ui/separator"

interface SummaryPanelProps {
  masterPromptRuntime: number
  totalInferenceTime: number
  elementCount: number
}

export function SummaryPanel({ masterPromptRuntime, totalInferenceTime, elementCount }: SummaryPanelProps) {
  const averageInferenceTime = elementCount > 0 ? totalInferenceTime / elementCount : 0

  return (
    <ScrollArea className="h-[calc(100vh-220px)]">
      <div className="p-4 space-y-4">
        <div className="space-y-2">
          <h3 className="text-lg font-medium">Performance Summary</h3>
          <div className="mt-2 space-y-2">
            <div className="flex items-center justify-between">
              <div className="flex items-center text-sm">
                <Clock className="h-4 w-4 mr-1.5 text-muted-foreground" />
                <span>Master Prompt Runtime:</span>
              </div>
              <span className="font-medium">{masterPromptRuntime.toFixed(1)}s</span>
            </div>
            <div className="flex items-center justify-between">
              <div className="flex items-center text-sm">
                <Clock className="h-4 w-4 mr-1.5 text-muted-foreground" />
                <span>Total Inference Time:</span>
              </div>
              <span className="font-medium">{totalInferenceTime.toFixed(1)}s</span>
            </div>
          </div>
        </div>

        <Separator />

        <div className="space-y-2">
          <h3 className="text-lg font-medium">Element Statistics</h3>
          <div className="text-sm">
            <p>Total Elements: {elementCount}</p>
            <p>Average Inference Time: {averageInferenceTime.toFixed(2)}s</p>
          </div>
        </div>
      </div>
    </ScrollArea>
  )
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/ui/badge.tsx
================
import * as React from "react"
import { Slot } from "@radix-ui/react-slot"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "@/lib/utils"

const badgeVariants = cva(
  "inline-flex items-center justify-center rounded-md border px-2 py-0.5 text-xs font-medium w-fit whitespace-nowrap shrink-0 [&>svg]:size-3 gap-1 [&>svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden",
  {
    variants: {
      variant: {
        default:
          "border-transparent bg-primary text-primary-foreground [a&]:hover:bg-primary/90",
        secondary:
          "border-transparent bg-secondary text-secondary-foreground [a&]:hover:bg-secondary/90",
        destructive:
          "border-transparent bg-destructive text-white [a&]:hover:bg-destructive/90 focus-visible:ring-destructive/20 dark:focus-visible:ring-destructive/40 dark:bg-destructive/60",
        outline:
          "text-foreground [a&]:hover:bg-accent [a&]:hover:text-accent-foreground",
      },
    },
    defaultVariants: {
      variant: "default",
    },
  }
)

function Badge({
  className,
  variant,
  asChild = false,
  ...props
}: React.ComponentProps<"span"> &
  VariantProps<typeof badgeVariants> & { asChild?: boolean }) {
  const Comp = asChild ? Slot : "span"

  return (
    <Comp
      data-slot="badge"
      className={cn(badgeVariants({ variant }), className)}
      {...props}
    />
  )
}

export { Badge, badgeVariants }

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/ui/button.tsx
================
import * as React from "react"
import { Slot } from "@radix-ui/react-slot"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "@/lib/utils"

const buttonVariants = cva(
  "inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive",
  {
    variants: {
      variant: {
        default:
          "bg-primary text-primary-foreground shadow-xs hover:bg-primary/90",
        destructive:
          "bg-destructive text-white shadow-xs hover:bg-destructive/90 focus-visible:ring-destructive/20 dark:focus-visible:ring-destructive/40 dark:bg-destructive/60",
        outline:
          "border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50",
        secondary:
          "bg-secondary text-secondary-foreground shadow-xs hover:bg-secondary/80",
        ghost:
          "hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50",
        link: "text-primary underline-offset-4 hover:underline",
      },
      size: {
        default: "h-9 px-4 py-2 has-[>svg]:px-3",
        sm: "h-8 rounded-md gap-1.5 px-3 has-[>svg]:px-2.5",
        lg: "h-10 rounded-md px-6 has-[>svg]:px-4",
        icon: "size-9",
      },
    },
    defaultVariants: {
      variant: "default",
      size: "default",
    },
  }
)

function Button({
  className,
  variant,
  size,
  asChild = false,
  ...props
}: React.ComponentProps<"button"> &
  VariantProps<typeof buttonVariants> & {
    asChild?: boolean
  }) {
  const Comp = asChild ? Slot : "button"

  return (
    <Comp
      data-slot="button"
      className={cn(buttonVariants({ variant, size, className }))}
      {...props}
    />
  )
}

export { Button, buttonVariants }

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/ui/card.tsx
================
import * as React from "react"

import { cn } from "@/lib/utils"

function Card({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="card"
      className={cn(
        "bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm",
        className
      )}
      {...props}
    />
  )
}

function CardHeader({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="card-header"
      className={cn(
        "@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-1.5 px-6 has-data-[slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6",
        className
      )}
      {...props}
    />
  )
}

function CardTitle({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="card-title"
      className={cn("leading-none font-semibold", className)}
      {...props}
    />
  )
}

function CardDescription({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="card-description"
      className={cn("text-muted-foreground text-sm", className)}
      {...props}
    />
  )
}

function CardAction({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="card-action"
      className={cn(
        "col-start-2 row-span-2 row-start-1 self-start justify-self-end",
        className
      )}
      {...props}
    />
  )
}

function CardContent({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="card-content"
      className={cn("px-6", className)}
      {...props}
    />
  )
}

function CardFooter({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="card-footer"
      className={cn("flex items-center px-6 [.border-t]:pt-6", className)}
      {...props}
    />
  )
}

export {
  Card,
  CardHeader,
  CardFooter,
  CardTitle,
  CardAction,
  CardDescription,
  CardContent,
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/ui/input.tsx
================
import * as React from "react"

import { cn } from "@/lib/utils"

function Input({ className, type, ...props }: React.ComponentProps<"input">) {
  return (
    <input
      type={type}
      data-slot="input"
      className={cn(
        "file:text-foreground placeholder:text-muted-foreground selection:bg-primary selection:text-primary-foreground dark:bg-input/30 border-input flex h-9 w-full min-w-0 rounded-md border bg-transparent px-3 py-1 text-base shadow-xs transition-[color,box-shadow] outline-none file:inline-flex file:h-7 file:border-0 file:bg-transparent file:text-sm file:font-medium disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 md:text-sm",
        "focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px]",
        "aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive",
        className
      )}
      {...props}
    />
  )
}

export { Input }

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/ui/label.tsx
================
"use client"

import * as React from "react"
import * as LabelPrimitive from "@radix-ui/react-label"

import { cn } from "@/lib/utils"

function Label({
  className,
  ...props
}: React.ComponentProps<typeof LabelPrimitive.Root>) {
  return (
    <LabelPrimitive.Root
      data-slot="label"
      className={cn(
        "flex items-center gap-2 text-sm leading-none font-medium select-none group-data-[disabled=true]:pointer-events-none group-data-[disabled=true]:opacity-50 peer-disabled:cursor-not-allowed peer-disabled:opacity-50",
        className
      )}
      {...props}
    />
  )
}

export { Label }

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/ui/reveal-on-hover.tsx
================
import React from "react"
import { cn } from "@/lib/utils"

interface RevealOnHoverProps {
  isVisible: boolean
  children: React.ReactNode
  className?: string
  duration?: string
  visibleHeight?: string
  visibleMargin?: string
}

export function RevealOnHover({
  isVisible,
  children,
  className,
  duration = "duration-200",
  visibleHeight = "max-h-20",
  visibleMargin = "mt-2",
}: RevealOnHoverProps) {
  return (
    <div
      className={cn(
        "overflow-hidden transition-all",
        duration,
        isVisible ? `${visibleHeight} ${visibleMargin} opacity-100` : "max-h-0 opacity-0",
        className
      )}
    >
      {children}
    </div>
  )
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/ui/scroll-area.tsx
================
"use client"

import * as React from "react"
import * as ScrollAreaPrimitive from "@radix-ui/react-scroll-area"

import { cn } from "@/lib/utils"

function ScrollArea({
  className,
  children,
  ...props
}: React.ComponentProps<typeof ScrollAreaPrimitive.Root>) {
  return (
    <ScrollAreaPrimitive.Root
      data-slot="scroll-area"
      className={cn("relative", className)}
      {...props}
    >
      <ScrollAreaPrimitive.Viewport
        data-slot="scroll-area-viewport"
        className="focus-visible:ring-ring/50 size-full rounded-[inherit] transition-[color,box-shadow] outline-none focus-visible:ring-[3px] focus-visible:outline-1"
      >
        {children}
      </ScrollAreaPrimitive.Viewport>
      <ScrollBar />
      <ScrollAreaPrimitive.Corner />
    </ScrollAreaPrimitive.Root>
  )
}

function ScrollBar({
  className,
  orientation = "vertical",
  ...props
}: React.ComponentProps<typeof ScrollAreaPrimitive.ScrollAreaScrollbar>) {
  return (
    <ScrollAreaPrimitive.ScrollAreaScrollbar
      data-slot="scroll-area-scrollbar"
      orientation={orientation}
      className={cn(
        "flex touch-none p-px transition-colors select-none",
        orientation === "vertical" &&
          "h-full w-2.5 border-l border-l-transparent",
        orientation === "horizontal" &&
          "h-2.5 flex-col border-t border-t-transparent",
        className
      )}
      {...props}
    >
      <ScrollAreaPrimitive.ScrollAreaThumb
        data-slot="scroll-area-thumb"
        className="bg-border relative flex-1 rounded-full"
      />
    </ScrollAreaPrimitive.ScrollAreaScrollbar>
  )
}

export { ScrollArea, ScrollBar }

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/ui/select.tsx
================
"use client"

import * as React from "react"
import * as SelectPrimitive from "@radix-ui/react-select"
import { CheckIcon, ChevronDownIcon, ChevronUpIcon } from "lucide-react"

import { cn } from "@/lib/utils"

function Select({
  ...props
}: React.ComponentProps<typeof SelectPrimitive.Root>) {
  return <SelectPrimitive.Root data-slot="select" {...props} />
}

function SelectGroup({
  ...props
}: React.ComponentProps<typeof SelectPrimitive.Group>) {
  return <SelectPrimitive.Group data-slot="select-group" {...props} />
}

function SelectValue({
  ...props
}: React.ComponentProps<typeof SelectPrimitive.Value>) {
  return <SelectPrimitive.Value data-slot="select-value" {...props} />
}

function SelectTrigger({
  className,
  size = "default",
  children,
  ...props
}: React.ComponentProps<typeof SelectPrimitive.Trigger> & {
  size?: "sm" | "default"
}) {
  return (
    <SelectPrimitive.Trigger
      data-slot="select-trigger"
      data-size={size}
      className={cn(
        "border-input data-[placeholder]:text-muted-foreground [&_svg:not([class*='text-'])]:text-muted-foreground focus-visible:border-ring focus-visible:ring-ring/50 aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive dark:bg-input/30 dark:hover:bg-input/50 flex w-fit items-center justify-between gap-2 rounded-md border bg-transparent px-3 py-2 text-sm whitespace-nowrap shadow-xs transition-[color,box-shadow] outline-none focus-visible:ring-[3px] disabled:cursor-not-allowed disabled:opacity-50 data-[size=default]:h-9 data-[size=sm]:h-8 *:data-[slot=select-value]:line-clamp-1 *:data-[slot=select-value]:flex *:data-[slot=select-value]:items-center *:data-[slot=select-value]:gap-2 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className
      )}
      {...props}
    >
      {children}
      <SelectPrimitive.Icon asChild>
        <ChevronDownIcon className="size-4 opacity-50" />
      </SelectPrimitive.Icon>
    </SelectPrimitive.Trigger>
  )
}

function SelectContent({
  className,
  children,
  position = "popper",
  ...props
}: React.ComponentProps<typeof SelectPrimitive.Content>) {
  return (
    <SelectPrimitive.Portal>
      <SelectPrimitive.Content
        data-slot="select-content"
        className={cn(
          "bg-popover text-popover-foreground data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 relative z-50 max-h-(--radix-select-content-available-height) min-w-[8rem] origin-(--radix-select-content-transform-origin) overflow-x-hidden overflow-y-auto rounded-md border shadow-md",
          position === "popper" &&
            "data-[side=bottom]:translate-y-1 data-[side=left]:-translate-x-1 data-[side=right]:translate-x-1 data-[side=top]:-translate-y-1",
          className
        )}
        position={position}
        {...props}
      >
        <SelectScrollUpButton />
        <SelectPrimitive.Viewport
          className={cn(
            "p-1",
            position === "popper" &&
              "h-[var(--radix-select-trigger-height)] w-full min-w-[var(--radix-select-trigger-width)] scroll-my-1"
          )}
        >
          {children}
        </SelectPrimitive.Viewport>
        <SelectScrollDownButton />
      </SelectPrimitive.Content>
    </SelectPrimitive.Portal>
  )
}

function SelectLabel({
  className,
  ...props
}: React.ComponentProps<typeof SelectPrimitive.Label>) {
  return (
    <SelectPrimitive.Label
      data-slot="select-label"
      className={cn("text-muted-foreground px-2 py-1.5 text-xs", className)}
      {...props}
    />
  )
}

function SelectItem({
  className,
  children,
  ...props
}: React.ComponentProps<typeof SelectPrimitive.Item>) {
  return (
    <SelectPrimitive.Item
      data-slot="select-item"
      className={cn(
        "focus:bg-accent focus:text-accent-foreground [&_svg:not([class*='text-'])]:text-muted-foreground relative flex w-full cursor-default items-center gap-2 rounded-sm py-1.5 pr-8 pl-2 text-sm outline-hidden select-none data-[disabled]:pointer-events-none data-[disabled]:opacity-50 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4 *:[span]:last:flex *:[span]:last:items-center *:[span]:last:gap-2",
        className
      )}
      {...props}
    >
      <span className="absolute right-2 flex size-3.5 items-center justify-center">
        <SelectPrimitive.ItemIndicator>
          <CheckIcon className="size-4" />
        </SelectPrimitive.ItemIndicator>
      </span>
      <SelectPrimitive.ItemText>{children}</SelectPrimitive.ItemText>
    </SelectPrimitive.Item>
  )
}

function SelectSeparator({
  className,
  ...props
}: React.ComponentProps<typeof SelectPrimitive.Separator>) {
  return (
    <SelectPrimitive.Separator
      data-slot="select-separator"
      className={cn("bg-border pointer-events-none -mx-1 my-1 h-px", className)}
      {...props}
    />
  )
}

function SelectScrollUpButton({
  className,
  ...props
}: React.ComponentProps<typeof SelectPrimitive.ScrollUpButton>) {
  return (
    <SelectPrimitive.ScrollUpButton
      data-slot="select-scroll-up-button"
      className={cn(
        "flex cursor-default items-center justify-center py-1",
        className
      )}
      {...props}
    >
      <ChevronUpIcon className="size-4" />
    </SelectPrimitive.ScrollUpButton>
  )
}

function SelectScrollDownButton({
  className,
  ...props
}: React.ComponentProps<typeof SelectPrimitive.ScrollDownButton>) {
  return (
    <SelectPrimitive.ScrollDownButton
      data-slot="select-scroll-down-button"
      className={cn(
        "flex cursor-default items-center justify-center py-1",
        className
      )}
      {...props}
    >
      <ChevronDownIcon className="size-4" />
    </SelectPrimitive.ScrollDownButton>
  )
}

export {
  Select,
  SelectContent,
  SelectGroup,
  SelectItem,
  SelectLabel,
  SelectScrollDownButton,
  SelectScrollUpButton,
  SelectSeparator,
  SelectTrigger,
  SelectValue,
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/ui/separator.tsx
================
"use client"

import * as React from "react"
import * as SeparatorPrimitive from "@radix-ui/react-separator"

import { cn } from "@/lib/utils"

function Separator({
  className,
  orientation = "horizontal",
  decorative = true,
  ...props
}: React.ComponentProps<typeof SeparatorPrimitive.Root>) {
  return (
    <SeparatorPrimitive.Root
      data-slot="separator-root"
      decorative={decorative}
      orientation={orientation}
      className={cn(
        "bg-border shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px",
        className
      )}
      {...props}
    />
  )
}

export { Separator }

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/ui/tabs.tsx
================
"use client"

import * as React from "react"
import * as TabsPrimitive from "@radix-ui/react-tabs"

import { cn } from "@/lib/utils"

function Tabs({
  className,
  ...props
}: React.ComponentProps<typeof TabsPrimitive.Root>) {
  return (
    <TabsPrimitive.Root
      data-slot="tabs"
      className={cn("flex flex-col gap-2", className)}
      {...props}
    />
  )
}

function TabsList({
  className,
  ...props
}: React.ComponentProps<typeof TabsPrimitive.List>) {
  return (
    <TabsPrimitive.List
      data-slot="tabs-list"
      className={cn(
        "bg-muted text-muted-foreground inline-flex h-9 w-fit items-center justify-center rounded-lg p-[3px]",
        className
      )}
      {...props}
    />
  )
}

function TabsTrigger({
  className,
  ...props
}: React.ComponentProps<typeof TabsPrimitive.Trigger>) {
  return (
    <TabsPrimitive.Trigger
      data-slot="tabs-trigger"
      className={cn(
        "data-[state=active]:bg-background dark:data-[state=active]:text-foreground focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:outline-ring dark:data-[state=active]:border-input dark:data-[state=active]:bg-input/30 text-foreground dark:text-muted-foreground inline-flex h-[calc(100%-1px)] flex-1 items-center justify-center gap-1.5 rounded-md border border-transparent px-2 py-1 text-sm font-medium whitespace-nowrap transition-[color,box-shadow] focus-visible:ring-[3px] focus-visible:outline-1 disabled:pointer-events-none disabled:opacity-50 data-[state=active]:shadow-sm [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className
      )}
      {...props}
    />
  )
}

function TabsContent({
  className,
  ...props
}: React.ComponentProps<typeof TabsPrimitive.Content>) {
  return (
    <TabsPrimitive.Content
      data-slot="tabs-content"
      className={cn("flex-1 outline-none", className)}
      {...props}
    />
  )
}

export { Tabs, TabsList, TabsTrigger, TabsContent }

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/ui/toast.tsx
================
import * as React from "react"
import * as ToastPrimitives from "@radix-ui/react-toast"
import { cva, type VariantProps } from "class-variance-authority"
import { cn } from "@/lib/utils"

const ToastProvider = ToastPrimitives.Provider
const ToastViewport = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Viewport>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Viewport>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Viewport
    ref={ref}
    className={cn(
      "fixed top-0 z-[100] flex max-h-screen w-full flex-col-reverse p-4 sm:bottom-0 sm:right-0 sm:top-auto sm:flex-col md:max-w-[420px]",
      className
    )}
    {...props}
  />
))
ToastViewport.displayName = ToastPrimitives.Viewport.displayName

const toastVariants = cva(
  "group pointer-events-auto relative flex w-full items-center justify-between space-x-4 overflow-hidden rounded-md border p-6 pr-8 shadow-lg transition-all data-[swipe=cancel]:translate-x-0 data-[swipe=end]:translate-x-[var(--radix-toast-swipe-end-x)] data-[swipe=move]:translate-x-[var(--radix-toast-swipe-move-x)] data-[swipe=move]:transition-none data-[state=open]:animate-in data-[state=closed]:animate-out data-[swipe=end]:animate-out data-[state=closed]:fade-out-80 data-[state=closed]:slide-out-to-right-full data-[state=open]:slide-in-from-top-full data-[state=open]:sm:slide-in-from-bottom-full",
  {
    variants: {
      variant: {
        default: "border bg-background text-foreground",
        destructive:
          "destructive group border-destructive bg-destructive text-destructive-foreground",
      },
    },
    defaultVariants: {
      variant: "default",
    },
  }
)

const Toast = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Root>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Root> &
    VariantProps<typeof toastVariants>
>(({ className, variant, ...props }, ref) => {
  return (
    <ToastPrimitives.Root
      ref={ref}
      className={cn(toastVariants({ variant }), className)}
      {...props}
    />
  )
})
Toast.displayName = ToastPrimitives.Root.displayName

const ToastAction = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Action>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Action>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Action
    ref={ref}
    className={cn(
      "inline-flex h-8 shrink-0 items-center justify-center rounded-md border bg-transparent px-3 text-sm font-medium ring-offset-background transition-colors hover:bg-secondary focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 group-[.destructive]:border-muted/40 group-[.destructive]:hover:border-destructive/30 group-[.destructive]:hover:bg-destructive group-[.destructive]:hover:text-destructive-foreground group-[.destructive]:focus:ring-destructive",
      className
    )}
    {...props}
  />
))
ToastAction.displayName = ToastPrimitives.Action.displayName

const ToastClose = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Close>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Close>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Close
    ref={ref}
    className={cn(
      "absolute right-2 top-2 rounded-md p-1 text-foreground/50 opacity-0 transition-opacity hover:text-foreground focus:opacity-100 focus:outline-none focus:ring-2 group-hover:opacity-100 group-[.destructive]:text-red-300 group-[.destructive]:hover:text-red-50 group-[.destructive]:focus:ring-red-400 group-[.destructive]:focus:ring-offset-red-600",
      className
    )}
    toast-close=""
    {...props}
  >
    <span className="sr-only">Close</span>
    <svg
      xmlns="http://www.w3.org/2000/svg"
      width="16"
      height="16"
      viewBox="0 0 24 24"
      fill="none"
      stroke="currentColor"
      strokeWidth="2"
      strokeLinecap="round"
      strokeLinejoin="round"
    >
      <line x1="18" y1="6" x2="6" y2="18"></line>
      <line x1="6" y1="6" x2="18" y2="18"></line>
    </svg>
  </ToastPrimitives.Close>
))
ToastClose.displayName = ToastPrimitives.Close.displayName

const ToastTitle = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Title>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Title>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Title
    ref={ref}
    className={cn("text-sm font-semibold", className)}
    {...props}
  />
))
ToastTitle.displayName = ToastPrimitives.Title.displayName

const ToastDescription = React.forwardRef<
  React.ElementRef<typeof ToastPrimitives.Description>,
  React.ComponentPropsWithoutRef<typeof ToastPrimitives.Description>
>(({ className, ...props }, ref) => (
  <ToastPrimitives.Description
    ref={ref}
    className={cn("text-sm opacity-90", className)}
    {...props}
  />
))
ToastDescription.displayName = ToastPrimitives.Description.displayName

type ToastProps = React.ComponentPropsWithoutRef<typeof Toast>

type ToastActionElement = React.ReactElement<typeof ToastAction>

export {
  type ToastProps,
  type ToastActionElement,
  ToastProvider,
  ToastViewport,
  Toast,
  ToastTitle,
  ToastDescription,
  ToastClose,
  ToastAction,
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/ui/tooltip.tsx
================
"use client"

import * as React from "react"
import * as TooltipPrimitive from "@radix-ui/react-tooltip"

import { cn } from "@/lib/utils"

function TooltipProvider({
  delayDuration = 0,
  ...props
}: React.ComponentProps<typeof TooltipPrimitive.Provider>) {
  return (
    <TooltipPrimitive.Provider
      data-slot="tooltip-provider"
      delayDuration={delayDuration}
      {...props}
    />
  )
}

function Tooltip({
  ...props
}: React.ComponentProps<typeof TooltipPrimitive.Root>) {
  return (
    <TooltipProvider>
      <TooltipPrimitive.Root data-slot="tooltip" {...props} />
    </TooltipProvider>
  )
}

function TooltipTrigger({
  ...props
}: React.ComponentProps<typeof TooltipPrimitive.Trigger>) {
  return <TooltipPrimitive.Trigger data-slot="tooltip-trigger" {...props} />
}

function TooltipContent({
  className,
  sideOffset = 0,
  children,
  ...props
}: React.ComponentProps<typeof TooltipPrimitive.Content>) {
  return (
    <TooltipPrimitive.Portal>
      <TooltipPrimitive.Content
        data-slot="tooltip-content"
        sideOffset={sideOffset}
        className={cn(
          "bg-primary text-primary-foreground animate-in fade-in-0 zoom-in-95 data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=closed]:zoom-out-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 z-50 w-fit origin-(--radix-tooltip-content-transform-origin) rounded-md px-3 py-1.5 text-xs text-balance",
          className
        )}
        {...props}
      >
        {children}
        <TooltipPrimitive.Arrow className="bg-primary fill-primary z-50 size-2.5 translate-y-[calc(-50%_-_2px)] rotate-45 rounded-[2px]" />
      </TooltipPrimitive.Content>
    </TooltipPrimitive.Portal>
  )
}

export { Tooltip, TooltipTrigger, TooltipContent, TooltipProvider }

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/upload/batch-card/batch-header.tsx
================
import { Button } from "@/components/ui/button";
import { FileImage, ChevronUp, ChevronDown, ClipboardCheck, ExternalLink } from "lucide-react";
import { StatusBadge } from "./status-badge";
import { PerformanceTooltip } from "./performance-tooltip";
import type { Batch } from "@/types/batch_v1";

interface BatchHeaderProps {
  batch: Batch;
  isExpanded: boolean;
  onToggle: () => void;
  onViewResults: (batchId: string) => void;
}

export const BatchHeader = ({ batch, isExpanded, onToggle, onViewResults }: BatchHeaderProps) => (
  <div className="flex-1">
    <div className="flex items-center justify-between mb-1">
      <h3 className="font-medium">{batch.name}</h3>
      <div className="flex items-center gap-2">
        <StatusBadge status={batch.status} />
        {/* {batch.status === 'extracting' && (
          <Button 
            variant="outline" 
            size="default" 
            className="flex items-center gap-1 h-6 px-2"
            onClick={(e) => {
              e.stopPropagation();
              onViewResults(batch.id);
            }}
          >
            <ExternalLink className="h-3 w-3" />
            <span className="text-xs">View Result</span>
          </Button>
        )} */}

          <Button 
            variant="outline" 
            size="default" 
            className="flex items-center gap-1 h-6 px-2"
            onClick={(e) => {
              e.stopPropagation();
              onViewResults(batch.id);
            }}
          >
            <ExternalLink className="h-3 w-3" />
            <span className="text-xs">View Result</span>
          </Button>   
        <Button 
          variant="ghost" 
          size="icon" 
          className="flex items-center gap-1 h-6 px-2"
          onClick={onToggle}
        >
          {isExpanded ? <ChevronUp className="h-3 w-3" /> : <ChevronDown className="h-3 w-3" />}
        </Button>
      </div>
    </div>
    <div className="flex flex-wrap items-center text-sm text-muted-foreground mt-1">
      <div className="flex items-center gap-2 mr-4">
        <FileImage className="h-4 w-4" />
        {batch.images.length} {batch.images.length === 1 ? "image" : "images"}
      </div>
      {batch.analysisType && (
        <div className="flex items-center gap-2 mr-4">
          <ClipboardCheck className="h-4 w-4" />
          <span>{batch.analysisType}</span>
        </div>
      )}
      {batch.performance && <PerformanceTooltip performance={batch.performance} />}
    </div>
  </div>
);

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/upload/batch-card/constants.ts
================
export const DATE_FORMAT_OPTIONS: Intl.DateTimeFormatOptions = {
  year: "numeric",
  month: "short",
  day: "numeric",
  hour: "2-digit",
  minute: "2-digit",
  timeZone: Intl.DateTimeFormat().resolvedOptions().timeZone
};

export const STATUS_BADGE_CONFIG = {
  uploading: {
    icon: "Loader2",
    label: "Uploading",
    className: "bg-blue-50 text-blue-700 border-blue-200"
  },
  extracting: {
    icon: "Zap",
    label: "Extracting UI",
    className: "bg-amber-50 text-amber-700 border-amber-200"
  },
  annotating: {
    icon: "Pencil",
    label: "Annotating",
    className: "bg-purple-50 text-purple-700 border-purple-200"
  },
  preview: {
    icon: "Eye",
    label: "Preview Available",
    className: "bg-green-50 text-green-700 border-green-200"
  },
  done: {
    icon: "CheckCircle",
    label: "Done",
    className: "bg-green-100 text-green-800 border-green-300"
  }
} as const;

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/upload/batch-card/image-grid.tsx
================
import { ScrollArea } from "@/components/ui/scroll-area";
import { ImageCard } from "../image-card";
import type { Batch } from "@/types/batch_v1";

interface ImageGridProps {
  images: Batch["images"];
  onImageSelect: (index: number) => void;
}

export const ImageGrid = ({ images, onImageSelect }: ImageGridProps) => (
  <div className="p-4">
    <ScrollArea className="h-[300px]">
      <div className="grid grid-cols-1 xs:grid-cols-2 sm:grid-cols-3 md:grid-cols-4 lg:grid-cols-5 gap-4">
        {images.map((image, index) => (
          <ImageCard
            key={image.id}
            file={image}
            index={index}
            // onClick={() => onImageSelect(index)}
            onClick={() => {}}
            isUploadMode={false}
          />
        ))}
      </div>
    </ScrollArea>
  </div>
);

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/upload/batch-card/index.tsx
================
import { Separator } from "@/components/ui/separator";
import { BatchHeader } from "./batch-header";
import { PerformanceStats } from "./performance-stats";
import { ImageGrid } from "./image-grid";
import type { Batch } from "@/types/batch_v1";
// import { BatchCard } from "@/components/upload/batch-card";

interface BatchCardProps {
  batch: Batch;
  isExpanded: boolean;
  onToggle: () => void;
  onImageSelect: (imageIndex: number) => void;
  onViewResults: (batchId: string) => void;
}

export function BatchCard({ batch, isExpanded, onToggle, onImageSelect, onViewResults }: BatchCardProps) {
  return (
    <div className="rounded-md border border-border overflow-hidden">
      <div
        className="p-4 flex items-center justify-between cursor-pointer hover:bg-muted/50 transition-colors"
        onClick={onToggle}
      >
        <BatchHeader batch={batch} isExpanded={isExpanded} onToggle={onToggle} onViewResults={(batchId) => onViewResults(batchId)   } />
      </div>

      {batch.performance && isExpanded && <PerformanceStats performance={batch.performance} />}

      {isExpanded && (
        <>
          <Separator />
          <ImageGrid images={batch.images} onImageSelect={onImageSelect} />
        </>
      )}
    </div>
  );
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/upload/batch-card/performance-stats.tsx
================
import type { Batch } from "@/types/batch_v1";

interface PerformanceStatsProps {
  performance: Batch["performance"];
}

export const PerformanceStats = ({ performance }: PerformanceStatsProps) => (
  <div className="px-4 py-2 bg-muted/30 border-t border-b">
    <div className="grid grid-cols-3 gap-2 text-sm">
      <div className="flex flex-col items-center p-2 rounded-md bg-background">
        <span className="text-muted-foreground text-xs">Master Prompt</span>
        <span className="font-medium">{performance?.masterPromptRuntime.toFixed(1)}s</span>
      </div>
      <div className="flex flex-col items-center p-2 rounded-md bg-background">
        <span className="text-muted-foreground text-xs">Inference Time</span>
        <span className="font-medium">{performance?.totalInferenceTime.toFixed(1)}s</span>
      </div>
      <div className="flex flex-col items-center p-2 rounded-md bg-background">
        <span className="text-muted-foreground text-xs">Elements</span>
        <span className="font-medium">{performance?.detectedElementsCount}</span>
      </div>
    </div>
  </div>
);

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/upload/batch-card/performance-tooltip.tsx
================
import { Button } from "@/components/ui/button";
import { Tooltip, TooltipContent, TooltipProvider, TooltipTrigger } from "@/components/ui/tooltip";
import { BarChart } from "lucide-react";
import type { Batch } from "@/types/batch_v1";

interface PerformanceTooltipProps {
  performance: Batch["performance"];
}

export const PerformanceTooltip = ({ performance }: PerformanceTooltipProps) => (
  <div className="flex items-center ml-4">
    <TooltipProvider>
      <Tooltip>
        <TooltipTrigger asChild>
          <Button variant="ghost" size="icon" className="flex items-center gap-1">
            <BarChart className="h-4 w-4 text-muted-foreground" />
            <span>Insight</span>
          </Button>
        </TooltipTrigger>
        <TooltipContent>
          <div className="text-xs">
            <p>Master Prompt: {performance?.masterPromptRuntime.toFixed(1)}s</p>
            <p>Total Inference: {performance?.totalInferenceTime.toFixed(1)}s</p>
            <p>Elements: {performance?.detectedElementsCount}</p>
          </div>
        </TooltipContent>
      </Tooltip>
    </TooltipProvider>
  </div>
);

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/upload/batch-card/status-badge.tsx
================
import { Badge } from "@/components/ui/badge";
import { STATUS_BADGE_CONFIG } from "./constants";
import { Loader2, Zap, Pencil, Eye, CheckCircle } from "lucide-react";
import type { Batch } from "@/types/batch_v1";

const iconComponents = {
  Loader2,
  Zap,
  Pencil,
  Eye,
  CheckCircle
} as const;

interface StatusBadgeProps {
  status: Batch["status"];
}

export const StatusBadge = ({ status }: StatusBadgeProps) => {
  const config = STATUS_BADGE_CONFIG[status];
  if (!config) return null;

  const IconComponent = iconComponents[config.icon];

  return (
    <Badge variant="outline" className={`${config.className} flex items-center gap-1`}>
      <IconComponent className="h-3 w-3" />
      <span>{config.label}</span>
    </Badge>
  );
};

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/upload/batch-card/utils.ts
================
import { DATE_FORMAT_OPTIONS } from "./constants";

export const formatDate = (date: Date): string => {
  try {
    if (!(date instanceof Date) || isNaN(date.getTime())) {
      return 'Invalid date';
    }
    return new Intl.DateTimeFormat("en-US", DATE_FORMAT_OPTIONS).format(date);
  } catch (error) {
    console.error('Error formatting date:', error);
    return 'Invalid date';
  }
};

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/upload/batch-display.tsx
================
// TODO: This component is not used anymore, but it's kept here for reference
// TODO: Remove this file once the new upload interface is fully implementeds

import useSWR from 'swr'
import Image from 'next/image'
import type { Batch } from '@/types/batch_v1'

const fetcher = (url: string) => fetch(url).then(res => res.json())

export function BatchDisplay() {
  const { data: batches, error, isLoading } = useSWR<Batch[]>('/api/batches', fetcher)

  // if (isLoading) return <div>Loading batches...</div>
  if (error) return <div>Error loading batches</div>
  if (!batches) return null

  return (
    <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4 p-4">
      {batches.map((batch: Batch) => (
        <div key={batch.id} className="border rounded-lg p-4 shadow-sm">
          <h3 className="font-semibold mb-2">{batch.name}</h3>
          <p className="text-sm text-gray-600 mb-2">
            {new Date(batch.timestamp).toLocaleDateString()}
          </p>
          <div className="grid grid-cols-2 gap-2">
            {batch.images.map((image) => (
              <div key={image.id} className="relative aspect-square">
                <Image
                  src={image.url}
                  alt={image.name}
                  fill
                  className="object-cover rounded"
                />
              </div>
            ))}
          </div>
        </div>
      ))}
    </div>
  )
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/upload/batch-list.tsx
================
import type { Batch } from "@/types/batch_v1"
import { BatchCard } from "@/components/upload/batch-card"
// import { RevealOnHover } from "@/components/ui/reveal-on-hover"

interface BatchListProps {
  batches: Batch[]
  expandedBatchId: string | null
  toggleBatch: (batchId: string) => void
  onImageSelect: (batchId: string, imageIndex: number) => void
  onViewResults: (batchId: string) => void
}

export function BatchList({ 
  batches, 
  expandedBatchId, 
  toggleBatch, 
  onImageSelect,
  onViewResults,
}: BatchListProps) {
  return (
    <div className="mt-4">
      <h2 className="text-xl font-medium mb-4">Batches ({batches.length})</h2>
      <div className="space-y-3">
        {batches.map((batch) => (
            <BatchCard
              key={batch.id}
              batch={batch}
              isExpanded={expandedBatchId === batch.id}
              onToggle={() => toggleBatch(batch.id)}
              onImageSelect={(imageIndex: number) => onImageSelect(batch.id, imageIndex)}
              onViewResults={() => onViewResults(batch.id)}
            />
        ))}
      </div>
    </div>
  )
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/upload/dropzone-area.tsx
================
import { useDropzone } from "react-dropzone"
import { Upload, ImageIcon, FolderOpen } from "lucide-react"
import { Button } from "@/components/ui/button"

interface DropzoneAreaProps {
  isDragging: boolean
  setIsDragging: (isDragging: boolean) => void
  onDrop: (acceptedFiles: File[]) => void
}

export function DropzoneArea({ isDragging, setIsDragging, onDrop }: DropzoneAreaProps) {
  const { getRootProps, getInputProps } = useDropzone({
    onDrop,
    accept: {
      "image/*": [],
    },
    onDragEnter: () => setIsDragging(true),
    onDragLeave: () => setIsDragging(false),
  })

  return (
    <div
      {...getRootProps()}
      className={`border-2 border-dashed rounded-lg p-6 md:p-10 text-center cursor-pointer transition-colors
        ${isDragging ? "border-primary bg-primary/5" : "border-muted-foreground/25 hover:border-primary/50"}`}
    >
      <input {...getInputProps()} />
      <Upload className="mx-auto h-10 w-10 md:h-12 md:w-12 text-muted-foreground mb-4" />
      <h2 className="text-lg md:text-xl font-medium mb-2">Drag & drop images here</h2>
      <p className="text-muted-foreground mb-4">Or click to browse files (up to 20 images)</p>
      <div className="flex flex-col sm:flex-row justify-center gap-3">
        <Button className="w-full sm:w-auto">
          <ImageIcon className="mr-2 h-4 w-4" />
          Select Images
        </Button>
        <Button variant="outline" className="w-full sm:w-auto">
          <FolderOpen className="mr-2 h-4 w-4" />
          Select Folder
        </Button>
      </div>
    </div>
  )
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/upload/image-card.tsx
================
import { FileImage, X } from "lucide-react"
import { Button } from "@/components/ui/button"
import { Card, CardContent } from "@/components/ui/card"
import Image from "next/image"

type FileType = {
  id: string
  name: string
  url: string
} | File

interface ImageCardProps {
  file: FileType
  index: number
  onClick: () => void
  onRemove?: (index: number) => void
  isUploadMode?: boolean
}

export function ImageCard({ 
  file, 
  index, 
  onClick, 
  onRemove,
  isUploadMode = false 
}: ImageCardProps) {
  const handleRemoveClick = (e: React.MouseEvent) => {
    e.stopPropagation()
    onRemove?.(index)
  }

  const getImageUrl = () => {
    if (file instanceof File) {
      return URL.createObjectURL(file)
    }
    return file.url
  }

  const getFileName = () => {
    if (file instanceof File) {
      return file.name
    }
    return file.name
  }

  const cardClassName = `relative group cursor-pointer hover:shadow-md transition-shadow`

  return (
    <Card 
      className={cardClassName}
      onClick={onClick}
    >
      <CardContent className="p-2">
      <div className="aspect-square relative overflow-hidden rounded-md mb-2">
        <Image
          src={getImageUrl()}
          alt={getFileName()}
          fill
          sizes="(max-width: 768px) 100vw, (max-width: 1200px) 50vw, 33vw"
          className="object-cover"
        />
        {isUploadMode && onRemove && (
          <Button
            variant="destructive"
            size="icon"
            className="absolute top-1 right-1 h-6 w-6 opacity-0 group-hover:opacity-100 transition-opacity"
            onClick={handleRemoveClick}
          >
            <X className="h-3 w-3" />
          </Button>
        )}
        <div className="absolute bottom-0 left-0 right-0 p-2 bg-background/80 text-xs truncate">
          {getFileName()}
        </div>
      </div>
      </CardContent>
    </Card>
  )
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/upload/selected-images-panel.tsx
================
import { Upload } from "lucide-react"
import { Button } from "@/components/ui/button"
import { Input } from "@/components/ui/input"
import { ScrollArea } from "@/components/ui/scroll-area"
import { ImageCard } from "./image-card"
import { 
  Select,
  SelectContent,
  SelectItem,
  SelectTrigger,
  SelectValue 
} from "@/components/ui/select"
import { Toast, ToastProvider, ToastViewport, ToastTitle, ToastDescription } from "@/components/ui/toast"
import React from "react"

// Define analysis types as constants to avoid magic strings
const ANALYSIS_TYPES = {
    USABILITY: 'Usability Audit',
    MARKETING: 'Conversion Analysis',
    // ACCESSIBILITY: 'Inclusive Design Audit',
    TAXONOMY: 'UI Categorization'
  }  

interface SelectedImagesPanelProps {
  selectedFiles: File[]
  batchName: string
  setBatchName: (name: string) => void
  onRemoveFile: (index: number) => void
  onUploadBatch: (files: File[], batchName: string, analysisType: string) => void
  analysisType: string
  setAnalysisType: (type: string) => void
  onRefetchBatches: () => void
}

export function SelectedImagesPanel({
  selectedFiles,
  batchName,
  setBatchName,
  onRemoveFile,
  onUploadBatch,
  analysisType,
  setAnalysisType,
  onRefetchBatches,
}: SelectedImagesPanelProps) {
  const [showToast, setShowToast] = React.useState(false);
  const [isUploading, setIsUploading] = React.useState(false);

  const handleUpload = async () => {
    if (!analysisType) {
      setShowToast(true);
      return;
    }
    
    setIsUploading(true);
    try {
      await onUploadBatch(selectedFiles, batchName, analysisType);
    } catch (error) {
      console.error('Upload failed:', error);
      // You might want to show an error toast here
    } finally {
      setIsUploading(false);
    }
  };

  return (
    <ToastProvider>
      <div>
        <div className="flex flex-col sm:flex-row justify-between items-start sm:items-center mb-4">
          <h2 className="text-xl font-medium">Selected Images ({selectedFiles.length})</h2>
          <div className="flex flex-col sm:flex-row gap-3 mt-2 sm:mt-0 w-full sm:w-auto">
            <div className="flex-1 sm:flex-initial">
              <Input
                placeholder="Batch Name (optional)"
                value={batchName}
                onChange={(e) => setBatchName(e.target.value)}
                className="w-full"
              />
            </div>
            
            <Select 
              value={analysisType} 
              onValueChange={(value) => setAnalysisType(value)}
            >
              <SelectTrigger className="w-full sm:w-[220px]">
                <SelectValue placeholder="Select Analysis Type" />
              </SelectTrigger>
              <SelectContent>
                <SelectItem value={ANALYSIS_TYPES.USABILITY}>
                  {ANALYSIS_TYPES.USABILITY}
                </SelectItem>
                <SelectItem value={ANALYSIS_TYPES.MARKETING}>
                  {ANALYSIS_TYPES.MARKETING}
                </SelectItem>
                {/* <SelectItem value={ANALYSIS_TYPES.ACCESSIBILITY}>
                  {ANALYSIS_TYPES.ACCESSIBILITY}
                </SelectItem> */}
                <SelectItem value={ANALYSIS_TYPES.TAXONOMY}>
                  {ANALYSIS_TYPES.TAXONOMY}
                </SelectItem>
              </SelectContent>
            </Select>
            
            <Button 
              className="w-full sm:w-auto" 
              onClick={handleUpload} 
              disabled={isUploading}
            >
              {isUploading ? (
                <>
                  <span className="animate-spin mr-2"></span>
                  Uploading...
                </>
              ) : (
                <>
                  <Upload className="mr-2 h-4 w-4" />
                  Upload Batch
                </>
              )}
            </Button>
          </div>
        </div>

        <ScrollArea className="h-[300px] md:h-[400px] rounded-md border">
          <div className="grid grid-cols-1 xs:grid-cols-2 sm:grid-cols-3 md:grid-cols-4 lg:grid-cols-5 gap-4 p-4">
            {selectedFiles.map((file, index) => (
              <ImageCard
                key={`${file.name}-${index}`}
                file={file}
                index={index}
                onRemove={onRemoveFile}
                isUploadMode={true} 
                onClick={() => {}}
              />
            ))}
          </div>
        </ScrollArea>
      </div>
      
      {showToast && (
        <Toast variant="default" onOpenChange={setShowToast}>
          <ToastTitle>Analysis type required</ToastTitle>
          <ToastDescription>
            Please select an analysis type before uploading.
          </ToastDescription>
        </Toast>
      )}
      
      <ToastViewport />
    </ToastProvider>
  )
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/annotation-editor.tsx
================
"use client"

import type React from "react"

import { useState, useRef, useEffect } from "react"
import { ArrowLeft, Save, ChevronUp, ChevronDown, Loader2 } from "lucide-react"
import { Button } from "@/components/ui/button"
import { ControlPanel } from "@/components/control-panel"
import { useIsMobile } from "@/hooks/use-mobile"
import { useImageScale } from "../hooks/use-image-scale"
import { useBoxInteraction } from "../hooks/use-box-interaction"
import { AnnotationCanvas } from "../components/annotation/annotation-canvas"
import { AnnotationHeader } from "../components/annotation/annotation-header"
import { BoundingBox } from "@/types/annotation"
import { useAnnotationState } from "../hooks/use-annotation-state"

// Mock data for demonstration purposes
const mockBoundingBoxes = [
  {
    id: 1,
    label: "Button",
    textLabel: "Submit",
    description: "Main action button",
    x: 50,
    y: 100,
    width: 120,
    height: 40,
    inferenceTime: 0.78,
  },
  {
    id: 2,
    label: "Tab Bar",
    textLabel: "Navigation",
    description: "Main navigation tabs",
    x: 200,
    y: 50,
    width: 300,
    height: 60,
    inferenceTime: 1.25,
  },
  {
    id: 3,
    label: "Text Field",
    textLabel: "Username",
    description: "Username input field",
    x: 100,
    y: 200,
    width: 200,
    height: 40,
    inferenceTime: 0.92,
  },
  {
    id: 4,
    label: "Checkbox",
    textLabel: "Remember me",
    description: "Session persistence option",
    x: 400,
    y: 300,
    width: 30,
    height: 30,
    inferenceTime: 0.65,
  },
  {
    id: 5,
    label: "Dropdown",
    textLabel: "Country",
    description: "Country selection dropdown",
    x: 500,
    y: 150,
    width: 150,
    height: 40,
    inferenceTime: 1.12,
  },
]


interface AnnotationEditorProps {
  image: {
    id: string
    name: string
    url: string
  }
  onBack: () => void
  onNextImage?: () => void
  onPreviousImage?: () => void
}

export function AnnotationEditor({ image, onBack, onNextImage, onPreviousImage }: AnnotationEditorProps) {
  // Use our centralized annotation state
  const {
    boundingBoxes,
    selectedBox,
    editingLabelId,
    editingLabelText,
    setEditingLabelId,
    setEditingLabelText,
    updateBox,
    selectBox,
    deleteBox,
    updateLabelAndFinishEditing,
    dragState,
    resizeState,
    setDragState,
    setResizeState
  } = useAnnotationState(mockBoundingBoxes)

  const [masterPromptRuntime, setMasterPromptRuntime] = useState<number>(1.8) // in seconds
  const [isPanelCollapsed, setIsPanelCollapsed] = useState(false)
  const [isImageLoading, setIsImageLoading] = useState(true)
  // const isMobile = useIsMobile()  // Commented out mobile check
  
  const containerRef = useRef<HTMLDivElement>(document.createElement('div'))
  const imageRef = useRef<HTMLImageElement>(document.createElement('img'))
  const controlPanelRef = useRef<HTMLDivElement>(null) // Add ref for control panel
  
  // Custom hooks
  const { scale } = useImageScale(image.url, containerRef, imageRef)
  
  // Handle image load
  useEffect(() => {
    const handleImageLoad = () => {
      setIsImageLoading(false)
    }

    if (imageRef.current) {
      imageRef.current.onload = handleImageLoad
      // Reset loading state if image URL changes
      setIsImageLoading(true)
    }
  }, [image.url])

  // Use the useBoxInteraction hook with our centralized state
  const { startDragging, startResizing } = useBoxInteraction({
    containerRef,
    scale,
    updateBox,
    selectBox,
    setDragState,
    setResizeState
  })

  // Handle click outside canvas and control panel to deselect
  useEffect(() => {
    const handleClickOutside = (e: MouseEvent) => {
      if (
        containerRef.current && 
        !containerRef.current.contains(e.target as Node) &&
        controlPanelRef.current && 
        !controlPanelRef.current.contains(e.target as Node)
      ) {
        selectBox(null)
      }
    }

    document.addEventListener('mousedown', handleClickOutside)
    return () => document.removeEventListener('mousedown', handleClickOutside)
  }, [containerRef, controlPanelRef, selectBox])

  const handleSave = () => {
    console.log("Saving annotation data:", boundingBoxes)
    // Here you would typically send the data to your backend
    alert("Annotations saved successfully!")
  }

  const togglePanel = () => {
    setIsPanelCollapsed(!isPanelCollapsed)
  }

  // Group related props
  const boxControls = {
    boundingBoxes,
    selectedBox,
    onSelect: selectBox,
    onUpdate: updateBox,
    onDelete: deleteBox,
    onDeselect: () => selectBox(null)
  }

  const labelEditing = {
    editingLabelId,
    editingLabelText,
    setEditingLabelId,
    setEditingLabelText,
    updateLabelAndFinishEditing
  }

  const imageState = {
    imageUrl: image.url,
    scale,
    imageRef,
    containerRef
  }

  const interactionHandlers = {
    startDragging,
    startResizing,
    dragState,
    resizeState
  }

  return (
    <div className="flex h-screen min-w-[800px]">
      {/* Main annotation area - fixed width and height */}
      <div className="w-[1000px] h-screen flex flex-col">
        <AnnotationHeader 
          imageName={image.name}
          onBack={onBack}
          onSave={handleSave}
        />

        <div className="flex-1 overflow-auto bg-muted/30 p-2 sm:p-4 relative">
          {isImageLoading && (
            <div className="absolute inset-0 flex items-center justify-center bg-background/80 z-10">
              <Loader2 className="h-8 w-8 animate-spin text-primary" />
            </div>
          )}
          <AnnotationCanvas
            imageState={imageState}
            boxControls={boxControls}
            labelEditing={labelEditing}
            interactionHandlers={interactionHandlers}
            isMobile={false}
          />
        </div>

        {/* Mobile panel toggle button - commented out
        {isMobile && (
          <div className="border-t border-b p-2 bg-background flex justify-center">
            <Button variant="outline" onClick={togglePanel} className="w-full flex items-center justify-center">
              {isPanelCollapsed ? (
                <>
                  <ChevronUp className="mr-2 h-4 w-4" />
                  Show Control Panel
                </>
              ) : (
                <>
                  <ChevronDown className="mr-2 h-4 w-4" />
                  Hide Control Panel
                </>
              )}
            </Button>
          </div>
        )}
        */}
      </div>

      {/* Control panel / sidebar - flexible width */}
      <div 
        ref={controlPanelRef} // Attach ref to the control panel wrapper
        className={`flex-1 border-l bg-background flex flex-col h-full min-w-[300px] ${isPanelCollapsed ? "hidden" : "flex"}`}>
        <ControlPanel
          boundingBoxes={boundingBoxes}
          selectedBox={selectedBox}
          onBoxSelect={selectBox}
          onBoxUpdate={updateBox}
          onBoxDelete={deleteBox}
          onBoxDeselect={() => selectBox(null)}
          editingLabelState={{
            editingLabelId,
            editingLabelText,
            setEditingLabelId,
            setEditingLabelText,
            updateLabelAndFinishEditing
          }}
          masterPromptRuntime={masterPromptRuntime}
          onSave={handleSave}
          onNextImage={onNextImage}
          onPreviousImage={onPreviousImage}
          isMobile={false}
        />
      </div>
    </div>
  )
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/control-panel.tsx
================
"use client"

import { useState, useMemo } from "react"
import { Tabs, TabsContent, TabsList, TabsTrigger } from "@/components/ui/tabs"
import { ControlPanelHeader } from "@/components/control-panel/control-panel-header"
import { ElementList } from "@/components/control-panel/element-list"
import { ElementEditor } from "@/components/control-panel/element-editor"
import { SummaryPanel } from "@/components/control-panel/summary-panel"
import { PanelFooterActions } from "@/components/control-panel/panel-footer-actions"
import { BoundingBox } from "@/types/annotation"
import { useControlPanelState } from "@/hooks/use-box-interaction"

interface ControlPanelProps {
  boundingBoxes: BoundingBox[]
  selectedBox: BoundingBox | null
  onBoxSelect: (box: BoundingBox) => void
  onBoxUpdate: (box: BoundingBox) => void
  onBoxDelete: (id: number) => void
  masterPromptRuntime: number
  onSave: () => void
  onNextImage?: () => void
  onPreviousImage?: () => void
  isMobile?: boolean
  onBoxDeselect: () => void
  editingLabelState: {
    editingLabelId: number | null
    editingLabelText: string
    setEditingLabelId: (id: number | null) => void
    setEditingLabelText: (text: string) => void
    updateLabelAndFinishEditing: () => void
  }
}

export function ControlPanel({
  boundingBoxes,
  selectedBox,
  onBoxSelect,
  onBoxUpdate,
  onBoxDelete,
  masterPromptRuntime,
  onSave,
  onNextImage,
  onPreviousImage,
  isMobile = false,
  onBoxDeselect,
  editingLabelState,
}: ControlPanelProps) {
  // Use the hook for UI state management
  const {
    activeTab,
    setActiveTab,
    hoveredBoxId,
    setHoveredBoxId,
    view,
    setView,
    totalInferenceTime
  } = useControlPanelState(boundingBoxes)

  const handleElementSelect = (box: BoundingBox) => {
    onBoxSelect(box)
    setView("edit")
  }

  const handleBackToList = () => {
    onBoxDeselect()
    setView("list")
  }

  const handleExportAnnotations = () => {
    const annotationData = {
      masterPromptRuntime,
      totalInferenceTime,
      elements: boundingBoxes,
    }

    const dataStr = JSON.stringify(annotationData, null, 2)
    const dataUri = "data:application/json;charset=utf-8," + encodeURIComponent(dataStr)

    const exportFileDefaultName = "annotations.json"

    const linkElement = document.createElement("a")
    linkElement.setAttribute("href", dataUri)
    linkElement.setAttribute("download", exportFileDefaultName)
    linkElement.click()
  }

  // Mobile view uses tabs
  if (isMobile) {
    return (
      <div className="flex flex-col h-full">
        <Tabs defaultValue="elements" value={activeTab} onValueChange={setActiveTab} className="w-full">
          <div className="px-4 pt-4 border-b sticky top-0 bg-background z-10">
            <TabsList className="w-full grid grid-cols-3">
              <TabsTrigger value="elements">Elements</TabsTrigger>
              <TabsTrigger value="editor">Editor</TabsTrigger>
              <TabsTrigger value="summary">Summary</TabsTrigger>
            </TabsList>
          </div>

          <TabsContent value="elements" className="mt-0 p-0">
            <ElementList
              boundingBoxes={boundingBoxes}
              selectedBox={selectedBox}
              hoveredBoxId={hoveredBoxId}
              setHoveredBoxId={setHoveredBoxId}
              onBoxSelect={onBoxSelect}
              onBoxDelete={onBoxDelete}
            />
          </TabsContent>

          <TabsContent value="editor" className="mt-0 p-0">
            {selectedBox ? (
              <ElementEditor
                selectedBox={selectedBox}
                onBoxUpdate={onBoxUpdate}
                onBoxDelete={onBoxDelete}
                onBackToList={handleBackToList}
                editingLabelState={editingLabelState}
              />
            ) : (
              <div className="p-4 text-center text-muted-foreground">Select an element to edit its properties</div>
            )}
          </TabsContent>

          <TabsContent value="summary" className="mt-0 p-0">
            <SummaryPanel
              masterPromptRuntime={masterPromptRuntime}
              totalInferenceTime={totalInferenceTime}
              elementCount={boundingBoxes.length}
            />
          </TabsContent>
        </Tabs>

        <PanelFooterActions
          onSave={onSave}
          onExport={handleExportAnnotations}
          onPreviousImage={onPreviousImage}
          onNextImage={onNextImage}
        />
      </div>
    )
  }

  // Desktop view - now with separate list and edit views
  return (
    <div className="flex flex-col h-full">
      {/* List View */}
      {view === "list" && (
        <>
          <ControlPanelHeader
            title="Performance Summary"
            masterPromptRuntime={masterPromptRuntime}
            totalInferenceTime={totalInferenceTime}
          />

          <div className="p-4 border-b">
            <h3 className="text-lg font-medium">Detected Elements</h3>
            <p className="text-sm text-muted-foreground">{boundingBoxes.length} elements found</p>
          </div>

          <ElementList
            boundingBoxes={boundingBoxes}
            selectedBox={selectedBox}
            hoveredBoxId={hoveredBoxId}
            setHoveredBoxId={setHoveredBoxId}
            onBoxSelect={handleElementSelect}
            onBoxDelete={onBoxDelete}
          />

          <PanelFooterActions
            onSave={onSave}
            onExport={handleExportAnnotations}
            onPreviousImage={onPreviousImage}
            onNextImage={onNextImage}
          />
        </>
      )}

      {/* Edit View */}
      {view === "edit" && selectedBox && (
        <ElementEditor
          selectedBox={selectedBox}
          onBoxUpdate={onBoxUpdate}
          onBoxDelete={onBoxDelete}
          onBackToList={handleBackToList}
          editingLabelState={editingLabelState}
        />
      )}
    </div>
  )
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/element-list-item.tsx
================
"use client"
import { motion, AnimatePresence } from "framer-motion"
import { Trash2, Eye, Clock, ChevronDown, ChevronUp } from "lucide-react"
import { Button } from "@/components/ui/button"
import { Card, CardContent } from "@/components/ui/card"
import { BoundingBox } from "@/types/annotation"

interface ElementListItemProps {
  box: BoundingBox
  isSelected: boolean
  isExpanded: boolean
  onSelect: (box: BoundingBox) => void
  onDelete: (id: number) => void
  onToggleExpand: (id: number) => void
  isMobile: boolean
}

export function ElementListItem({
  box,
  isSelected,
  isExpanded,
  onSelect,
  onDelete,
  onToggleExpand,
  isMobile,
}: ElementListItemProps) {
  const handleClick = () => {
    if (isMobile) {
      onSelect(box)
    } else {
      onToggleExpand(box.id)
    }
  }

  return (
    <Card className={`cursor-pointer transition-colors ${isSelected ? "border-primary" : ""}`} onClick={handleClick}>
      <CardContent className="p-3">
        <div className="flex items-center justify-between">
          <div className="max-w-[70%]">
            <div className="font-medium break-words">{box.textLabel}</div>
          </div>
          <div className="flex gap-1">
            {!isMobile && (
              <Button
                variant="ghost"
                size="icon"
                className="h-7 w-7"
                onClick={(e) => {
                  e.stopPropagation()
                  onToggleExpand(box.id)
                }}
              >
                {isExpanded ? <ChevronUp className="h-4 w-4" /> : <ChevronDown className="h-4 w-4" />}
              </Button>
            )}
          </div>
        </div>

        <AnimatePresence>
          {isExpanded && (
            <motion.div
              initial={{ height: 0, opacity: 0 }}
              animate={{ height: "auto", opacity: 1 }}
              exit={{ height: 0, opacity: 0 }}
              transition={{ duration: 0.2 }}
              className="overflow-hidden"
            >
              <div className="mt-2 pt-2 border-t">
                <div className="text-xs text-muted-foreground">
                  <span className="font-medium">Type:</span> {box.label}
                </div>
                <div
                  className="text-xs text-muted-foreground mt-1"
                  key={`${box.x}-${box.y}-${box.width}-${box.height}`}
                >
                  <span className="font-medium">Position:</span> x: {box.x}, y: {box.y}, w: {box.width}, h: {box.height}
                </div>
                <div className="text-xs flex items-center mt-1 text-muted-foreground">
                  <Clock className="h-3 w-3 mr-1" />
                  Inference Time: {box.inferenceTime.toFixed(2)}s
                </div>
                <div className="flex gap-1 mt-2">
                  <Button
                    variant="outline"
                    size="sm"
                    className="h-7 text-xs flex-1"
                    onClick={(e) => {
                      e.stopPropagation()
                      onSelect(box)
                    }}
                  >
                    <Eye className="h-3 w-3 mr-1" />
                    Edit
                  </Button>
                  <Button
                    variant="outline"
                    size="sm"
                    className="h-7 text-xs flex-1 text-destructive hover:text-destructive"
                    onClick={(e) => {
                      e.stopPropagation()
                      onDelete(box.id)
                    }}
                  >
                    <Trash2 className="h-3 w-3 mr-1" />
                    Delete
                  </Button>
                </div>
              </div>
            </motion.div>
          )}
        </AnimatePresence>
      </CardContent>
    </Card>
  )
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/components/upload-interface.tsx
================
"use client"

import { useState, useCallback } from "react"
import { Loader2 } from "lucide-react"
import type { Batch } from "@/types/batch_v1"
import { useIsMobile } from "@/hooks/use-mobile"
import { useBatchManagement } from "@/hooks/use-batch-management"
import { filterAndLimitImageFiles, removeFileAtIndex } from "@/lib/file-utils"
import { uploadFiles } from "@/services/upload-service"
import { TOAST_MESSAGES } from "@/lib/constants"
import { DropzoneArea } from "@/components/upload/dropzone-area"
import { SelectedImagesPanel } from "@/components/upload/selected-images-panel"
import { BatchList } from "@/components/upload/batch-list"
import { Toast, ToastProvider, ToastViewport, ToastTitle, ToastDescription } from "@/components/ui/toast"

interface UploadInterfaceProps {
  selectedFiles: File[]
  onFilesSelected: (files: File[]) => void
  onUploadBatch: (batchName: string, analysisType: string, uploadedFiles: File[]) => void
  onImageSelect: (batchId: string, imageIndex: number) => void
  onViewResults: (batchId: string) => void
  onRefetchBatches: () => void
}

export function UploadInterface({
  selectedFiles,
  onFilesSelected,
  onUploadBatch,
  onImageSelect,
  onViewResults,
  onRefetchBatches,
}: UploadInterfaceProps) {
  const [isDragging, setIsDragging] = useState(false)
  const [batchName, setBatchName] = useState("")
  const [analysisType, setAnalysisType] = useState("")
  const isMobile = useIsMobile()
  
  const {
    batches,
    error,
    isLoading,
    mutate,
    expandedBatchId,
    toggleBatch,
    showToast,
    setShowToast,
    generateDefaultBatchName,
  } = useBatchManagement()

  const handleFileDrop = useCallback(
    (acceptedFiles: File[]) => {
      const combinedFiles = filterAndLimitImageFiles(acceptedFiles, selectedFiles)
      onFilesSelected(combinedFiles)
      setIsDragging(false)
    },
    [onFilesSelected, selectedFiles],
  )

  const handleFileRemove = (index: number) => {
    const newFiles = removeFileAtIndex(selectedFiles, index)
    onFilesSelected(newFiles)
  }

  const handleUpload = async (files: File[], batchName: string, analysisType: string) => {
    const finalBatchName = batchName.trim() || generateDefaultBatchName()
    
    const result= await uploadFiles(files, finalBatchName, analysisType)
    
    if (result.success) {
      onUploadBatch(finalBatchName, analysisType, files)
      await mutate()
    } else {
      setShowToast(true)
    }
  }

  return (
    <div className="container mx-auto py-6 md:py-10 px-4">
      <h1 className="text-2xl md:text-3xl font-bold mb-6 md:mb-8 text-center">Annotation Tool</h1>

      <div className="flex flex-col gap-8">
        <DropzoneArea 
          isDragging={isDragging}
          setIsDragging={setIsDragging}
          onDrop={handleFileDrop}
        />

        {selectedFiles.length > 0 && (
          <SelectedImagesPanel
            selectedFiles={selectedFiles}
            batchName={batchName}
            setBatchName={setBatchName}
            onRemoveFile={handleFileRemove}
            onUploadBatch={handleUpload}
            analysisType={analysisType}
            setAnalysisType={setAnalysisType}
            onRefetchBatches={onRefetchBatches}
          />
        )}

        {isLoading ? (
          <div className="flex items-center justify-center h-full">
            <div className="flex flex-col items-center">
              <Loader2 className="h-8 w-8 animate-spin" />
              <p className="mt-4 text-lg">{TOAST_MESSAGES.LOADING_BATCHES}</p>
            </div>
          </div>
        ) : error ? (
          <div>Error loading batches</div>
        ) : batches ? (
          <BatchList
            batches={batches}
            expandedBatchId={expandedBatchId}
            toggleBatch={toggleBatch}
            onImageSelect={onImageSelect}
            onViewResults={onViewResults}
          />
        ) : null}
      </div>

      <ToastProvider>
        <Toast open={showToast} onOpenChange={setShowToast}>
          <ToastTitle>Error</ToastTitle>
          <ToastDescription>{TOAST_MESSAGES.UPLOAD_ERROR}</ToastDescription>
        </Toast>
        <ToastViewport />
      </ToastProvider>
    </div>
  )
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/hooks/use-annotation-state.tsx
================
import { useState, useCallback, useRef } from "react"
import { BoundingBox } from "@/types/annotation"

interface AnnotationState {
  boundingBoxes: BoundingBox[]
  selectedBox: BoundingBox | null
  editingLabelId: number | null
  editingLabelText: string
  dragState: {
    isDragging: boolean
    startX: number
    startY: number
    originalBox: BoundingBox | null
  }
  resizeState: {
    isResizing: boolean
    handle: string | null
    startX: number
    startY: number
    originalBox: BoundingBox | null
  }
}

export function useAnnotationState(initialBoxes: BoundingBox[]) {
  // Use refs for frequently updated values to avoid re-renders
  const dragStateRef = useRef({
    isDragging: false,
    startX: 0,
    startY: 0,
    originalBox: null as BoundingBox | null
  })

  const resizeStateRef = useRef({
    isResizing: false,
    handle: null as string | null,
    startX: 0,
    startY: 0,
    originalBox: null as BoundingBox | null
  })

  // Core state management
  const [state, setState] = useState<AnnotationState>({
    boundingBoxes: initialBoxes,
    selectedBox: null,
    editingLabelId: null,
    editingLabelText: "",
    dragState: dragStateRef.current,
    resizeState: resizeStateRef.current
  })

  // Box manipulation methods
  const updateBox = useCallback((updatedBox: BoundingBox) => {
    setState(current => {
      // Only update if the box has actually changed
      const existingBox = current.boundingBoxes.find(box => box.id === updatedBox.id)
      if (existingBox && 
          existingBox.x === updatedBox.x &&
          existingBox.y === updatedBox.y &&
          existingBox.width === updatedBox.width &&
          existingBox.height === updatedBox.height) {
        return current
      }

      return {
        ...current,
        boundingBoxes: current.boundingBoxes.map(box => 
          box.id === updatedBox.id ? updatedBox : box
        ),
        selectedBox: current.selectedBox?.id === updatedBox.id ? updatedBox : current.selectedBox
      }
    })
  }, [])

  const selectBox = useCallback((box: BoundingBox | null) => {
    setState(current => ({
      ...current,
      selectedBox: box,
      editingLabelId: box ? box.id : null,
      editingLabelText: box ? box.textLabel : ""
    }))
  }, [])

  const deleteBox = useCallback((id: number) => {
    setState(current => ({
      ...current,
      boundingBoxes: current.boundingBoxes.filter(box => box.id !== id),
      selectedBox: current.selectedBox?.id === id ? null : current.selectedBox,
      editingLabelId: current.editingLabelId === id ? null : current.editingLabelId
    }))
  }, [])

  // Label editing methods
  const setEditingLabelId = useCallback((id: number | null) => {
    setState(current => {
      // If starting to edit, pre-populate with the existing label
      const editingBox = id ? current.boundingBoxes.find(box => box.id === id) : null;
      
      const nextEditingText = editingBox ? editingBox.textLabel : current.editingLabelText

      return {
        ...current,
        editingLabelId: id,
        editingLabelText: id === current.editingLabelId ? current.editingLabelText : nextEditingText
      }
    })
  }, [])

  const setEditingLabelText = useCallback((text: string) => {
    setState(current => ({
      ...current,
      editingLabelText: text
    }))
  }, [])

  const updateLabelAndFinishEditing = useCallback(() => {
    setState(current => {
      if (current.editingLabelId) {
        const updatedBoxes = current.boundingBoxes.map(box => 
          box.id === current.editingLabelId 
            ? { ...box, textLabel: current.editingLabelText } 
            : box
        );
        
        const updatedSelectedBox = current.selectedBox?.id === current.editingLabelId 
          ? { ...current.selectedBox, textLabel: current.editingLabelText } 
          : current.selectedBox;
          
        return {
          ...current,
          boundingBoxes: updatedBoxes,
          selectedBox: updatedSelectedBox,
          editingLabelId: null,
          editingLabelText: ""
        }
      }
      return current;
    })
  }, [])

  // Optimized interaction state methods
  const setDragState = useCallback((newState: Partial<AnnotationState['dragState']> | ((prev: AnnotationState['dragState']) => AnnotationState['dragState'])) => {
    const updatedState = typeof newState === 'function' 
      ? newState(dragStateRef.current)
      : { ...dragStateRef.current, ...newState }
    
    dragStateRef.current = updatedState
    
    // Only update React state if necessary
    if (updatedState.isDragging !== state.dragState.isDragging ||
        updatedState.originalBox !== state.dragState.originalBox) {
      setState(current => ({
        ...current,
        dragState: updatedState
      }))
    }
  }, [state.dragState.isDragging, state.dragState.originalBox])

  const setResizeState = useCallback((newState: Partial<AnnotationState['resizeState']> | ((prev: AnnotationState['resizeState']) => AnnotationState['resizeState'])) => {
    const updatedState = typeof newState === 'function'
      ? newState(resizeStateRef.current)
      : { ...resizeStateRef.current, ...newState }
    
    resizeStateRef.current = updatedState
    
    // Only update React state if necessary
    if (updatedState.isResizing !== state.resizeState.isResizing ||
        updatedState.handle !== state.resizeState.handle ||
        updatedState.originalBox !== state.resizeState.originalBox) {
      setState(current => ({
        ...current,
        resizeState: updatedState
      }))
    }
  }, [state.resizeState.isResizing, state.resizeState.handle, state.resizeState.originalBox])

  return {
    // Direct state access
    boundingBoxes: state.boundingBoxes,
    selectedBox: state.selectedBox,
    editingLabelId: state.editingLabelId,
    editingLabelText: state.editingLabelText,
    dragState: dragStateRef.current,
    resizeState: resizeStateRef.current,
    
    // Methods
    updateBox,
    selectBox,
    deleteBox,
    setEditingLabelId,
    setEditingLabelText,
    updateLabelAndFinishEditing,
    setDragState,
    setResizeState
  }
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/hooks/use-batch-management.ts
================
import { useState } from 'react';
import useSWR from 'swr';
import { API_ENDPOINTS, DEFAULT_BATCH_NAME_PREFIX } from '@/lib/constants';
import type { Batch } from '@/types/batch_v1';

const fetcher = (url: string) => fetch(url).then(res => res.json());

export const useBatchManagement = () => {
  const [expandedBatchId, setExpandedBatchId] = useState<string | null>(null);
  const [showToast, setShowToast] = useState(false);
  
  const { data: batches, error, isLoading, mutate } = useSWR<Batch[]>(
    API_ENDPOINTS.BATCHES, 
    fetcher
  );

  const toggleBatch = (batchId: string) => {
    setExpandedBatchId(expandedBatchId === batchId ? null : batchId);
  };

  const generateDefaultBatchName = () => {
    const date = new Date();
    const day = String(date.getDate()).padStart(2, '0');
    const month = date.toLocaleString('default', { month: 'short' });
    const hour = String(date.getHours()).padStart(2, '0');
    const minute = String(date.getMinutes()).padStart(2, '0');
    return `${DEFAULT_BATCH_NAME_PREFIX}${day}${month}_${hour}${minute}`;
  };

  return {
    batches,
    error,
    isLoading,
    mutate,
    expandedBatchId,
    toggleBatch,
    showToast,
    setShowToast,
    generateDefaultBatchName,
  };
};

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/hooks/use-box-interaction.tsx
================
import { useCallback, useEffect, RefObject, useMemo, useState, useRef } from "react"
import { BoundingBox } from "@/types/annotation"


type DragState = {
  isDragging: boolean
  startX: number
  startY: number
  originalBox: BoundingBox | null
}

type ResizeState = {
  isResizing: boolean
  handle: string | null
  startX: number
  startY: number
  originalBox: BoundingBox | null
}

interface UseBoxInteractionProps {
  containerRef: RefObject<HTMLDivElement>
  scale: number
  updateBox: (box: BoundingBox) => void
  selectBox: (box: BoundingBox | null) => void
  setDragState: (state: Partial<DragState> | ((prev: DragState) => DragState)) => void
  setResizeState: (state: Partial<ResizeState> | ((prev: ResizeState) => ResizeState)) => void
}

export function useBoxInteraction({
  containerRef,
  scale,
  updateBox,
  selectBox,
  setDragState,
  setResizeState
}: UseBoxInteractionProps) {
  // Add throttling refs
  const lastUpdateTime = useRef(0)
  const THROTTLE_MS = 16 // ~60fps

  // Set up global mouse event listeners for dragging and resizing
  useEffect(() => {
    const handleMouseMove = (e: MouseEvent) => {
      const now = Date.now()
      if (now - lastUpdateTime.current < THROTTLE_MS) {
        return
      }
      lastUpdateTime.current = now

      if (containerRef.current) {
        const rect = containerRef.current.getBoundingClientRect()
        const x = (e.clientX - rect.left) / scale
        const y = (e.clientY - rect.top) / scale

        // Get current state using callback pattern
        setDragState(dragState => {
          // Handle dragging
          if (dragState.isDragging && dragState.originalBox) {
            const deltaX = x - dragState.startX / scale
            const deltaY = y - dragState.startY / scale

            const updatedBox = {
              ...dragState.originalBox,
              x: dragState.originalBox.x + deltaX,
              y: dragState.originalBox.y + deltaY,
            }

            // Batch the update
            requestAnimationFrame(() => {
              updateBox(updatedBox)
            })
          }
          return dragState;
        })

        // Get current resize state
        setResizeState((resizeState: ResizeState) => {
          // Handle resizing
          if (resizeState.isResizing && resizeState.originalBox && resizeState.handle) {
            const deltaX = x - resizeState.startX / scale
            const deltaY = y - resizeState.startY / scale
            const original = resizeState.originalBox
            let updatedBox = { ...original }

            // Apply resize based on which handle is being dragged
            switch (resizeState.handle) {
              case "top-left":
                updatedBox = {
                  ...original,
                  x: original.x + deltaX,
                  y: original.y + deltaY,
                  width: original.width - deltaX,
                  height: original.height - deltaY,
                }
                break
              case "top-right":
                updatedBox = {
                  ...original,
                  y: original.y + deltaY,
                  width: original.width + deltaX,
                  height: original.height - deltaY,
                }
                break
              case "bottom-left":
                updatedBox = {
                  ...original,
                  x: original.x + deltaX,
                  width: original.width - deltaX,
                  height: original.height + deltaY,
                }
                break
              case "bottom-right":
                updatedBox = {
                  ...original,
                  width: original.width + deltaX,
                  height: original.height + deltaY,
                }
                break
              case "top":
                updatedBox = {
                  ...original,
                  y: original.y + deltaY,
                  height: original.height - deltaY,
                }
                break
              case "right":
                updatedBox = {
                  ...original,
                  width: original.width + deltaX,
                }
                break
              case "bottom":
                updatedBox = {
                  ...original,
                  height: original.height + deltaY,
                }
                break
              case "left":
                updatedBox = {
                  ...original,
                  x: original.x + deltaX,
                  width: original.width - deltaX,
                }
                break
            }

            // Ensure width and height are positive
            if (updatedBox.width < 10) {
              updatedBox.width = 10
              if (["top-left", "bottom-left", "left"].includes(resizeState.handle)) {
                updatedBox.x = original.x + original.width - 10
              }
            }

            if (updatedBox.height < 10) {
              updatedBox.height = 10
              if (["top-left", "top-right", "top"].includes(resizeState.handle)) {
                updatedBox.y = original.y + original.height - 10
              }
            }

            // Batch the update
            requestAnimationFrame(() => {
              updateBox(updatedBox)
            })
          }
          return resizeState;
        })
      }
    }

    const handleMouseUp = () => {
      setDragState({
        isDragging: false,
        startX: 0,
        startY: 0,
        originalBox: null,
      })

      setResizeState({
        isResizing: false,
        handle: null,
        startX: 0,
        startY: 0,
        originalBox: null,
      })
    }

    window.addEventListener("mousemove", handleMouseMove)
    window.addEventListener("mouseup", handleMouseUp)
    window.addEventListener("touchend", handleMouseUp)

    return () => {
      window.removeEventListener("mousemove", handleMouseMove)
      window.removeEventListener("mouseup", handleMouseUp)
      window.removeEventListener("touchend", handleMouseUp)
    }
  }, [containerRef, scale, updateBox, setDragState, setResizeState])

  const startDragging = useCallback((e: React.MouseEvent | React.TouchEvent, box: BoundingBox) => {
    if (containerRef.current) {
      const rect = containerRef.current.getBoundingClientRect()

      let clientX, clientY
      if ("touches" in e) {
        // Touch event
        clientX = e.touches[0].clientX
        clientY = e.touches[0].clientY
      } else {
        // Mouse event
        clientX = e.clientX
        clientY = e.clientY
      }

      setDragState({
        isDragging: true,
        startX: clientX - rect.left,
        startY: clientY - rect.top,
        originalBox: box,
      })
      selectBox(box)
      e.stopPropagation()
    }
  }, [containerRef, selectBox, setDragState])

  const startResizing = useCallback((e: React.MouseEvent | React.TouchEvent, box: BoundingBox, handle: string) => {
    if (containerRef.current) {
      const rect = containerRef.current.getBoundingClientRect()

      let clientX, clientY
      if ("touches" in e) {
        // Touch event
        clientX = e.touches[0].clientX
        clientY = e.touches[0].clientY
      } else {
        // Mouse event
        clientX = e.clientX
        clientY = e.clientY
      }

      setResizeState({
        isResizing: true,
        handle,
        startX: clientX - rect.left,
        startY: clientY - rect.top,
        originalBox: box,
      })
      selectBox(box)
      e.stopPropagation()
    }
  }, [containerRef, selectBox, setResizeState])

  return {
    startDragging,
    startResizing
  }
}

export function useControlPanelState(
  boundingBoxes: BoundingBox[],
  externalEditingState?: {
    editingLabel: string;
    setEditingLabel: (label: string) => void;
  }
) {
  // Use external state if provided, otherwise create local state
  const [localEditingLabel, setLocalEditingLabel] = useState<string>("")
  const editingLabel = externalEditingState?.editingLabel ?? localEditingLabel
  const setEditingLabel = externalEditingState?.setEditingLabel ?? setLocalEditingLabel
  
  const [activeTab, setActiveTab] = useState<string>("elements")
  const [hoveredBoxId, setHoveredBoxId] = useState<number | null>(null)
  const [view, setView] = useState<"list" | "edit">("list")

  // Calculate total inference time
  const totalInferenceTime = useMemo(() => {
    return boundingBoxes.reduce((total, box) => total + box.inferenceTime, 0)
  }, [boundingBoxes])

  return {
    editingLabel,
    setEditingLabel,
    activeTab,
    setActiveTab,
    hoveredBoxId,
    setHoveredBoxId,
    view,
    setView,
    totalInferenceTime
  }
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/hooks/use-image-scale.tsx
================
import { useState, useEffect, RefObject, useRef } from "react"

export function useImageScale(
  imageUrl: string,
  containerRef: RefObject<HTMLDivElement>,
  imageRef: RefObject<HTMLImageElement>
) {
  const [scale, setScale] = useState<number>(1)
  const lastScaleRef = useRef(1)
  const resizeTimeoutRef = useRef<NodeJS.Timeout | undefined>(undefined)

  // Calculate scale factor when image loads or container resizes
  useEffect(() => {
    const updateScale = () => {
      if (imageRef.current && containerRef.current) {
        const containerWidth = containerRef.current.clientWidth
        const imageNaturalWidth = imageRef.current.naturalWidth

        if (imageNaturalWidth > containerWidth) {
          const newScale = containerWidth / imageNaturalWidth
          // Only update if the scale has changed significantly
          if (Math.abs(newScale - lastScaleRef.current) > 0.01) {
            lastScaleRef.current = newScale
            setScale(newScale)
          }
        } else if (lastScaleRef.current !== 1) {
          lastScaleRef.current = 1
          setScale(1)
        }
      }
    }

    // Debounced resize handler
    const handleResize = () => {
      if (resizeTimeoutRef.current) {
        clearTimeout(resizeTimeoutRef.current)
      }
      resizeTimeoutRef.current = setTimeout(updateScale, 100)
    }

    // Update scale when image loads
    if (imageRef.current) {
      imageRef.current.onload = updateScale
    }

    // Update scale on window resize with debounce
    window.addEventListener("resize", handleResize)
    return () => {
      window.removeEventListener("resize", handleResize)
      if (resizeTimeoutRef.current) {
        clearTimeout(resizeTimeoutRef.current)
      }
    }
  }, [imageUrl, containerRef, imageRef])

  return { scale }
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/hooks/use-mobile.tsx
================
"use client"

import { useEffect, useState } from "react"

export function useIsMobile() {
  const [isMobile, setIsMobile] = useState(false)

  useEffect(() => {
    const checkIfMobile = () => {
      setIsMobile(window.innerWidth < 768)
    }

    // Initial check
    checkIfMobile()

    // Add event listener
    window.addEventListener("resize", checkIfMobile)

    // Clean up
    return () => {
      window.removeEventListener("resize", checkIfMobile)
    }
  }, [])

  return isMobile
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/lib/services/ai/ClaudeAIService.ts
================
import Anthropic from '@anthropic-ai/sdk';
import { PromptResult } from '../../../types/PromptRunner'; // adjust path as needed
import { EXTRACT_ELEMENTS_PROMPT_v2, ANCHOR_ELEMENTS_PROMPT_v0, ANCHOR_ELEMENTS_PROMPT_v1, ANCHOR_ELEMENTS_PROMPT_v2, EXTRACT_ELEMENTS_PROMPT_v3, ANCHOR_ELEMENTS_PROMPT_v3 } from '@/lib/prompt/prompts';
import { PromptTrackingContext } from '@/lib/logger';
import { PromptLogType } from '@/lib/constants';
import { cleanText } from '@/lib/file-utils'; 
// Ensure your Claude API key is set in ENV
const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

// Specify the Claude vision model version
const VISION_MODEL_CLAUDE = 'claude-3-7-sonnet-20250219';
const VISION_MODEL_HAIKU = 'claude-3-5-haiku-20241022';

// Constants for token cost calculation (update with actual costs)
const CLAUDE_INPUT_TOKEN_COST = 0.000015; // example cost per input token
const CLAUDE_OUTPUT_TOKEN_COST = 0.000060; // example cost per output token

/**
 * Calls the Claude vision-capable model with a text prompt and optional image URL.
 *
 * @param prompt   - The text prompt to send.
 * @param imageUrl - Optional URL of an image for the model to analyze.
 * @param context  - The tracking context containing batch, screenshot, and other IDs
 * @param promptType - The type of prompt being processed.
 * @returns        - A structured PromptResult containing the response, timing, and token usage.
 */
export async function callClaudeVisionModel(
  prompt: string,
  imageUrl: string | null,
  context: PromptTrackingContext,
  promptType: PromptLogType.ELEMENT_EXTRACTION | PromptLogType.ANCHORING
): Promise<any> {
  // Build the Anthropic messages payload
  const messages = [
    {
      role: 'user',
      content: [
        // include image if provided
        imageUrl && {
          type: 'image',
          source: { type: 'url', url: imageUrl }
        },
        { type: 'text', text: prompt }
      ].filter(Boolean),
    },
  ];

  try {
    // Start timing right before the API call
    const startTime = Date.now();
    
    const response = await anthropic.messages.create({
      // model: VISION_MODEL_HAIKU,
      model: VISION_MODEL_CLAUDE,
      max_tokens: 8192, // tweak as needed
      messages: messages as Anthropic.MessageParam[],
    });
    
    // End timing right after the API call
    const endTime = Date.now();
    const durationMs = endTime - startTime;

    // Extract usage data
    const inputTokens = response?.usage?.input_tokens || 0;
    const outputTokens = response?.usage?.output_tokens || 0;
    
    // Log the interaction using the context with the measured duration
    await context.logPromptInteraction(
      `Claude-${VISION_MODEL_CLAUDE}`,
      promptType,
      prompt,
      JSON.stringify(response),
      durationMs,
      {
        input: inputTokens,
        output: outputTokens,
        total: inputTokens + outputTokens
      },
      CLAUDE_INPUT_TOKEN_COST,
      CLAUDE_OUTPUT_TOKEN_COST
    );

    return response;
  } catch (err) {
    console.error('Error calling Claude Vision Model:', err);
    throw new Error(
      `Failed to get response from Claude: ${
        err instanceof Error ? err.message : String(err)
      }`
    );
  }
}

/**
 * Extracts components from an image using the OpenAI vision model.
 *
 * @param imageUrl The URL of the image to analyze.
 * @param component_list The list of components to guide the extraction.
 * @param context The tracking context containing batch, screenshot, and other IDs
 * @returns A promise resolving to the structured PromptResult.
 * @throws Throws an error if the API call fails.
 */
export async function extract_element_from_image(
  imageUrl: string, 
  component_list: string,
  context: PromptTrackingContext
) {
  // Define the prompt for extraction
  const prompt = EXTRACT_ELEMENTS_PROMPT_v2 + `\n\n<component_list>${component_list}</component_list>`;
  const response = await callClaudeVisionModel(
    prompt, 
    imageUrl, 
    context,
    PromptLogType.ELEMENT_EXTRACTION
  );

  const { parsedContent, rawText, usage } = extractClaudeResponseData(response);

  // Call the OpenAI vision model with the prompt and image URL
  return { parsedContent, rawText, usage };
}

/**
 * Extracts anchor elements from an image using the Claude vision model.
 *
 * @param imageUrl The URL of the image to analyze.
 * @param element_list The list of elements to guide the extraction.
 * @param context The tracking context containing batch, screenshot, and other IDs
 * @returns A promise resolving to the structured PromptResult.
 * @throws Throws an error if the API call fails.
 */
export async function anchor_elements_from_image(
  imageUrl: string, 
  element_list: string,
  context: PromptTrackingContext
) {
  // Define the prompt for anchor extraction
  const prompt = ANCHOR_ELEMENTS_PROMPT_v3 + `\n\n<element_list>${element_list}</element_list>`;
  const response = await callClaudeVisionModel(
    prompt, 
    imageUrl,
    context,
    PromptLogType.ANCHORING
  );

  const { parsedContent, rawText, usage } = extractClaudeResponseData(response);

  // Call the Claude vision model with the prompt and image URL
  return { parsedContent, rawText,usage };
}



/**
 * Cleans the raw text and returns a list of components.
 *
 * @param components - The array of components to filter and clean.
 * @returns Array of cleaned strings in the format "component_name: description".
 */
function cleanTextToList(components: any[]): string[] {
  return components
    .filter(component => typeof component?.component_name === 'string' && typeof component?.description === 'string')
    .map(component => `${component.component_name}: ${component.description}`);
}

/**
 * Helper: Parses Claude's text content into a JSON object safely.
 * Handles common formatting quirks like trailing commas or line breaks.
 * Searches for JSON content within the response text.
 *
 * @param rawText - Raw text string returned from Claude.
 * @returns Parsed JSON object.
 */
function parseClaudeTextToJson(rawText: string): Record<string, string> {
  try {
    // Look for JSON pattern in the text - either within code blocks or standalone
    const jsonRegex = /```(?:json)?\s*({[\s\S]*?})\s*```|({[\s\S]*})/;
    const match = rawText.match(jsonRegex);
    
    let jsonContent = '';
    if (match) {
      // Use the first matched group that contains content
      jsonContent = match[1] || match[2];
    } else {
      // Fall back to using the entire text
      jsonContent = rawText;
    }
    
    const cleanedText = cleanText(jsonContent);
    return JSON.parse(cleanedText);
  } catch (error) {
    console.error('Failed to parse Claude response as JSON:', error);
    return {};
  }
}

/**
 * Extracts structured content text and usage metadata from Claude's response.
 *
 * @param response - Full Claude response object.
 * @returns Object containing parsed text content and usage details.
 */
export function extractClaudeResponseData(response: any): {
  parsedContent: Record<string, string>,
  rawText: string,
  usage: {
    input_tokens?: number,
    output_tokens?: number
  }
} {
  const rawText = response?.content?.find((item: any) => item.type === 'text')?.text ?? '';

  const parsedContent = parseClaudeTextToJson(rawText);

  const usage = {
    input_tokens: response?.usage?.input_tokens,
    output_tokens: response?.usage?.output_tokens,
  };

  return {
    parsedContent,
    rawText,
    usage,
  };
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/lib/services/ai/MoondreamAIService.ts
================
// THIS DOES NOT WORK. DO NOT USE OR MODIFY.

import { PromptTrackingContext } from '@/lib/logger';
import { MOON_DREAM_API_KEY } from '@/config';
import { PromptLogType } from '@/lib/constants';
/**
 * Interface for the detect API response
 */
interface DetectResponse {
  request_id: string;
  objects: Array<{
    x_min: number;
    y_min: number;
    x_max: number;
    y_max: number;
  }>;
}

/**
 * Converts a Blob to a base64 string with data URI prefix
 * 
 * @param blob - The Blob to convert
 * @param mimeType - The MIME type of the image (defaults to 'image/jpeg')
 * @returns A promise resolving to a base64 string with data URI prefix
 */
export async function blobToBase64(blob: Blob, mimeType: string = 'image/jpeg'): Promise<string> {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onloadend = () => {
      if (typeof reader.result === 'string') {
        resolve(reader.result);
      } else {
        reject(new Error('FileReader did not return a string'));
      }
    };
    reader.onerror = reject;
    reader.readAsDataURL(blob);
  });
}

/**
 * Fetches image data from a URL
 * 
 * @param imageUrl - URL of the image to fetch
 * @returns A promise resolving to the image blob
 */
export async function fetchImageFromUrl(imageUrl: string): Promise<Blob> {
  const imageResponse = await fetch(imageUrl);
  const imageBlob = await imageResponse.blob();
  return imageBlob;
}

/**
 * Calls the Moondream API to detect objects in images
 * 
 * @param imageUrl - URL of the image to analyze
 * @param object - The object type to detect (e.g., "person", "car", "face")
 * @param context - The tracking context containing batch, screenshot, and component IDs
 * @returns A promise resolving to the detection response
 */
export async function detectObjectsFromImage(
  imageUrl: string,
  object: string,
  context: PromptTrackingContext
): Promise<DetectResponse> {
  console.log(`CALLING MOONDREAM API: Object=${object}, ImageURL=${imageUrl}`);

  // Fetch the image data from URL
  const imageBlob = await fetchImageFromUrl(imageUrl);

  // Create form data with image and object parameters
  const formData = new FormData();
  formData.append('image', imageBlob);
  formData.append('object', object);

  try {
    // Start timing right before the API call
    const startTime = Date.now();
    
    const response = await fetch('https://api.moondream.ai/v1/detect', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${MOON_DREAM_API_KEY}`
      },
      body: formData
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Moondream API error (${response.status}): ${errorText}`);
    }

    const result = await response.json() as DetectResponse;
    
    // End timing right after the API call finishes
    const endTime = Date.now();
    const durationMs = endTime - startTime;
    
    // Log the interaction using the context with the measured duration
    await context.logPromptInteraction(
      'Moondream-Detect',
      PromptLogType.VLM_LABELING,
      `Detect ${object} in image`,
      JSON.stringify(result),
      durationMs,
      // Moondream doesn't provide token usage, so we leave these undefined
      {
        input: undefined,
        output: undefined,
        total: undefined
      }
    );

    return result;
  } catch (err) {
    console.error('Error calling Moondream API:', err);
    throw new Error(
      `Failed to get response from Moondream: ${
        err instanceof Error ? err.message : String(err)
      }`
    );
  }
}

/**
 * Converts the normalized coordinates to pixel coordinates
 * 
 * @param coordinates - Object with normalized coordinates (0-1)
 * @param imageWidth - Width of the image in pixels
 * @param imageHeight - Height of the image in pixels
 * @returns Object with pixel coordinates
 */
export function normalizedToPixelCoordinates(
  coordinates: { x_min: number; y_min: number; x_max: number; y_max: number },
  imageWidth: number,
  imageHeight: number
) {
  return {
    x_min: Math.round(coordinates.x_min * imageWidth),
    y_min: Math.round(coordinates.y_min * imageHeight),
    x_max: Math.round(coordinates.x_max * imageWidth),
    y_max: Math.round(coordinates.y_max * imageHeight)
  };
} 

/**
 * Detect objects in an image blob via Moondream API.
 *
 * @param imageBlob   Image data as a Blob
 * @param objectType  The object type to detect (e.g. "person", "car", "face")
 * @param context - The tracking context containing batch, screenshot, and component IDs
 */
export async function detectObjectsFromBlob(
  imageBlob: Blob,
  objectType: string,
  context: PromptTrackingContext
): Promise<DetectResponse> {
  console.log(`CALLING MOONDREAM API: Object=${objectType}, Blob input`);

  const formData = new FormData();
  formData.append('image', imageBlob);
  formData.append('object', objectType);

  // Start timing right before the API call
  const startTime = Date.now();
  
  const resp = await fetch('https://api.moondream.ai/v1/detect', {
    method: 'POST',
    headers: { 'Authorization': `Bearer ${MOON_DREAM_API_KEY}` },
    body: formData
  });

  if (!resp.ok) {
    const txt = await resp.text();
    throw new Error(`Moondream API error (${resp.status}): ${txt}`);
  }

  const result = (await resp.json()) as DetectResponse;
  
  // End timing right after the API call finishes
  const endTime = Date.now();
  const durationMs = endTime - startTime;

  // Log the interaction using the context with the measured duration
  await context.logPromptInteraction(
    'Moondream-Detect',
    PromptLogType.VLM_LABELING,
    `Detect ${objectType} in blob`,
    JSON.stringify(result),
    durationMs,
    { input: undefined, output: undefined, total: undefined }
  );

  return result;
}

/**
 * Detect objects in a base64 encoded image via Moondream API.
 *
 * @param imageBase64  Image data as a base64 string with data URI prefix
 * @param objectType  The object type to detect (e.g. "person", "car", "face")
 * @param context - The tracking context containing batch, screenshot, and component IDs
 */
export async function detectObjectsFromBase64(
  imageBase64: string,
  objectType: string,
  context: PromptTrackingContext
): Promise<DetectResponse> {
  if (!MOON_DREAM_API_KEY) {
    console.error('[Moondream] MOON_DREAM_API_KEY is undefined  check your environment variables.');
    throw new Error(
      '[Moondream] MOON_DREAM_API_KEY is undefined  check your environment variables.'
    );
  }

  console.log(`CALLING MOONDREAM API: Object=${objectType}, Base64 input`);

  // Convert base64 to a blob for FormData compatibility
  const formData = new FormData();
  
  // Create a Blob from the base64 string by removing the data URI prefix if present
  let base64Data = imageBase64;
  if (base64Data.startsWith('data:')) {
    base64Data = base64Data.split(',')[1];
  }
  
  // Convert base64 to binary
  const binaryStr = atob(base64Data);
  const byteArray = new Uint8Array(binaryStr.length);
  for (let i = 0; i < binaryStr.length; i++) {
    byteArray[i] = binaryStr.charCodeAt(i);
  }
  
  // Create blob from binary data
  const blob = new Blob([byteArray], { type: 'image/jpeg' });
  
  // Append to form data
  formData.append('image_url', blob);
  formData.append('object', objectType);

  // Start timing right before the API call
  const startTime = Date.now();
  
  const resp = await fetch('https://api.moondream.ai/v1/detect', {
    method: 'POST',
    headers: { 
      'Authorization': `Bearer ${MOON_DREAM_API_KEY}`
    },
    body: formData
  });

  if (!resp.ok) {
    const txt = await resp.text();
    throw new Error(`Moondream API error (${resp.status}): ${txt}`);
  }

  const result = (await resp.json()) as DetectResponse;
  
  // End timing right after the API call finishes
  const endTime = Date.now();
  const durationMs = endTime - startTime;

  // Log the interaction using the context with the measured duration
  await context.logPromptInteraction(
    'Moondream-Detect',
    PromptLogType.VLM_LABELING,
    `Detect ${objectType} in base64 image`,
    JSON.stringify(result),
    durationMs,
    { input: undefined, output: undefined, total: undefined }
  );

  return result;
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/lib/services/ai/MoondreamDetectionService.js
================
import { detectObjectsFromBuffer, normalizedToPixelCoordinates } from '@/lib/services/ai/MoondreamVLService';
import fs from 'fs';
import path from 'path';
import Jimp from 'jimp';
import { logPromptInteraction, logPromptToDatabase, PromptTrackingContext, createScreenshotTrackingContext } from '@/lib/logger';
import pLimit from 'p-limit';
import {
  BOX_COLOR,
  BOX_WIDTH,
  OVERLAY_COLOR,
  generateAnnotatedImageBuffer,
  saveAnnotatedImageDebug,
  normalizeLabel
} from '@/lib/services/imageServices/BoundingBoxService';

// --- Constants ---
const API_RETRY_DELAY_MS = 1000;
const CONCURRENCY_LIMIT = 5;
const VLM_MODEL_NAME = 'moondream'; // Define the model name being used

// --- Type Imports (using JSDoc for type hinting in JS) ---
/**
 * @typedef {import('../../types/DetectionResult').ElementDetectionItem} ElementDetectionItem
 * @typedef {import('../../types/DetectionResult').ComponentDetectionResult} ComponentDetectionResult
 */

/**
 * Extracts the first level of the label hierarchy
 * @param {string} label - The full hierarchical label
 * @returns {string} First level category
 */
function getFirstLevelCategory(label) {
  return label.split(' > ')[0];
}

/**
 * Determines the appropriate grouping category for hierarchical labels
 * Elements are grouped by mid-level categories if they have >2 children
 * 
 * This algorithm implements a dynamic grouping strategy for hierarchical labels:
 * 1. Creates a tree structure representing the label hierarchy
 * 2. Identifies nodes with >2 children or direct elements
 * 3. Promotes these nodes as standalone categories
 * 4. Assigns each element to its deepest eligible category
 * 
 * Example:
 * For "Operational Risk Overview > ICU Department > Occupancy", 
 * if "ICU Department" has >2 child elements, it becomes the category
 * instead of just "Operational Risk Overview".
 * 
 * @param {string[]} allLabels - Array of all hierarchical labels (e.g. "Parent > Child > Grandchild")
 * @returns {Object} Map of labels to their assigned category
 */
function determineHierarchicalGroups(allLabels) {
  // Step 1: Build a tree structure from all labels
  const hierarchy = {};
  
  // Count elements under each prefix
  allLabels.forEach(label => {
    const parts = label.split(' > ');
    
    // Initialize all paths in the hierarchy for this label
    for (let i = 0; i < parts.length; i++) {
      const currentPath = parts.slice(0, i + 1).join(' > ');
      
      if (!hierarchy[currentPath]) {
        hierarchy[currentPath] = {
          count: 0,          // Number of leaf nodes directly assigned to this path
          level: i + 1,      // Depth in the hierarchy (1 = top level)
          parent: i > 0 ? parts.slice(0, i).join(' > ') : null,
          children: new Set() // Set of immediate child paths
        };
      }
      
      // If this is a leaf node (full path), increment leaf count
      if (i === parts.length - 1) {
        hierarchy[currentPath].count++;
      }
      
      // Add as child to parent node
      if (i > 0) {
        const parentPath = parts.slice(0, i).join(' > ');
        if (hierarchy[parentPath]) {
          hierarchy[parentPath].children.add(currentPath);
        }
      }
    }
  });
  
  // Log the hierarchy structure (debug only)
  if (process.env.DEBUG_HIERARCHY === 'true') {
    console.log('=== Label Hierarchy ===');
    Object.entries(hierarchy).forEach(([path, node]) => {
      console.log(`${path} (Level ${node.level}): ${node.count} direct elements, ${node.children.size} children`);
    });
    console.log('======================');
  }
  
  // Step 2: Find the appropriate category for each label
  const labelToCategory = {};
  
  allLabels.forEach(label => {
    const parts = label.split(' > ');
    let bestCategory = parts[0]; // Default to top level
    let bestLevel = 1;
    
    // Find the deepest qualifying category
    for (let i = 0; i < parts.length; i++) { 
      const currentPath = parts.slice(0, i + 1).join(' > ');
      const node = hierarchy[currentPath];
      
      if (!node) continue;
      
      // Determine if this node qualifies as a category:
      // 1. Always include top level
      // 2. If node has >2 children or contains >2 elements directly
      const childCount = node.children.size;
      const hasEnoughChildren = childCount > 2 || node.count > 2;
      
      if (i === 0 || hasEnoughChildren) {
        // This is a better category than what we have
        if (node.level > bestLevel) {
          bestCategory = currentPath;
          bestLevel = node.level;
        }
      }
    }
    
    labelToCategory[label] = bestCategory;
  });
  
  // Log some stats about the grouping results
  const categoryCounts = {};
  Object.values(labelToCategory).forEach(category => {
    categoryCounts[category] = (categoryCounts[category] || 0) + 1;
  });
  
  const uniqueCategories = Object.keys(categoryCounts);
  console.log(`Created ${uniqueCategories.length} groupings from ${allLabels.length} elements:`);
  uniqueCategories.forEach(category => {
    console.log(`- ${category}: ${categoryCounts[category]} elements`);
  });
  
  return labelToCategory;
}

/**
 * Creates an output directory with timestamp
 * @returns {Promise<string>} Path to the created directory
 */
async function createOutputDirectory() {
  const timestamp = new Date().toISOString().replace(/[:.-]/g, '').replace('T', '_').slice(0, 15);
  const outputDir = `mobbin_attempt_folder/detection_output_${timestamp}`;
  
  try {
    await fs.promises.mkdir(outputDir, { recursive: true });
    console.log(`Output directory created: ${outputDir}`);
    return outputDir;
  } catch (err) {
    console.error(`Failed to create output directory: ${err}`);
    throw err;
  }
}

/**
 * Saves JSON data to a file
 * @param {Object} data - The data to save
 * @param {string} filePath - Path to save the JSON file
 * @returns {Promise<void>}
 */
async function saveJson(data, filePath) {
  try {
    // Only save if needed (e.g., for debugging)
    if (process.env.SAVE_DEBUG_FILES === 'true') {
        await fs.promises.writeFile(filePath, JSON.stringify(data, null, 4));
        // console.log(`Debug JSON data saved successfully to: ${filePath}`);
    }
  } catch (err) {
    console.error(`Error saving debug JSON file to ${filePath}: ${err}`);
  }
}

/**
 * Processes a single description to detect objects
 * @param {Buffer} imageBuffer - The image buffer
 * @param {string} description - The object description to detect
 * @param {PromptTrackingContext} context - The tracking context containing batch, screenshot, and component IDs
 * @returns {Promise<{objects: Array, duration: number}>} Detected objects and duration
 */
async function detectSingleObject(imageBuffer, description, context) {
  try {
    // Create a component-specific context if this detection is for a specific component
    const componentContext = context.componentId 
      ? context 
      : context; // Use as-is if no component ID present yet

    // We measure only the API call duration, which is handled inside detectObjectsFromBuffer
    const result = await detectObjectsFromBuffer(imageBuffer, description, componentContext);
    
    // The API call duration is already tracked in detectObjectsFromBuffer
    if (result && result.objects && result.objects.length > 0) {
      return { objects: result.objects, duration: 0 }; // Duration is already logged
    } else {
      return { objects: [], duration: 0 }; // Duration is already logged
    }
  } catch (err) {
    console.error(`Error during detection for '${description}': ${err}`);
    throw err; // Let the caller handle the error state
  }
}

/**
 * Process detected objects and scale coordinates to absolute pixel values
 * @param {Array} detectedObjectsList - List of raw detection objects
 * @param {string} label - The label being processed
 * @param {number} imgWidth - Image width in pixels
 * @param {number} imgHeight - Image height in pixels
 * @returns {Array<{x_min: number, y_min: number, x_max: number, y_max: number}>} List of processed bounding boxes
 */
function processBoundingBoxes(detectedObjectsList, label, imgWidth, imgHeight) {
  const boundingBoxes = [];

  for (const rawDetection of detectedObjectsList) {
    try {
      if ('x_min' in rawDetection && 'y_min' in rawDetection && 'x_max' in rawDetection && 'y_max' in rawDetection) {
        const scaledCoords = normalizedToPixelCoordinates(rawDetection, imgWidth, imgHeight);
        boundingBoxes.push(scaledCoords);
      } else {
        console.warn(`Skipping a detection for label '${label}' due to missing coordinate keys in:`, rawDetection);
      }
    } catch (err) {
      console.error(`Error scaling coordinates for one detection of label '${label}': ${err}`);
      // Decide how to handle scaling errors - skip this box or mark as error?
    }
  }

  return boundingBoxes;
}

/**
 * Main processing function: detects objects, groups by category, generates annotated images/data.
 * Returns structured results per component/category.
 * @param {number} screenshotId - ID of the screenshot being processed
 * @param {Buffer} imageBuffer - Buffer containing the image data
 * @param {Object.<string, string>} labelsDict - Dictionary of {label: description}
 * @param {number} batchId - The ID of the batch this operation is part of
 * @returns {Promise<ComponentDetectionResult[]>} Array of detection results for each component/category.
 */
export async function processAndSaveByCategory(screenshotId, imageBuffer, labelsDict, batchId) {
  const overallStartTime = performance.now();
  let outputDir = null; // Only needed if saving debug files
  if (process.env.SAVE_DEBUG_FILES === 'true') {
      outputDir = await createOutputDirectory();
  }
  const limit = pLimit(CONCURRENCY_LIMIT);
  const componentResults = [];

  // Create a tracking context for this screenshot
  const context = createScreenshotTrackingContext(batchId, screenshotId);

  try {
    // --- Image Validation ---
    let validatedImageBuffer = imageBuffer;
    let jimpImage;
    try {
      jimpImage = await Jimp.read(imageBuffer);
    } catch (err) {
      console.error(`Invalid initial image format for screenshot ${screenshotId}: ${err.message}. Attempting conversion...`);
      try {
        // Attempt conversion (e.g., from JPEG or WEBP to PNG buffer)
        const tempImage = await Jimp.read(imageBuffer);
        validatedImageBuffer = await tempImage.getBufferAsync(Jimp.MIME_PNG);
        jimpImage = await Jimp.read(validatedImageBuffer); // Read the converted buffer
        console.log(`Image conversion successful for screenshot ${screenshotId}.`);
      } catch (convErr) {
        // If conversion fails, we cannot proceed with this screenshot
        console.error(`FATAL: Image conversion failed for screenshot ${screenshotId}: ${convErr.message}. Skipping detection for this image.`);
        // Return an empty array or a specific error result? Empty array for now.
        return [];
        // Or: throw new Error(`Could not process image for screenshot ${screenshotId}: ${convErr.message}`);
      }
    }
    const imgWidth = jimpImage.getWidth();
    const imgHeight = jimpImage.getHeight();

    // --- Parallel Detection ---
    const labelEntries = Object.entries(labelsDict);
    console.log(`[Screenshot ${screenshotId}] Starting detection for ${labelEntries.length} labels with concurrency ${CONCURRENCY_LIMIT}`);

    // Intermediate structure to hold results per label
    const detectionResultsByLabel = {};

    const detectionTasks = labelEntries.map(([label, description]) =>
      limit(async () => {
        // console.log(`[Screenshot ${screenshotId}] Starting detection for: '${label}'`);
        let detectionData = { objects: [], duration: 0, error: null };
        let status = 'Not Detected';
        try {
            detectionData = await detectSingleObject(validatedImageBuffer, description, context);
            status = detectionData.objects.length > 0 ? 'Detected' : 'Not Detected';
            // console.log(`[Screenshot ${screenshotId}] Finished detection for: '${label}' (Found: ${detectionData.objects.length})`);
        } catch (error) {
            console.error(`[Screenshot ${screenshotId}] Error in detectSingleObject for '${label}':`, error);
            detectionData.error = error;
            status = 'Error'; // Mark detection as errored
        }
        return { label, description, rawDetections: detectionData.objects, duration: detectionData.duration, status, error: detectionData.error };
      })
    );

    const settledDetectionTasks = await Promise.allSettled(detectionTasks);
    console.log(`[Screenshot ${screenshotId}] All detection tasks settled.`);

    // --- Process and Group Results ---
    // First get all labels for dynamic grouping determination
    const allLabels = labelEntries.map(([label]) => label);
    const labelToGroupMap = determineHierarchicalGroups(allLabels);
    
    const elementsByCategory = {};

    settledDetectionTasks.forEach((result, index) => {
      const [originalLabel, originalDescription] = labelEntries[index]; // Get label/desc based on original index

      if (result.status === 'fulfilled') {
        const { label, description, rawDetections, duration, status: detectionStatus, error } = result.value;

        const elementItem = {
          label: label,
          description: description,
          bounding_box: null, // Will be populated if coordinates are valid
          status: detectionStatus,
          vlm_model: VLM_MODEL_NAME,
          element_inference_time: duration, // Time for this specific label's detection
          // accuracy_score: undefined, // To be added later
          // suggested_coordinates: undefined, // To be added later
          error: error ? (error.message || 'Detection Error') : null
        };

        if (detectionStatus === 'Detected' && rawDetections.length > 0) {
          // Currently takes the first box if multiple are returned for one description.
          // Consider how to handle multiple boxes for a single label if needed.
          const boundingBoxes = processBoundingBoxes(rawDetections.slice(0, 1), label, imgWidth, imgHeight);
          if (boundingBoxes.length > 0) {
            elementItem.bounding_box = boundingBoxes[0]; // Assign the first valid box
          } else {
            // Detected but failed coordinate scaling
            elementItem.status = 'Error';
            elementItem.error = elementItem.error || 'Coordinate scaling failed';
            console.warn(`[Screenshot ${screenshotId}] Processed '${label}': Detected but failed to scale coordinates.`);
          }
        } else if (detectionStatus === 'Error') {
            console.warn(`[Screenshot ${screenshotId}] Processed '${label}': Detection failed.`);
        } else {
           // console.log(`[Screenshot ${screenshotId}] Processed '${label}': Not detected.`);
        }

        // Use the dynamically determined category instead of just first level
        const categoryName = labelToGroupMap[label] || getFirstLevelCategory(label);
        
        if (!elementsByCategory[categoryName]) {
          elementsByCategory[categoryName] = [];
        }
        elementsByCategory[categoryName].push(elementItem);

      } else {
        // Task itself failed (rejected promise from p-limit queue, shouldn't happen often with try/catch inside)
        console.error(`[Screenshot ${screenshotId}] Detection task failed unexpectedly for label '${originalLabel}':`, result.reason);
        
        // Use the dynamically determined category instead of just first level
        const categoryName = labelToGroupMap[originalLabel] || getFirstLevelCategory(originalLabel);
        
        if (!elementsByCategory[categoryName]) {
          elementsByCategory[categoryName] = [];
        }
        elementsByCategory[categoryName].push({
          label: originalLabel,
          description: originalDescription,
          bounding_box: null,
          status: 'Error',
          vlm_model: VLM_MODEL_NAME,
          element_inference_time: 0, // Unknown duration
          error: result.reason?.message || 'Unknown task error'
        });
      }
    });

    // --- Generate Component Results (Image Buffer + Data) ---
    const componentProcessingPromises = Object.entries(elementsByCategory).map(async ([categoryName, elements]) => {
        const categoryStartTime = performance.now();

        // Filter items relevant for drawing (successfully detected with boxes)
        const detectedElements = elements.filter(el => el.status === 'Detected' && el.bounding_box);

        // Generate annotated image buffer for this category
        /** @type {Buffer | null} */
        const annotatedImageBuffer = await generateAnnotatedImageBuffer(
            validatedImageBuffer,
            detectedElements,
            BOX_COLOR, // Use a consistent color or cycle colors per category if needed
            categoryName
        );

        // Save debug image if enabled and buffer exists
        if (outputDir && annotatedImageBuffer) {
           await saveAnnotatedImageDebug(annotatedImageBuffer, categoryName, outputDir);
        }
        // Save debug JSON if enabled
        if (outputDir) {
            const normalizedKey = normalizeLabel(categoryName);
            const jsonPath = path.join(outputDir, `${normalizedKey}.json`);
            await saveJson({ screenshotId, categoryName, elements }, jsonPath); // Save all elements for the category
        }


        // Determine overall status for the component
        let componentStatus = 'failed';
        const hasSuccess = elements.some(el => el.status === 'Detected');
        const hasError = elements.some(el => el.status === 'Error');
        if (hasSuccess && !hasError) {
            componentStatus = 'success';
        } else if (hasSuccess && hasError) {
            componentStatus = 'partial';
        } else if (!hasSuccess && hasError) {
            componentStatus = 'failed'; // All elements failed or errored
        } else {
            componentStatus = 'failed'; // No elements detected or processed successfully
        }

        // Aggregate inference time (sum of individual element times)
        const totalInferenceTime = elements.reduce((sum, el) => sum + el.element_inference_time, 0);

        // Construct the ComponentDetectionResult
        /** @type {ComponentDetectionResult} */
        const componentResult = {
            screenshot_id: screenshotId,
            component_name: categoryName,
            // Use placeholder buffer if generation failed? Or handle null upstream? Using null for now.
            annotated_image_object: annotatedImageBuffer,
            annotated_image_url: undefined, // To be filled after upload
            // TODO: Define how to get a meaningful component_description. Using category name for now.
            component_description: `Detection results for ${categoryName}`,
            detection_status: componentStatus,
            inference_time: totalInferenceTime, // Or use category wall time: performance.now() - categoryStartTime;
            elements: elements, // Include all elements (detected, not detected, error)
        };

        componentResults.push(componentResult);
        // console.log(`[Screenshot ${screenshotId}] Finished processing component: '${categoryName}'`);
    });

    await Promise.all(componentProcessingPromises);

    const overallDuration = performance.now() - overallStartTime;
    console.log(`[Screenshot ${screenshotId}] Annotation Complete. Total time: ${overallDuration.toFixed(2)/1000}s`);
    return componentResults;

  } catch (err) {
    // Catch errors during initial setup (e.g., image reading/conversion)
    console.error(`[Screenshot ${screenshotId}] FATAL error during Moondream processing setup:`, err);
    // Return empty array to indicate failure for this screenshot
    return [];
  }
}

/**
 * Processes an image from a file path using labels dictionary
 * @param {string} imagePath - Path to the image file
 * @param {Object} labelsDict - Dictionary of labels and their descriptions
 * @returns {Promise<Object|null>} Categories with their detected items
 */
export async function processImageFile(imagePath, labelsDict) {
  try {
    let imageBuffer = await fs.promises.readFile(imagePath);
    console.log(`Image loaded successfully from: ${imagePath}`);
    
    return processAndSaveByCategory(imageBuffer, labelsDict);
  } catch (err) {
    console.error(`Error processing image ${imagePath}: ${err}`);
    return null;
  }
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/lib/services/ai/MoondreamVLService.js
================
import { vl } from 'moondream';
import { PromptTrackingContext } from '@/lib/logger';
import { MOON_DREAM_API_KEY } from '@/config';
import fs from 'fs';

/**
 * Type definition for detection results
 */
export const DetectionResultType = {
  request_id: String,
  objects: Array
};

/**
 * Initialize the vl model with API key
 */
const model = new vl({ apiKey: `${MOON_DREAM_API_KEY}` });

/**
 * Detect objects in an image using Moondream vl client
 * 
 * @param {Buffer} imageBuffer - Buffer containing image data
 * @param {string} objectType - The object type to detect (e.g., "person", "car", "face")
 * @param {PromptTrackingContext} context - The tracking context containing batch, screenshot, and component IDs
 * @returns {Promise<Object>} A promise resolving to the detection response
 */
export async function detectObjectsFromBuffer(
  imageBuffer, 
  objectType, 
  context
) {
  try {
    // Timing specifically the API call, not surrounding logic
    const startTime = Date.now();
    
    const result = await model.detect({
      image: imageBuffer,
      object: objectType
    });
    
    const endTime = Date.now();
    const durationMs = endTime - startTime;
    
    // Log the interaction using the context with the measured duration
    await context.logPromptInteraction(
      'Moondream-vl-Detect',
      'vlm_labeling',
      `Detect ${objectType} in image`,
      JSON.stringify(result),
      durationMs,
      {
        // Moondream doesn't provide token usage, so we leave these undefined
        input: undefined,
        output: undefined,
        total: undefined
      }
    );

    console.log(`-- [Detected] "${objectType.slice(0,50)}..." in ${durationMs/1000}s`);
    return {
      request_id: result.request_id,
      objects: result.objects
    };
  } catch (err) {
    console.error('Error using Moondream vl:', err);
    throw new Error(
      `Failed to get response from Moondream vl: ${
        err instanceof Error ? err.message : String(err)
      }`
    );
  }
}

/**
 * Converts the normalized coordinates to pixel coordinates
 * 
 * @param {Object} coordinates - Object with normalized coordinates (0-1)
 * @param {number} coordinates.x_min - Minimum x coordinate (0-1)
 * @param {number} coordinates.y_min - Minimum y coordinate (0-1)
 * @param {number} coordinates.x_max - Maximum x coordinate (0-1)
 * @param {number} coordinates.y_max - Maximum y coordinate (0-1)
 * @param {number} imageWidth - Width of the image in pixels
 * @param {number} imageHeight - Height of the image in pixels
 * @returns {Object} Object with pixel coordinates
 */
export function normalizedToPixelCoordinates(coordinates, imageWidth, imageHeight) {
  return {
    x_min: Math.round(coordinates.x_min * imageWidth),
    y_min: Math.round(coordinates.y_min * imageHeight),
    x_max: Math.round(coordinates.x_max * imageWidth),
    y_max: Math.round(coordinates.y_max * imageHeight)
  };
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/lib/services/ai/OpenAIService.js
================
import OpenAI from 'openai';
import { PromptResult } from '../../../types/PromptRunner'; // Adjust the path as needed
import { EXTRACTION_PROMPT_v1, EXTRACT_ELEMENTS_PROMPT, EXTRACTION_PROMPT_v2, EXTRACTION_PROMPT_v3, EXTRACTION_PROMPT_v4, ACCURACY_VALIDATION_PROMPT_v0 } from '@/lib/prompt/prompts';
import { PromptTrackingContext } from '@/lib/logger';
import { PromptLogType } from '@/lib/constants';
import { cleanText } from '@/lib/file-utils';
// Ensure OPENAI_API_KEY is set in your environment variables
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Constants
const OPENAI_CONFIG = {
  VISION_MODEL: 'gpt-4o-2024-11-20',
  VISION_MODEL_GPT4: 'gpt-4.1-2025-04-14',
  INPUT_TOKEN_COST: 0.00001,
  OUTPUT_TOKEN_COST: 0.00003
};

/**
 * Handles the common response processing logic for OpenAI API calls
 */
async function handleOpenAIResponse(response, context, promptType, prompt, startTime) {
  const endTime = Date.now();
  const durationMs = endTime - startTime;

  const inputTokens = response?.usage?.input_tokens || 0;
  const outputTokens = response?.usage?.output_tokens || 0;
  
  await context.logPromptInteraction(
    `OpenAI-${OPENAI_CONFIG.VISION_MODEL_GPT4}`,
    promptType,
    prompt,
    JSON.stringify(response),
    durationMs,
    {
      input: inputTokens,
      output: outputTokens,
      total: response?.usage?.total_tokens
    },
    OPENAI_CONFIG.INPUT_TOKEN_COST,
    OPENAI_CONFIG.OUTPUT_TOKEN_COST
  );

  return response;
}

/**
 * Base function for making OpenAI API calls
 */
async function makeOpenAICall(messages, context, promptType, prompt) {
  const startTime = Date.now();
  
  try {
    const response = await openai.responses.create({
      model: OPENAI_CONFIG.VISION_MODEL_GPT4,
      input: messages
    });
    
    return await handleOpenAIResponse(response, context, promptType, prompt, startTime);
  } catch (error) {
    console.error('Error calling OpenAI Vision Model:', error);
    throw new Error(`Failed to get response from OpenAI: ${error instanceof Error ? error.message : String(error)}`);
  }
}

/**
 * Creates messages payload for OpenAI API
 */
function createMessagesPayload(prompt, image) {
  return [{
    role: 'user',
    content: [
      { type: 'input_text', text: prompt },
      { type: 'input_image', image_url: image }
    ],
  }];
}

/**
 * Calls the OpenAI vision model with a prompt and optional image URL.
 *
 * @param prompt The text prompt to send to the model.
 * @param imageUrl Optional URL of an image for the vision model.
 * @param context The tracking context containing batch, screenshot, and other IDs
 * @param promptType The type of prompt being processed.
 * @returns A promise resolving to the structured PromptResult.
 * @throws Throws an error if the API call fails.
 */
export async function callOpenAIVisionModelURL(
  prompt,
  imageUrl,
  context,
  promptType = PromptLogType.COMPONENT_EXTRACTION
){
  const messages = createMessagesPayload(prompt, imageUrl);
  return makeOpenAICall(messages, context, promptType, prompt);
} 

export async function callOpenAIVisionModelBase64(
  prompt,
  imageBase64,
  context,
  promptType = PromptLogType.ACCURACY_VALIDATION
) {
  const imageUrl = `data:image/jpeg;base64,${imageBase64}`;
  const messages = createMessagesPayload(prompt, imageUrl);
  return makeOpenAICall(messages, context, promptType, prompt);
}

/**
 * Extracts components from an image using the OpenAI vision model.
 *
 * @param imageUrl The URL of the image to analyze.
 * @param context The tracking context containing batch, screenshot, and other IDs
 * @returns A promise resolving to the structured PromptResult.
 * @throws Throws an error if the API call fails.
 */
export async function extract_component_from_image(imageUrl, context) {
  const result = await callOpenAIVisionModelURL(
    EXTRACTION_PROMPT_v4, 
    imageUrl, 
    context,
    PromptLogType.COMPONENT_EXTRACTION
  );
  
  return processResponse(result, `Component extraction failed for URL: ${imageUrl}`);
}

export async function validate_bounding_boxes_base64(imageBase64, context, elementsJson) {
  // Create prompt with elements JSON included
  const prompt = elementsJson 
    ? `${ACCURACY_VALIDATION_PROMPT_v0}\n\nHere are the elements to evaluate:\n${elementsJson}`
    : ACCURACY_VALIDATION_PROMPT_v0;
    
  const result = await callOpenAIVisionModelBase64(
    prompt, 
    imageBase64, 
    context,
    PromptLogType.ACCURACY_VALIDATION
  );

  return processResponse(result, 'Bounding box validation failed for image');
}

/**
 * Processes OpenAI response data
 */
function processResponse(result, errorMessage) {
  if (!result || result.status !== 'completed') {
    throw new Error(errorMessage);
  }

  const { parsedContent, usage } = extractOpenAIResponseData(result);
  return { parsedContent, usage };
}

/**
 * Helper: Parses OpenAI's output_text string into a JSON object safely.
 *
 * @param rawText - The raw `output_text` returned from OpenAI.
 * @returns Parsed JSON object.
 */
function parseOpenAIOutputTextToJson(rawText) {
  try {
    const cleaned = rawText
    .replace(/,\s*}/g, '}') // remove trailing commas
    .replace(/,\s*]/g, ']') // remove trailing commas
    .trim();

    return JSON.parse(cleaned);

    // const jsonRegex = /```(?:json)?\s*({[\s\S]*?})\s*```|({[\s\S]*})/;
    // const match = rawText.match(jsonRegex);
    
    // const jsonContent = match ? (match[1] || match[2]) : rawText;
    // const cleanedText = cleanText(jsonContent);

    // return JSON.parse(cleanedText);
  } catch (error) {
    console.error('Failed to parse OpenAI output_text as JSON:', error);
    return [];
  }
}


/**
 * Extracts structured content and usage metadata from OpenAI's response.
 *
 * @param response - Full OpenAI response object.
 * @returns Object containing parsed output_text and token usage info.
 */
export function extractOpenAIResponseData(response) {
  const rawText = response?.output_text ?? '';
  const parsedContent = parseOpenAIOutputTextToJson(rawText);

  const usage = {
    input_tokens: response?.usage?.input_tokens,
    output_tokens: response?.usage?.output_tokens,
    total_tokens: response?.usage?.total_tokens
  };

  return {
    parsedContent,
    rawText,
    usage,
  };
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/lib/services/imageServices/BoundingBoxService.js
================
import Jimp from 'jimp';
import fs from 'fs';
import path from 'path';

// --- Constants ---
const BOX_COLOR = 0xFF0000FF; // RGBA Red color
const BOX_WIDTH = 2;
const OVERLAY_COLOR = 0x80808080; // RGBA semi-transparent gray
const OVERLAY_ALPHA = 0.5;
const REFERENCE_POINT_COLOR = 0x00FF00FF; // RGBA Green color
const REFERENCE_POINT_SIZE = 4;
const TEXT_COLOR = 0xFFFFFFFF; // RGBA White color
const TEXT_BACKGROUND = 0x000000AA; // RGBA Black color with some transparency

const SHOW_COORDINATES = process.env.SHOW_COORDINATES === 'true';

/**
 * Normalizes a label string into a file/key-friendly format
 * @param {string} label - The label to normalize
 * @returns {string} Normalized label string
 */
function normalizeLabel(label) {
  return label.toLowerCase().replace(/\s/g, '_').replace(/>/g, '_').replace(/\//g, '_');
}

/**
 * Draw a rectangle with a specific width
 * @param {Jimp} image - Jimp image to draw on
 * @param {number} x - X coordinate of top-left corner
 * @param {number} y - Y coordinate of top-left corner
 * @param {number} width - Width of the rectangle
 * @param {number} height - Height of the rectangle
 * @param {number} color - Color of the rectangle (RGBA hex)
 * @param {number} lineWidth - Width of the rectangle border
 */
function drawRect(image, x, y, width, height, color, lineWidth) {
  // Draw top line
  image.scan(x, y, width, lineWidth, function(cx, cy, idx) {
    this.bitmap.data[idx] = (color >> 24) & 0xFF;     // R
    this.bitmap.data[idx + 1] = (color >> 16) & 0xFF; // G
    this.bitmap.data[idx + 2] = (color >> 8) & 0xFF;  // B
    this.bitmap.data[idx + 3] = color & 0xFF;         // A
  });
  
  // Draw bottom line
  image.scan(x, y + height - lineWidth, width, lineWidth, function(cx, cy, idx) {
    this.bitmap.data[idx] = (color >> 24) & 0xFF;     // R
    this.bitmap.data[idx + 1] = (color >> 16) & 0xFF; // G
    this.bitmap.data[idx + 2] = (color >> 8) & 0xFF;  // B
    this.bitmap.data[idx + 3] = color & 0xFF;         // A
  });
  
  // Draw left line
  image.scan(x, y, lineWidth, height, function(cx, cy, idx) {
    this.bitmap.data[idx] = (color >> 24) & 0xFF;     // R
    this.bitmap.data[idx + 1] = (color >> 16) & 0xFF; // G
    this.bitmap.data[idx + 2] = (color >> 8) & 0xFF;  // B
    this.bitmap.data[idx + 3] = color & 0xFF;         // A
  });
  
  // Draw right line
  image.scan(x + width - lineWidth, y, lineWidth, height, function(cx, cy, idx) {
    this.bitmap.data[idx] = (color >> 24) & 0xFF;     // R
    this.bitmap.data[idx + 1] = (color >> 16) & 0xFF; // G
    this.bitmap.data[idx + 2] = (color >> 8) & 0xFF;  // B
    this.bitmap.data[idx + 3] = color & 0xFF;         // A
  });
}

/**
 * Draw a filled rectangle on the image
 * @param {Jimp} image - Jimp image to draw on
 * @param {number} x - X coordinate of top-left corner
 * @param {number} y - Y coordinate of top-left corner
 * @param {number} width - Width of the rectangle
 * @param {number} height - Height of the rectangle
 * @param {number} color - Color of the rectangle (RGBA hex)
 */
function fillRect(image, x, y, width, height, color) {
  // Make sure coordinates are integers and within bounds
  const startX = Math.max(0, Math.floor(x));
  const startY = Math.max(0, Math.floor(y));
  const imgWidth = image.getWidth();
  const imgHeight = image.getHeight();
  
  // Ensure width/height calculations don't exceed image boundaries
  const endX = Math.min(imgWidth, startX + width);
  const endY = Math.min(imgHeight, startY + height);
  
  const drawWidth = endX - startX;
  const drawHeight = endY - startY;
  
  if (drawWidth <= 0 || drawHeight <= 0) return;
  
  image.scan(startX, startY, drawWidth, drawHeight, function(cx, cy, idx) {
    this.bitmap.data[idx] = (color >> 24) & 0xFF;     // R
    this.bitmap.data[idx + 1] = (color >> 16) & 0xFF; // G
    this.bitmap.data[idx + 2] = (color >> 8) & 0xFF;  // B
    this.bitmap.data[idx + 3] = color & 0xFF;         // A
  });
}

/**
 * Creates a transparent area in the overlay for detected objects
 * @param {Jimp} overlay - Overlay image to modify
 * @param {number} x - X coordinate of top-left corner
 * @param {number} y - Y coordinate of top-left corner
 * @param {number} width - Width of the transparent area
 * @param {number} height - Height of the transparent area
 * @param {number} boxWidth - Width of the border that should remain opaque
 */
function createTransparentArea(overlay, x, y, width, height, boxWidth) {
   // Ensure x, y, width, height are within overlay bounds and integers
   const overlayWidth = overlay.getWidth();
   const overlayHeight = overlay.getHeight();

   const startX = Math.max(0, Math.floor(x + boxWidth));
   const startY = Math.max(0, Math.floor(y + boxWidth));
   const endX = Math.min(overlayWidth, Math.floor(x + width - boxWidth));
   const endY = Math.min(overlayHeight, Math.floor(y + height - boxWidth));

   const clearWidth = Math.max(0, endX - startX);
   const clearHeight = Math.max(0, endY - startY);

   if (clearWidth > 0 && clearHeight > 0) {
       overlay.scan(startX, startY, clearWidth, clearHeight, function(cx, cy, idx) {
           this.bitmap.data[idx + 3] = 0; // Set alpha to 0 (fully transparent)
       });
   }
}

/**
 * Draw a simple coordinate label directly with pixel rectangles
 * @param {Jimp} image - Jimp image to draw on
 * @param {number} x - X coordinate for text start
 * @param {number} y - Y coordinate for text start
 * @param {string} value - Value to display
 * @param {number} color - Text color
 */
function drawCoordinateLabel(image, x, y, value, color = TEXT_COLOR) {
  // First draw background for better visibility
  const padding = 2;
  const charWidth = 5;
  const charHeight = 7;
  const totalWidth = value.length * (charWidth + 1) + padding * 2;
  const totalHeight = charHeight + padding * 2;
  
  // Ensure text stays within image bounds
  const imgWidth = image.getWidth();
  const imgHeight = image.getHeight();
  
  const textX = Math.max(0, Math.min(imgWidth - totalWidth, x));
  const textY = Math.max(0, Math.min(imgHeight - totalHeight, y));
  
  // Draw background
  fillRect(image, textX, textY, totalWidth, totalHeight, TEXT_BACKGROUND);
  
  // Draw text value
  image.scan(textX, textY, totalWidth, totalHeight, function(cx, cy, idx) {
    // Set entire area to the background color with some transparency
    this.bitmap.data[idx + 3] = 180; // Alpha component
  });
  
  // Place coordinate values as plain text using a simple technique
  const text = value;
  let currentX = textX + padding;
  
  for (let i = 0; i < text.length; i++) {
    // Draw a small rectangle for each character with the text color
    // This is a simple way to "stamp" the presence of text without rendering actual fonts
    fillRect(image, currentX, textY + padding, charWidth, charHeight, color);
    currentX += charWidth + 1;
  }
}

/**
 * Draw reference points at 0%, 25%, 50%, 75%, and 100% positions on each edge of the image
 * @param {Jimp} image - Jimp image to draw on
 * @param {number} imgWidth - Width of the image
 * @param {number} imgHeight - Height of the image
 * @param {number} color - Color for reference points (RGBA hex)
 * @param {number} pointSize - Size of the reference points
 */
function drawReferencePoints(image, imgWidth, imgHeight, color = REFERENCE_POINT_COLOR, pointSize = REFERENCE_POINT_SIZE) {
  const percentages = [0, 0.25, 0.5, 0.75, 1.0];
  
  // Top edge points
  percentages.forEach(percent => {
    const x = Math.floor(percent * (imgWidth - 1));
    const y = 0;
    
    // Draw point (larger to be more visible)
    fillRect(image, x - pointSize/2, y - pointSize/2, pointSize, pointSize, color);
    
    // Draw coordinate label
    const labelText = `(${x},${y})`;
    drawCoordinateLabel(image, x - 20, y + pointSize * 2, labelText);
  });
  
  // Bottom edge points
  percentages.forEach(percent => {
    const x = Math.floor(percent * (imgWidth - 1));
    const y = imgHeight - 1;
    
    // Draw point
    fillRect(image, x - pointSize/2, y - pointSize/2, pointSize, pointSize, color);
    
    // Draw coordinate label
    const labelText = `(${x},${y})`;
    drawCoordinateLabel(image, x - 20, y - 20, labelText);
  });
  
  // Left edge points
  percentages.forEach(percent => {
    const x = 0;
    const y = Math.floor(percent * (imgHeight - 1));
    
    // Draw point
    fillRect(image, x - pointSize/2, y - pointSize/2, pointSize, pointSize, color);
    
    // Draw coordinate label
    const labelText = `(${x},${y})`;
    drawCoordinateLabel(image, x + pointSize * 2, y - 10, labelText);
  });
  
  // Right edge points
  percentages.forEach(percent => {
    const x = imgWidth - 1;
    const y = Math.floor(percent * (imgHeight - 1));
    
    // Draw point
    fillRect(image, x - pointSize/2, y - pointSize/2, pointSize, pointSize, color);
    
    // Draw coordinate label
    const labelText = `(${x},${y})`;
    drawCoordinateLabel(image, x - 50, y - 10, labelText);
  });
}

/**
 * Generates an annotated image buffer for a specific component/category
 * @param {Buffer} baseImageBuffer - The original image buffer
 * @param {Array} detectedItems - Detected items for this component
 * @param {number} color - Color for bounding boxes (defaults to BOX_COLOR)
 * @param {string} categoryName - Name of the category (for logging)
 * @returns {Promise<Buffer|null>} Buffer of the annotated image, or null on error
 */
async function generateAnnotatedImageBuffer(baseImageBuffer, detectedItems, color = BOX_COLOR, categoryName) {
  const itemsToDraw = detectedItems.filter(item => item.status === 'Detected' && item.bounding_box);

  try {
    const baseImage = await Jimp.read(baseImageBuffer);
    const imgWidth = baseImage.getWidth();
    const imgHeight = baseImage.getHeight();

    // If there are no items to draw but we need to show coordinates, draw them on the base image
    if (itemsToDraw.length === 0) {
      if (SHOW_COORDINATES) {
        drawReferencePoints(baseImage, imgWidth, imgHeight);
      }
      return await baseImage.getBufferAsync(Jimp.MIME_PNG); // Ensure consistent format
    }

    // Create a semi-transparent overlay
    const overlay = new Jimp(imgWidth, imgHeight, OVERLAY_COLOR);

    // Sort itemsToDraw by area (descending) to process larger boxes first
    // This prevents large-box clear from erasing smaller borders
    itemsToDraw.sort((a, b) => {
      const areaA = (a.bounding_box.x_max - a.bounding_box.x_min) * (a.bounding_box.y_max - a.bounding_box.y_min);
      const areaB = (b.bounding_box.x_max - b.bounding_box.x_min) * (b.bounding_box.y_max - b.bounding_box.y_min);
      return areaB - areaA; // Descending order
    });

    // Process each detection and draw boxes on the overlay
    for (const item of itemsToDraw) {
      const { x_min, y_min, x_max, y_max } = item.bounding_box;

      // Make sure coordinates are integers and within bounds
      const x = Math.max(0, Math.floor(x_min));
      const y = Math.max(0, Math.floor(y_min));
      // Ensure width/height calculations don't exceed image boundaries
      const potentialWidth = Math.ceil(x_max - x_min);
      const potentialHeight = Math.ceil(y_max - y_min);
      const width = Math.min(imgWidth - x, potentialWidth);
      const height = Math.min(imgHeight - y, potentialHeight);

      if (width <= 0 || height <= 0) {
        console.warn(`Invalid box dimensions for item '${item.label}' in category '${categoryName}': ${width}x${height}`);
        continue;
      }

      // Draw the box outline on the overlay
      drawRect(overlay, x, y, width, height, color, BOX_WIDTH);

      // Create transparent area inside the box
      createTransparentArea(overlay, x, y, width, height, BOX_WIDTH);
    }

    // Composite the overlay onto the base image
    baseImage.composite(overlay, 0, 0, {
      mode: Jimp.BLEND_SOURCE_OVER,
      opacitySource: 1, // Use overlay's alpha
      opacityDest: 1
    });

    // Draw reference points if SHOW_COORDINATES is true
    if (SHOW_COORDINATES) {
      drawReferencePoints(baseImage, imgWidth, imgHeight);
    }

    // Return the buffer
    const annotatedBuffer = await baseImage.getBufferAsync(Jimp.MIME_PNG);
    // console.log(`Generated annotated image buffer for category '${categoryName}'.`);
    return annotatedBuffer;

  } catch (err) {
    console.error(`Error generating annotated image buffer for category '${categoryName}': ${err}`);
    return null;
  }
}

/**
 * Renders a category image (for debugging/local saving)
 * @param {Buffer} annotatedImageBuffer - The generated annotated image buffer
 * @param {string} categoryName - Name of the category
 * @param {string} outputDir - Directory to save output
 * @returns {Promise<void>}
 */
async function saveAnnotatedImageDebug(annotatedImageBuffer, categoryName, outputDir) {
   if (!annotatedImageBuffer || process.env.SAVE_DEBUG_FILES !== 'true') {
     return; // Don't save if buffer is null or debug saving is off
   }
   try {
     const normalizedKey = normalizeLabel(categoryName);
     const savePath = path.join(outputDir, `${normalizedKey}.png`);
     await fs.promises.writeFile(savePath, annotatedImageBuffer);
    //  console.log(`Debug image saved successfully to: ${savePath}`);
   } catch (err) {
     console.error(`Error saving debug image for '${categoryName}': ${err}`);
   }
}

export {
  BOX_COLOR,
  BOX_WIDTH,
  OVERLAY_COLOR,
  OVERLAY_ALPHA,
  REFERENCE_POINT_COLOR,
  REFERENCE_POINT_SIZE,
  TEXT_COLOR,
  TEXT_BACKGROUND,
  drawRect,
  fillRect,
  createTransparentArea,
  drawCoordinateLabel,
  drawReferencePoints,
  generateAnnotatedImageBuffer,
  saveAnnotatedImageDebug,
  normalizeLabel
};

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/lib/services/imageServices/imageFetchingService.ts
================
import { BatchProcessingScreenshot as Screenshot } from '@/types/BatchProcessingScreenshot';
import { Buffer } from 'buffer';

/**
 * Fetches an image and returns it as a Buffer for direct use in image processing.
 * Provides raw binary data with minimal overhead compared to Blob or Base64.
 *
 * @param imageUrl - the signed URL (or any URL) of the image
 * @returns a promise resolving to a Buffer containing the image data
 */
export async function fetchImageAsBuffer(imageUrl: string): Promise<Buffer | null> {
  try {
    const res = await fetch(imageUrl);
    if (!res.ok) throw new Error(`HTTP ${res.status} ${res.statusText}`);
    
    // Get the raw ArrayBuffer first
    const arrayBuffer = await res.arrayBuffer();
    
    // Convert ArrayBuffer to Buffer
    const buffer = Buffer.from(arrayBuffer);
    
    // console.log(`Successfully fetched image buffer (${buffer.byteLength} bytes)`);
    return buffer;
  } catch (err) {
    console.error("Error fetching image as buffer:", err);
    return null;
  }
}

/**
 * Fetches image data as Buffer for multiple screenshots with signed URLs
 * @param screenshots Array of screenshot objects with screenshot_signed_url property
 * @returns The same array with screenshot_image_buffer property populated
 */
export async function fetchScreenshotBuffers(screenshots: Screenshot[]): Promise<Screenshot[]> {
  // console.log(`Fetching image buffers for ${screenshots.length} screenshots...`);
  
  // Create an array of promises for fetching each image
  const fetchPromises = screenshots.map(async (screenshot) => {
    // Skip screenshots without a signed URL
    if (!screenshot.screenshot_signed_url) {
      console.warn(`Screenshot ID ${screenshot.screenshot_id} has no signed URL, skipping buffer fetch`);
      screenshot.screenshot_image_buffer = null;
      return screenshot;
    }
    
    try {
      // Fetch the image buffer and attach it directly
      screenshot.screenshot_image_buffer = await fetchImageAsBuffer(screenshot.screenshot_signed_url);
      
      if (screenshot.screenshot_image_buffer) {
        console.log(`Successfully fetched buffer for screenshot ID ${screenshot.screenshot_id} (${screenshot.screenshot_image_buffer.byteLength} bytes)`);
      }
    } catch (error) {
      console.error(`Error fetching buffer for screenshot ID ${screenshot.screenshot_id}:`, error);
      screenshot.screenshot_image_buffer = null;
    }
    
    return screenshot;
  });
  
  // Wait for all fetch operations to complete
  const updatedScreenshots = await Promise.all(fetchPromises);
  
  // Log summary of results
  const successCount = updatedScreenshots.filter(s => s.screenshot_image_buffer !== null).length;
  // console.log(`Fetched ${successCount}/${screenshots.length} image buffers successfully`);
  
  return updatedScreenshots;
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/lib/services/imageServices/ImageProcessor.ts
================
import sharp from 'sharp'
import fs from 'fs'
import path from 'path'
// import { v4 as uuidv4 } from 'uuid'

// Constants instead of magic numbers
const MAX_FILE_SIZE_MB = 1
const DEFAULT_TARGET_WIDTH = 800
const DEFAULT_TARGET_HEIGHT = 800
const DEFAULT_JPEG_QUALITY = 80

// Temporary directory for processed images
const TEMP_DIR = path.join(process.cwd(), 'tmp')

/**
 * Normalizes a filename by removing special characters and spaces
 * @param filename - Original filename to normalize
 * @returns Normalized filename with only alphanumeric characters, dots, and hyphens
 */
function sanitizeFilename(filename: string): string {
  // Remove file extension
  const { name, ext } = path.parse(filename)
  
  // Replace spaces and special characters with hyphens
  const normalized = name
    .toLowerCase()
    .replace(/[^a-z0-9]/g, '-') // Replace non-alphanumeric with hyphens
    .replace(/-+/g, '-')        // Replace multiple hyphens with single hyphen
    .replace(/^-|-$/g, '')      // Remove leading/trailing hyphens
  
  // Add timestamp to ensure uniqueness
  return `${normalized}${ext}`
}

// Ensure temp directory exists
if (!fs.existsSync(TEMP_DIR)) {
  fs.mkdirSync(TEMP_DIR, { recursive: true })
}

interface ProcessedImage {
  buffer: Buffer;
  filename: string;
}

/**
 * Compresses and pads an image to make it uniform in size
 * @param imageBuffer - The raw image buffer
 * @param originalFilename - Original filename to preserve
 * @param targetWidth - Desired width after processing
 * @param targetHeight - Desired height after processing
 * @returns Object containing the path and filename of the processed image
 */
export async function resizeAndPadImageBuffer(
  imageBuffer: Buffer,
  originalFilename: string,
  targetWidth: number = DEFAULT_TARGET_WIDTH,
  targetHeight: number = DEFAULT_TARGET_HEIGHT
): Promise<ProcessedImage> {
  const filename = sanitizeFilename(originalFilename)
  
  try {
    const metadata = await sharp(imageBuffer).metadata()
    
    // Calculate resize dimensions while maintaining aspect ratio
    let resizeWidth = targetWidth
    let resizeHeight = targetHeight
    
    if (metadata.width && metadata.height) {
      const aspectRatio = metadata.width / metadata.height
      
      if (aspectRatio > 1) {
        // Landscape image
        resizeHeight = Math.round(targetWidth / aspectRatio)
      } else {
        // Portrait image
        resizeWidth = Math.round(targetHeight * aspectRatio)
      }
    }
    
    // Process image and return buffer directly
    const processedBuffer = await sharp(imageBuffer)
      .resize(resizeWidth, resizeHeight, {
        fit: 'inside',
        withoutEnlargement: true
      })
      .jpeg({ quality: DEFAULT_JPEG_QUALITY }) // Compress to reduce file size
      .toBuffer()
      .then(resizedBuffer => {
        // Create a blank canvas with the target dimensions
        return sharp({
          create: {
            width: targetWidth,
            height: targetHeight,
            channels: 4,
            background: { r: 255, g: 255, b: 255, alpha: 1 }
          }
        })
        .composite([{
          input: resizedBuffer,
          gravity: 'center'
        }])
        .jpeg({ quality: DEFAULT_JPEG_QUALITY })
        .toBuffer()
      })

    return {
      buffer: processedBuffer,
      filename
    }
  } catch (error) {
    console.error('Error processing image:', error)
    throw error
  }
}

/**
 * Cleans up a temporary file
 */
export function deleteFile(filePath: string): void {
  try {
    if (fs.existsSync(filePath)) {
      fs.unlinkSync(filePath)
    }
  } catch (error) {
    console.error('Error cleaning up temp file:', error)
  }
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/lib/services/imageServices/screenshotProcessor.ts
================
import { File } from 'formidable';
import fs from 'fs';
import { resizeAndPadImageBuffer, deleteFile } from '@/lib/services/imageServices/ImageProcessor';
import { uploadImageToStorage } from '@/lib/storage';
import { supabase } from '@/lib/supabase'; // Assuming shared Supabase client
import { SupabaseClient } from '@supabase/supabase-js';

interface ProcessedImage {
  processedBlob: Blob;
  filename: string;
  processingTime?: number; // In seconds
}

export class ScreenshotProcessor {
  private supabaseClient: SupabaseClient;

  // Allow injecting Supabase client for testability/flexibility
  constructor(supabaseClient: SupabaseClient = supabase) {
    this.supabaseClient = supabaseClient;
  }

  /**
   * Processes a single uploaded file: resizes, pads, uploads to storage,
   * and saves the record in the database.
   * @param file The uploaded file object from formidable.
   * @param batchId The ID of the batch this screenshot belongs to.
   * @returns The name and URL of the uploaded screenshot.
   * @throws Error if any step fails.
   */
  public async processAndSave(file: File, batchId: number): Promise<{ name: string; url: string }> {
    if (!file || !file.filepath) {
        throw new Error('Invalid file provided to ScreenshotProcessor.');
    }
    
    const processedImage = await this.processUploadedFile(file);
    const savedRecord = await this.saveScreenshotRecord(processedImage, batchId);
    
    // Clean up the temporary file after successful processing and saving
    try {
        deleteFile(file.filepath);
    } catch (cleanupError) {
        // Log cleanup error but don't fail the operation
        console.error(`Failed to delete temporary file ${file.filepath}:`, cleanupError);
    }

    return savedRecord;
  }

  /**
   * Reads, resizes, and pads the image file.
   * @param file The uploaded file object.
   * @returns Processed image data.
   */
  private async processUploadedFile(file: File): Promise<ProcessedImage> {
    const fileBuffer = fs.readFileSync(file.filepath);
    const startTime = Date.now();
    const originalFilename = file.originalFilename ?? `unnamed_${Date.now()}`;

    // Perform image resizing and padding
    const processed = await resizeAndPadImageBuffer(fileBuffer, originalFilename);
    const processingTime = (Date.now() - startTime) / 1000; // Convert ms to seconds

    return {
      processedBlob: new Blob([processed.buffer], { type: 'image/jpeg' }), // Assuming JPEG output
      filename: processed.filename,
      processingTime,
    };
  }

  /**
   * Uploads the processed image to storage and saves the metadata to the database.
   * @param image Processed image data.
   * @param batchId The batch ID.
   * @returns The name and URL of the uploaded screenshot.
   */
  private async saveScreenshotRecord(
    image: ProcessedImage,
    batchId: number
  ): Promise<{ name: string; url: string }> {
    // Upload to Supabase storage
    const { fileUrl, error: uploadError } = await uploadImageToStorage(
      image.processedBlob,
      batchId,
      image.filename
    );
    if (uploadError) {
        console.error('Supabase storage upload error:', uploadError);
        throw new Error(`Failed to upload ${image.filename} to storage.`);
    }

    // Insert record into Supabase database
    const { error: dbError } = await this.supabaseClient
      .from('screenshot')
      .insert({
        batch_id: batchId,
        screenshot_file_name: image.filename,
        screenshot_file_url: fileUrl,
        screenshot_processing_status: 'pending', // Initial status before extraction
        screenshot_processing_time: image.processingTime ? `${image.processingTime.toFixed(2)} seconds` : null,
      });

    if (dbError) {
      console.error('Supabase screenshot insert error:', dbError);
      // Attempt to delete the uploaded file if DB insert fails to avoid orphans
      try {
          // TODO: Implement deletion from storage if needed
          console.warn(`DB insert failed for ${image.filename}, corresponding storage file might be orphaned: ${fileUrl}`);
      } catch (deleteError) {
          console.error(`Failed to delete orphaned storage file ${fileUrl}:`, deleteError);
      }
      throw new Error(`Failed to save screenshot record for ${image.filename}.`);
    }

    return {
      name: image.filename,
      url: fileUrl,
    };
  }
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/lib/services/AccuracyValidationService.ts
================
import { ComponentDetectionResult, ElementDetectionItem } from '@/types/DetectionResult';
import { validate_bounding_boxes_base64 } from '@/lib/services/ai/OpenAIService';
import pLimit from 'p-limit';
import { generateAnnotatedImageBuffer } from '@/lib/services/imageServices/BoundingBoxService';
import { createScreenshotTrackingContext } from '@/lib/logger';
import { PromptLogType } from '@/lib/constants'

// Constants for accuracy score thresholds
const ACCURACY_THRESHOLDS = {
  HIGH: 85, // Green boxes
  MEDIUM: 70, // Yellow/orange boxes
  LOW: 50, // Overwrite/redashed + suggested orange box
};

// Box colors for different accuracy levels
const BOX_COLORS = {
  HIGH: 0x00FF00FF, // Green (RGBA)
  MEDIUM: 0xFFA500FF, // Orange (RGBA)
  LOW: 0xFF0000FF, // Red (RGBA)
  SUGGESTED: 0xFFA500FF, // Orange for suggested box (RGBA)
};

// Concurrency limit for validation
const VALIDATION_CONCURRENCY = 5;

// Interface for validated element from OpenAI
interface ValidatedElement {
  label: string;
  accuracy_score: number;
  suggested_coordinates?: {
    x_min: number;
    y_min: number;
    x_max: number;
    y_max: number;
  };
}

// Interface for validation data from OpenAI
interface ValidationData {
  elements: ValidatedElement[];
}

/**
 * AccuracyValidationService
 * 
 * This service validates the accuracy of detected UI elements by:
 * 1. Processing components in parallel with controlled concurrency
 * 2. For each component, validating the accuracy of bounding boxes using OpenAI
 * 3. Re-rendering annotated images with different colors based on accuracy
 * 4. Adding accuracy scores and suggested coordinates to each element
 */
export class AccuracyValidationService {
  /**
   * Validates the accuracy of detected UI elements and updates their metadata
   * 
   * @param batchId - The ID of the batch being processed
   * @param components - Array of ComponentDetectionResult to validate
   * @returns The components array with updated elements and re-annotated images
   */
  public static async performAccuracyValidation(
    batchId: number,
    components: ComponentDetectionResult[]
  ): Promise<ComponentDetectionResult[]> {
    console.log(`[Batch ${batchId}] Stage 3: Starting Accuracy Validation for ${components.length} components...`);
    
    // Create a concurrency limiter
    const validationLimit = pLimit(VALIDATION_CONCURRENCY);
    
    // Process each component in parallel
    const validationPromises = components.map(component => 
      validationLimit(async () => {
        const screenshotId = component.screenshot_id;
        console.log(`[Batch ${batchId}] Stage 3: Validating component ${component.component_name} for screenshot ${screenshotId}...`);
        
        try {
          // Create tracking context for logging
          const context = createScreenshotTrackingContext(batchId, screenshotId);
          
          // Base64 encode the annotated image
          const imageBase64 = component.annotated_image_object.toString('base64');
          
          // Create elements JSON to send to OpenAI
          const elementsJson = JSON.stringify(component.elements);
          
          // Call OpenAI to validate bounding boxes
          const validationResult = await validate_bounding_boxes_base64(
            imageBase64,
            context,
            elementsJson
          );
          
          const validationData = validationResult.parsedContent as ValidationData;
          
          // Update elements with accuracy scores and suggested coordinates
          // This mutates the elements array in-place
          this.updateElementsWithValidation(component.elements, validationData);
          
          // Re-render the component's image with updated bounding boxes
          const updatedImageBuffer = await this.regenerateAnnotatedImage(
            component.annotated_image_object,
            component.elements
          );
          
          // Update the component with the new image buffer
          if (updatedImageBuffer) {
            component.annotated_image_object = updatedImageBuffer;
          }
          
          console.log(`[Batch ${batchId}] Stage 3: Completed validation for component ${component.component_name}`);
          
          return component;
        } catch (error) {
          console.error(`[Batch ${batchId}] Stage 3: Error validating component ${component.component_name}:`, error);
          // Return the original component if validation fails
          return component;
        }
      })
    );
    
    // Wait for all components to be validated
    const validatedComponents = await Promise.all(validationPromises);
    
    console.log(`[Batch ${batchId}] Stage 3: Completed Accuracy Validation for all components`);
    
    return validatedComponents;
  }
  
  /**
   * Updates elements with accuracy scores and suggested coordinates
   * 
   * @param elements - Array of elements to update
   * @param validationData - Validation data from OpenAI
   */
  private static updateElementsWithValidation(
    elements: ElementDetectionItem[],
    validationData: ValidationData
  ): void {
    // Ensure validation data has the expected format
    if (!validationData || !Array.isArray(validationData.elements)) {
      console.warn('Invalid validation data format');
      return;
    }
    
    // Create a map of elements by label for easier lookup
    const elementMap = new Map<string, ElementDetectionItem>();
    elements.forEach(element => {
      elementMap.set(element.label, element);
    });
    
    // Update elements with validation data
    validationData.elements.forEach((validatedElement: ValidatedElement) => {
      const element = elementMap.get(validatedElement.label);
      
      if (element) {
        // Add accuracy score
        element.accuracy_score = validatedElement.accuracy_score;
        
        // Add suggested coordinates if accuracy is below threshold
        if (validatedElement.accuracy_score < ACCURACY_THRESHOLDS.LOW && validatedElement.suggested_coordinates) {
          element.suggested_coordinates = validatedElement.suggested_coordinates;
        }
      }
    });
  }
  
  /**
   * Regenerates the annotated image with colored bounding boxes based on accuracy
   * 
   * @param originalImageBuffer - The original image buffer
   * @param elements - Array of elements with accuracy scores
   * @returns New image buffer with colored bounding boxes
   */
  private static async regenerateAnnotatedImage(
    originalImageBuffer: Buffer,
    elements: ElementDetectionItem[]
  ): Promise<Buffer | null> {
    // Process each element to determine its color based on accuracy
    const coloredElements = elements.map(element => {
      const accuracy = element.accuracy_score || 0;
      let color = BOX_COLORS.HIGH;
      
      if (accuracy < ACCURACY_THRESHOLDS.LOW) {
        color = BOX_COLORS.LOW;
      } else if (accuracy < ACCURACY_THRESHOLDS.MEDIUM) {
        color = BOX_COLORS.MEDIUM;
      }
      
      return {
        ...element,
        boxColor: color,
        // If accuracy is low and we have suggested coordinates, use those
        useAlternateBox: accuracy < ACCURACY_THRESHOLDS.LOW && element.suggested_coordinates != null,
        alternateBoxColor: BOX_COLORS.SUGGESTED,
      };
    });
    
    // Generate a new annotated image with colored boxes
    try {
      return await generateAnnotatedImageBuffer(
        originalImageBuffer,
        coloredElements,
        undefined, // Use default color, our elements have custom boxColor property
        PromptLogType.ACCURACY_VALIDATION // Category name for logging
      );
    } catch (error) {
      console.error('Error generating annotated image buffer:', error);
      return null;
    }
  }
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/lib/services/batchProcessingService.ts
================
import { supabase } from '@/lib/supabase'; 
import { SupabaseClient } from '@supabase/supabase-js';
import { generateSignedUrls, getScreenshotPath, getSignedUrls } from '@/lib/supabaseUtils';
import { fetchScreenshotBuffers } from '@/lib/services/imageServices/imageFetchingService';
import { BatchProcessingScreenshot as Screenshot } from '@/types/BatchProcessingScreenshot';
import type { ComponentDetectionResult } from '@/types/DetectionResult'; 
import pLimit from 'p-limit';
import { AIExtractionService, Stage1Result } from '@/lib/services/ParallelExtractionService';
import { ParallelMoondreamDetectionService } from '@/lib/services/ParallelAnnotationService';
import { AccuracyValidationService } from '@/lib/services/AccuracyValidationService';
import { EXTRACTION_CONCURRENCY, MOONDREAM_CONCURRENCY, ProcessStatus } from '@/lib/constants';


// --- Constants ---
// const EXTRACTION_CONCURRENCY = 5; // Concurrency limit for OpenAI/Claude calls
// const MOONDREAM_CONCURRENCY = 5; // Limit concurrency for Moondream processing per batch

export class BatchProcessingService {
  private supabaseClient: SupabaseClient;

  // Update constructor to accept StorageService
  constructor(
    supabaseClient: SupabaseClient = supabase,
  ) {
    this.supabaseClient = supabaseClient;
  }

  /**
   * Starts the processing pipeline for a given batch.
   * Changes status, fetches screenshots, gets signed URLs, processes each, and updates status.
   * @param batchId The ID of the batch to process.
   */
  public async start(batchId: number): Promise<void> {
    // console.log(`[Batch ${batchId}] Starting processing...`);
    // const initialStatus = 'processing'; // More generic starting status
    // await this.updateBatchStatus(batchId, initialStatus);

    try {
      // --- Setup 0: Load Screenshots, URLs, Buffers ---
      const screenshotsToProcess = await this.loadAndPrepareScreenshots(batchId);
      if (!screenshotsToProcess || screenshotsToProcess.length === 0) {
        return; // Early return handled in the helper function with appropriate status updates
      }

      // --- Stage 1: Parallel AI Component/Element/Anchor Extraction ---
      await this.updateBatchStatus(batchId, ProcessStatus.EXTRACTING);
      console.log(`[Batch ${batchId}] Begin Parallel Extraction on ${screenshotsToProcess.length} screenshots`);
      
      // Use the external AIExtractionService
      const stage1Results = await AIExtractionService.performAIExtraction(batchId, screenshotsToProcess);
      
      // Filter out screenshots that failed Stage 1 before proceeding to Stage 2
      const successfulScreenshotIds = new Set(
          Array.from(stage1Results.entries())
              .filter(([_, result]) => !result.error) // Keep only entries without an error
              .map(([id, _]) => id) // Get the screenshot IDs
      );

      const screenshotsForMoondream = screenshotsToProcess.filter(s =>
          successfulScreenshotIds.has(s.screenshot_id)
      );

      if (screenshotsForMoondream.length === 0) {
          console.warn(`[Batch ${batchId}] No screenshots successfully completed Stage 1. Cannot proceed to Moondream.`);
          // Consider the final status - potentially 'failed' or a specific 'extraction_failed' status
          await this.updateBatchStatus(batchId, ProcessStatus.FAILED);
          return;
      }
      console.log(`[Batch ${batchId}] ${screenshotsForMoondream.length} screenshots proceeding to Stage 2 (Moondream).`);

      // --- Stage 2: Parallel Moondream Detection ---
      await this.updateBatchStatus(batchId, ProcessStatus.ANNOTATING); 
      // console.log(`[Batch ${batchId}] Starting Moondream detection for ${screenshotsForMoondream.length} screenshots with concurrency ${MOONDREAM_CONCURRENCY}...`);
      
      // Use the external ParallelMoondreamDetectionService
      const allDetectionResults = await ParallelMoondreamDetectionService.performMoondreamDetection(
        batchId, 
        screenshotsForMoondream, 
        stage1Results
      );
      
      // --- Stage 3: Accuracy Validation ---
      await this.updateBatchStatus(batchId, ProcessStatus.VALIDATING);
      console.log(`[Batch ${batchId}] Stage 3: Starting Accuracy Validation...`);
      
      // Use the AccuracyValidationService to validate bounding boxes
      const validatedResults = await AccuracyValidationService.performAccuracyValidation(
        batchId,
        allDetectionResults
      );
      
      // --- Stage 4: Persist Results ---
      await this.updateBatchStatus(batchId, ProcessStatus.DONE);
      console.log(`[Batch ${batchId}] Placeholder: Persisting ${validatedResults.length} component results...`);
      // TODO: Implement persistence logic for `validatedResults`
      // 1. Upload unique annotated_image_objects to Storage
      // 2. Get public URLs
      // 3. Update ComponentDetectionResult objects
      // 4. Save component_detection metadata
      // 5. Save element_detection items


      // --- Finalize ---
      await this.updateBatchStatus(batchId, ProcessStatus.DONE); // Update status to 'done' after successful processing
      console.log(`[Batch ${batchId}] Processing complete. Status set to done.`);

    } catch (error) {
      // Catch errors from setup phase or unhandled exceptions in stages
      await this.handleProcessingError(batchId, error);
    }
  }

  /**
   * Loads screenshots, processes signed URLs, and fetches screenshot buffers
   * @param batchId The ID of the batch to process
   * @returns Array of screenshots ready for processing with buffers and signed URLs
   */
  private async loadAndPrepareScreenshots(batchId: number): Promise<Screenshot[]> {
    // Load screenshots from database
    const screenshots = await this.loadScreenshots(batchId);
    if (screenshots.length === 0) {
      console.log(`[Batch ${batchId}] No screenshots found. Setting status to done.`);
      await this.updateBatchStatus(batchId, ProcessStatus.DONE);
      return [];
    }
    console.log(`[Batch ${batchId}] Found ${screenshots.length} screenshots.`);

    // Process signed URLs
    await this.processSignedUrls(batchId, screenshots);
    // console.log(`[Batch ${batchId}] Processed signed URLs.`);

    // Fetch screenshot buffers
    await this.fetchScreenshotBuffers(screenshots);
    // console.log(`[Batch ${batchId}] Fetched screenshot buffers.`);

    // Filter screenshots that have both buffer and signed URL for processing
    const screenshotsToProcess = screenshots.filter(
      s => s.screenshot_image_buffer && s.screenshot_signed_url
    );

    if (screenshotsToProcess.length === 0) {
      console.warn(`[Batch ${batchId}] No screenshots with image buffers and signed URLs found after fetching. Cannot proceed.`);
      // Decide status: 'failed' if buffers were expected, 'done' if URLs weren't generated?
      await this.updateBatchStatus(batchId, ProcessStatus.FAILED);
      return [];
    }
    // console.log(`[Batch ${batchId}] ${screenshotsToProcess.length} screenshots eligible for processing.`);
    
    return screenshotsToProcess;
  }

  private async loadScreenshots(batchId: number): Promise<Screenshot[]> {
    const screenshots = await this.getBatchScreenshots(batchId);
    return screenshots;
  }

  private async processSignedUrls(batchId: number, screenshots: Screenshot[]): Promise<void> {
    // 1. Derive bucket paths
    const filePaths = screenshots
      .map(s => getScreenshotPath(s.screenshot_file_url))
      .filter((p): p is string => p !== null); // Type guard to filter nulls and ensure string[]

    if (filePaths.length !== screenshots.length) {
      console.warn(
        `[Batch ${batchId}] ${screenshots.length - filePaths.length} invalid screenshot file URLs found. Associated screenshots skipped for URL generation.`
      );
      // Optionally filter the screenshots array itself here if needed later
    }
    if (filePaths.length === 0) {
      console.log(`[Batch ${batchId}] No valid file paths found. Skipping signed URL fetch.`);
      // Update screenshots array to empty or mark them as missing URL?
      screenshots.forEach(s => {
          s.screenshot_signed_url = undefined;
          s.screenshot_bucket_path = undefined;
      });
      return;
    }

    // 2. Fetch signed URLs
    let signedUrls = new Map<string, string>();
    try {
      signedUrls = await getSignedUrls(this.supabaseClient, filePaths);
    } catch (urlError) {
      console.error(`[Batch ${batchId}] Failed to get signed URLs:`, urlError);
      // Consider how to handle this - fail the batch or proceed without URLs?
      // For now, proceed but log the issue. Screenshots without URLs will be filtered out later.
    }

    // 3. Attach to screenshots
    let attachedCount = 0;
    screenshots.forEach(s => {
      const path = getScreenshotPath(s.screenshot_file_url);
      if (path && signedUrls.has(path)) {
        s.screenshot_signed_url = signedUrls.get(path)!;
        s.screenshot_bucket_path = path;
        attachedCount++;
      } else {
        // Ensure screenshots that didn't get a URL (due to invalid path or fetch error) have undefined values
        s.screenshot_signed_url = undefined;
        s.screenshot_bucket_path = undefined;
      }
    });
    // console.log(`[Batch ${batchId}] Attached signed URLs to ${attachedCount} out of ${screenshots.length} initial screenshots (${filePaths.length} valid paths attempted).`);
  }


  private async handleProcessingError(batchId: number, error: unknown): Promise<void> {
    console.error(`[Batch ${batchId}] Critical error during batch processing:`, error);
    try {
      await this.updateBatchStatus(batchId, ProcessStatus.FAILED);
      console.error(`[Batch ${batchId}] Status set to failed.`);
    } catch (statusError) {
      console.error(
        `[Batch ${batchId}] Failed to update status to failed after critical error:`,
        statusError
      );
    }
  }


  /**
   * Updates the status of a batch in the database.
   * @param batchId The ID of the batch.
   * @param status The new status string.
   */
  private async updateBatchStatus(batchId: number, status: string): Promise<void> {
    const { error } = await this.supabaseClient
      .from('batch')
      .update({ batch_status: status, updated_at: new Date().toISOString() }) // Add updated_at
      .eq('batch_id', batchId);

    if (error) {
      console.error(`[Batch ${batchId}] Supabase batch status update error to '${status}':`, error);
      // Avoid throwing here to allow subsequent error handling like handleProcessingError to proceed
      // throw new Error(`Failed to update batch ${batchId} status to ${status}.`);
    } else {
      console.log(`[Batch ${batchId}] Status updated to '${status}'.`);
    }
  }



  /**
   * Fetches all screenshot records for a given batch ID.
   * @param batchId The ID of the batch.
   * @returns An array of screenshot records.
   */
   // Update return type to use the Screenshot interface
  private async getBatchScreenshots(batchId: number): Promise<Screenshot[]> {
    const { data, error } = await this.supabaseClient
      .from('screenshot')
      .select('*')
      .eq('batch_id', batchId);

    if (error) {
      console.error(`[Batch ${batchId}] Supabase screenshot fetch error:`, error);
      // Rethrow or return empty? Returning empty allows process to potentially continue if error is transient, but might hide issues.
      // Let's return empty and log, the calling function handles the empty case.
      return [];
    }

    // Explicitly cast data to Screenshot[] after checking for null/undefined
    return (data as Screenshot[] | null) || [];
  }


  /**
   * Fetches image data as ArrayBuffer for each screenshot with a valid signed URL
   * @param screenshots Array of screenshot objects with screenshot_signed_url property
   * @returns The same array of screenshots with screenshot_image_buffer property populated
   */
  public async fetchScreenshotBuffers(
    screenshots: Screenshot[]
  ): Promise<Screenshot[]> {
    // Assuming fetchScreenshotBuffers handles its own logging and concurrency
    return fetchScreenshotBuffers(screenshots);
  }
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/lib/services/DatabaseService.ts
================
import { createClient, SupabaseClient } from '@supabase/supabase-js';
import { SUPABASE_URL, SUPABASE_KEY } from '../../config'; // Adjust path as needed

export class DatabaseService {
  private static instance: DatabaseService;
  private client: SupabaseClient;

  private constructor() {
    if (!SUPABASE_URL || !SUPABASE_KEY) {
      throw new Error('Supabase URL or Key is missing in config.ts');
    }
    // Use Database type if you have generated types, otherwise use 'any'
    this.client = createClient<any>(SUPABASE_URL, SUPABASE_KEY);
  }

  public static getInstance(): DatabaseService {
    if (!DatabaseService.instance) {
      DatabaseService.instance = new DatabaseService();
    }
    return DatabaseService.instance;
  }

  public getClient(): SupabaseClient {
    return this.client;
  }
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/lib/services/ParallelAnnotationService.ts
================
import { BatchProcessingScreenshot as Screenshot } from '@/types/BatchProcessingScreenshot';
import type { ComponentDetectionResult } from '@/types/DetectionResult';
import { Stage1Result } from '@/lib/services/ParallelExtractionService';
// Import from the correct module
import { processAndSaveByCategory } from '@/lib/services/ai/MoondreamDetectionService';
import pLimit from 'p-limit';
import { MOONDREAM_CONCURRENCY } from '@/lib/constants';
import { createScreenshotTrackingContext } from '@/lib/logger';

 
/**
 * ParallelMoondreamDetectionService
 * 
 * This service handles the parallel processing of screenshots through Moondream's
 * language vision models, using anchor labels from previous AI processing steps
 * to guide object detection within UI screenshots.
 * 
 * DESIGN DECISIONS:
 * 1. Controlled Parallelism: We implement managed concurrency to balance throughput 
 *    against system resource constraints. This approach prevents overwhelming the 
 *    local model while still achieving significant performance gains.
 * 
 * 2. Error Isolation: Each screenshot is processed independently in its own promise,
 *    allowing failures to be contained without affecting the entire batch.
 * 
 * 3. Result Aggregation: All detection results are collected into a flat array,
 *    making it easier to persist results as a single operation rather than per-screenshot.
 * 
 * 4. Contextual Processing: By utilizing the anchor labels from Stage 1, we provide
 *    semantic context to the vision model, improving its accuracy in identifying
 *    specific UI components.
 * 
 * 5. Comprehensive Error Handling: We use Promise.allSettled to ensure the pipeline 
 *    continues even when individual screenshots fail processing.
 */
export class ParallelMoondreamDetectionService {
  /**
   * Performs parallel Moondream detection on screenshots using anchors from Stage 1
   * 
   * TECHNICAL DETAILS:
   * - Implements a processing pool with p-limit to manage resource consumption
   * - Each screenshot is processed independently within the concurrency pool
   * - Results are flat-mapped into a single array for efficient bulk persistence
   * - Empty arrays are returned for failed screenshots to maintain processing flow
   * - Promise.allSettled ensures batch resilience against individual failures
   * 
   * @param batchId The ID of the batch being processed (for logging)
   * @param screenshots Array of screenshots that passed Stage 1
   * @param stage1Results Map of Stage 1 results by screenshot ID
   * @returns Array of ComponentDetectionResult objects
   */
  public static async performMoondreamDetection(
    batchId: number, 
    screenshots: Screenshot[], 
    stage1Results: Map<number, Stage1Result>
  ): Promise<ComponentDetectionResult[]> {

    // Create concurrency limiter for Moondream to prevent resource exhaustion
    // This is especially important as Moondream is compute-intensive
    const moondreamLimit = pLimit(MOONDREAM_CONCURRENCY);
    const allDetectionResults: ComponentDetectionResult[] = []; // Collect all results in flat array
    
    console.log(`[Batch ${batchId}] Stage 2: Starting Bounding Box Detection for ${screenshots.length} screenshots... Concurrency: ${MOONDREAM_CONCURRENCY}`);

    // Initialize parallel detection tasks with controlled concurrency
    const detectionPromises = screenshots.map(screenshot =>
      moondreamLimit(async () => {
        // const context = createScreenshotTrackingContext(batchId, screenshot.screenshot_id);
        const screenshotId = screenshot.screenshot_id;
        // We know buffer exists because it passed the initial filter
        const buffer = screenshot.screenshot_image_buffer!;
        // We know stage 1 results exist because we filtered for successful ones
        const stage1Data = stage1Results.get(screenshotId)!;
        const anchorLabels = stage1Data.anchorLabels;

        console.log(`[Batch ${batchId}] Stage 2: Moondream labelling screenshot ${screenshotId}...`);

        try {
          // Process screenshot with Moondream using component anchors
          // These anchors provide semantic context to improve detection accuracy
          const results: ComponentDetectionResult[] = await processAndSaveByCategory(
            screenshotId,
            buffer,
            anchorLabels, // Use the labels derived specific to this screenshot
            batchId
          );
          console.log(`[Batch ${batchId}] Stage 2: Finished Moondream labelling for screenshot ${screenshotId}. Results count: ${results.length}`);
          return results; // Return results for this screenshot
        } catch (error) {
          // Log error but continue processing other screenshots
          console.error(`[Batch ${batchId}] Stage 2: Error labelling screenshot ${screenshotId} with Moondream:`, error);
          return []; // Return empty array on error for this screenshot
        }
      })
    );

    // Wait for all detection tasks to complete or fail
    // Using Promise.allSettled ensures we collect all successful results
    // even if some screenshots fail processing
    const settledMoondreamResults = await Promise.allSettled(detectionPromises);
    
    // Aggregate results from all successfully processed screenshots
    settledMoondreamResults.forEach(result => {
      if (result.status === 'fulfilled' && Array.isArray(result.value)) {
        // Spread array results into the flat collection
        allDetectionResults.push(...result.value);
      } else if (result.status === 'rejected') {
        // Error already logged inside the promise, add batch-level context
        console.error(`[Batch ${batchId}] Stage 2: A Moondream detection task failed:`, result.reason);
      }
    });
    
    return allDetectionResults;
  }
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/lib/services/ParallelExtractionService.ts
================
import { BatchProcessingScreenshot as Screenshot } from '@/types/BatchProcessingScreenshot';
import { extract_component_from_image } from '@/lib/services/ai/OpenAIService';
import { extract_element_from_image, anchor_elements_from_image } from '@/lib/services/ai/ClaudeAIService';
import pLimit from 'p-limit';
import { EXTRACTION_CONCURRENCY } from '@/lib/constants';
import { createScreenshotTrackingContext, PromptTrackingContext } from '@/lib/logger';

// --- Types for intermediate results ---
export interface Stage1Result {
    componentSummaries: string[];
    elementResultRawText: string;
    anchorLabels: Record<string, string>;
    error?: any; // error tracking per screenshot
}

/**
 * AIExtractionService
 * 
 * This service handles the parallel extraction of components, elements, and anchors from screenshots
 * using multiple AI systems (OpenAI and Claude).
 * 
 * DESIGN DECISIONS:
 * 1. Parallel Processing: We use controlled parallelism to maximize throughput without overwhelming 
 *    external API services. This balances speed with reliability and cost management.
 * 
 * 2. Fault Tolerance: Each screenshot is processed independently, and errors are captured per 
 *    screenshot rather than failing the entire batch. This allows partial batch success.
 * 
 * 3. Progressive Enhancement: The extraction pipeline builds incrementally, with each step using 
 *    the results of the previous step:
 *    - Component extraction identifies high-level UI patterns
 *    - Element extraction uses components to find specific elements
 *    - Anchor labeling uses element data to establish reference points
 * 
 * 4. Data Integrity: Results include error tracking to allow downstream processes to filter out
 *    failed operations and proceed with successful ones.
 */
export class AIExtractionService {
  /**
   * Extracts components, elements, and anchors from screenshots in parallel
   * 
   * TECHNICAL DETAILS:
   * - Implements controlled parallelism with p-limit to manage API rate limits
   * - Each screenshot processing runs independently with Promise.allSettled for fault isolation
   * - Maps screenshot IDs to their extraction results for later processing stages
   * - Progressive extraction: Components  Elements  Anchors
   * - Comprehensive error capture to prevent batch failure from individual items
   * 
   * @param batchId The ID of the batch being processed (for logging)
   * @param screenshots Array of screenshots with buffers and signed URLs
   * @returns Map of screenshot IDs to Stage1Result objects
   */
  public static async performAIExtraction(batchId: number, screenshots: Screenshot[]): Promise<Map<number, Stage1Result>> {
    // Create a concurrency limiter to prevent overwhelming external AI services
    // This is crucial for rate limit management and cost control
    const extractionLimit = pLimit(EXTRACTION_CONCURRENCY);
    const stage1Results = new Map<number, Stage1Result>(); // Map screenshot_id to results

    // Map each screenshot to a promise that processes it within concurrency limits
    const extractionPromises = screenshots.map(screenshot =>
      extractionLimit(async () => {
        const screenshotId = screenshot.screenshot_id;
        const signedUrl = screenshot.screenshot_signed_url!; // We filtered for this previously
        console.log(`[Batch ${batchId}] Stage 1: Processing screenshot ${screenshotId}...`);

        // Create a tracking context for this screenshot
        const context = createScreenshotTrackingContext(batchId, screenshotId);

        try {
          // 1. Extract Components using OpenAI vision capabilities
          // Components represent high-level UI patterns (forms, cards, etc.)
          console.log(`[Batch ${batchId}][Screenshot ${screenshotId}] Step 1.1 : Extracting High-Level Components...`);
          const componentResult = await extract_component_from_image(signedUrl, context);
          const componentSummaries = this.extractComponentSummaries(componentResult.parsedContent || []);
          console.log(`[Batch ${batchId}][Screenshot ${screenshotId}] Step 1.1 Complete. Found ${componentSummaries.length} Main Components.`);

          // 2. Extract Elements based on Components using Claude
          // Elements are specific interactive parts informed by component context
          console.log(`[Batch ${batchId}][Screenshot ${screenshotId}] Step 1.2 : Extracting Detailed Elements...`);
          const elementResult = await extract_element_from_image(signedUrl, componentSummaries.join('\n'), context);
          console.log(`[Batch ${batchId}][Screenshot ${screenshotId}] Step 1.2 Complete. Found ${elementResult.parsedContent.length} Detailed Elements.`);

          // 3. Anchor Elements based on Element Extraction
          // Anchors provide spatial reference points for Moondream to use later
          console.log(`[Batch ${batchId}][Screenshot ${screenshotId}] Step 1.3 : Optimising descriptions for VLM detection`);
          const anchorResult = await anchor_elements_from_image(signedUrl, `${elementResult.rawText}`, context);
          const anchorLabels: Record<string, string> = anchorResult.parsedContent || {};
          console.log(`[Batch ${batchId}][Screenshot ${screenshotId}] Step 1.3 Complete. Optimised ${Object.keys(anchorLabels).length} labels.`);

          if (Object.keys(anchorLabels).length === 0) {
            console.warn(`[Batch ${batchId}][Screenshot ${screenshotId}] No anchor labels generated. Moondream detection might be ineffective.`);
          }

          // Store successful results
          stage1Results.set(screenshotId, {
            componentSummaries,
            elementResultRawText: elementResult.rawText || '',
            anchorLabels,
          });
          console.log(`[Batch ${batchId}][Screenshot ${screenshotId}]Successfully processed screenshot ${screenshotId}. Found ${componentSummaries.length} Main Components, ${elementResult.parsedContent.length} Detailed Elements, ${Object.keys(anchorLabels).length} Optimised Labels.`);

        } catch (error) {
          console.error(`[Batch ${batchId}][Screenshot ${screenshotId}] Step 1.4 : Error processing screenshot ${screenshotId}:`, error);
          // Store error information for reporting and later filtering
          // This resilience allows the process to continue with successfully processed screenshots
          stage1Results.set(screenshotId, {
            componentSummaries: [],
            elementResultRawText: '',
            anchorLabels: {},
            error: error, // Store the error for filtering and diagnosis
          });
        }
      })
    );

    // Wait for all extractions to complete (successfully or with errors)
    // We use Promise.allSettled instead of Promise.all to prevent a single failure from stopping the batch
    await Promise.allSettled(extractionPromises);
    console.log(`[Batch ${batchId}] Completed Stage 1 AI extraction for all applicable screenshots.`);
    
    return stage1Results;
  }

  /**
   * Helper function to extract component summaries from AI extraction results
   * This is to pass to the element extraction step
   * 
   * @param components Array of components from AI extraction
   * @returns Array of component summary strings (just names for now)
   */
  private static extractComponentSummaries(components: any[]): string[] {
    if (!Array.isArray(components)) {
      console.warn("ExtractComponentSummaries: Expected an array of components, received:", typeof components);
      return [];
    }

    return components
      // Ensure component is an object and has the required string properties
      .filter(component =>
          typeof component === 'object' &&
          component !== null &&
          typeof component.component_name === 'string' &&
          typeof component.description === 'string' // Keep description check even if not used in output
      )
      .map(component => component.component_name); // Just using name now
  }
}

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/lib/services/sample_vision_api_call.txt
================
import OpenAI from "openai";

const openai = new OpenAI();

const response = await openai.responses.create({
    model: "gpt-4o-2024-11-20",
    input: [{
        role: "user",
        content: [
            { type: "input_text", text: "what's in this image?" },
            {
                type: "input_image",
                image_url: "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
            },
        ],
    }],
});

console.log(response.output_text);



import Anthropic from '@anthropic-ai/sdk';

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

async function main() {
  const message = await anthropic.messages.create({
    model: "claude-3-7-sonnet-20250219",
    max_tokens: 1024,
    messages: [
      {
        role: "user",
        content: [
          {
            type: "image",
            source: {
              type: "url",
              url: "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg"
            }
          },
          {
            type: "text",
            text: "Describe this image."
          }
        ]
      }
    ]
  });
  
  console.log(message);
}

main();

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/types/BatchProcessingScreenshot.ts
================
import { Buffer } from 'buffer';

export interface BatchProcessingScreenshot {
    screenshot_id: number;
    batch_id: number;
    screenshot_file_name: string;
    screenshot_file_url: string; // URL like https://<...>/public/<bucket>/<path>
    screenshot_processing_status: string;
    screenshot_processing_time: string;
    screenshot_created_at: string;
    screenshot_signed_url?: string | null;
    screenshot_bucket_path?: string | null;
    // screenshot_image_blob?: Blob | null;
    // screenshot_image_base64?: string | null; // Base64 encoded image with data URI prefix
    screenshot_image_buffer?: Buffer | null; // Raw buffer data for image processing
  }

================
File: /Users/jess/Desktop/personal git/mobbin/formobbin/types/DetectionResult.ts
================
interface ElementDetectionItem {
  label: string;
  description: string;
  bounding_box: {
    x_min: number;
    y_min: number;
    x_max: number;
    y_max: number;
  };
  status: 'Detected' | 'Not Detected' | 'Error';
  vlm_model: string; // Track which model provided the detection
  element_inference_time: number; // Time taken for this specific element
  accuracy_score?: number; // Optional: To be added later
  suggested_coordinates?: { x_min: number; y_min: number; x_max: number; y_max: number }; // Optional: To be added later
}

interface ComponentDetectionResult {
  screenshot_id: number;
  component_name: string; // Top-level category/component name
  annotated_image_object: Buffer; // The rendered image buffer for this component
  annotated_image_url?: string; // To be populated after upload
  component_description: string; // Maybe derived from element descriptions or passed in
  detection_status: 'success' | 'partial' | 'failed'; // Overall status for this component
  inference_time: number; // Total time for this component's elements
  elements: ElementDetectionItem[];
}

// Export the interfaces
export type { ComponentDetectionResult, ElementDetectionItem };
